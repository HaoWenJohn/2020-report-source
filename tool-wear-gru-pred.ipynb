{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PHMToolWearDataset(object):\n",
    "    # extract all data\n",
    "    cache_dir_path = '.cache/'\n",
    "    total_signal_num = 315\n",
    "    # only 1,4 and 6 is correct\n",
    "    sample_label = [1,4,6]\n",
    "    sample_loc = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.force_update = False\n",
    "\n",
    "    @property\n",
    "    def res_data_path(self):\n",
    "        return '~/Downloads/c1/c%s_wear.csv' % (self.sample_loc)\n",
    "\n",
    "    @property\n",
    "    def get_res_data_in_numpy(self):\n",
    "        # remove cache because it's not needed\n",
    "        res_csv_data = self.get_res_data_by_pandas\n",
    "        \n",
    "        res_array = np.array([np.array(i).reshape(3) for i in res_csv_data.values])\n",
    "        \n",
    "        # np.save(storage_path, res_array)\n",
    "        return res_array\n",
    "\n",
    "    @property\n",
    "    def get_res_data_by_pandas(self):\n",
    "        return pd.read_csv(self.res_data_path, index_col='cut')\n",
    "\n",
    "    @property\n",
    "    def res_data_storage(self):\n",
    "        return 'phm_tool_wear_data'\n",
    "\n",
    "    @property\n",
    "    def get_tool_wear_data(self):\n",
    "        storage_path = self.cache_dir_path + self.res_data_storage\n",
    "        self.sample_loc = 1\n",
    "        y_dat = self.get_res_data_in_numpy\n",
    "        for i in [4,6]:\n",
    "            self.sample_loc = i\n",
    "            y_dat = np.append(self.get_res_data_in_numpy, y_dat, axis=0)\n",
    "\n",
    "       \n",
    "        return y_dat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNSeriesDataSet(object):\n",
    "\n",
    "    def __init__(self,begin_timestep,end_timestep):\n",
    "        a = PHMToolWearDataset()\n",
    "        self.tool_wear_data = a.get_tool_wear_data\n",
    "        \n",
    "        self.max_tool_wear_data = np.max(self.tool_wear_data,axis=1)\n",
    "       \n",
    "        self.begin_timestep = begin_timestep\n",
    "        self.end_timestep = end_timestep\n",
    "\n",
    "    def get_tool_wear_data(self):\n",
    "        return self.tool_wear_data\n",
    "\n",
    "    def get_individual_tool_wear_batches(self,tool_wear_data):\n",
    "        \n",
    "        round_number = tool_wear_data.shape[0]\n",
    "        \n",
    "        begin_series = []\n",
    "        end_series = []\n",
    "        for start_index in range(self.begin_timestep,round_number-self.end_timestep):\n",
    "            x = tool_wear_data[start_index-self.begin_timestep:start_index]\n",
    "            y = tool_wear_data[start_index:start_index+self.end_timestep]\n",
    "            \n",
    "            begin_series.append(x)\n",
    "            end_series.append(y)\n",
    "        return begin_series,end_series\n",
    "\n",
    "    def get_rnn_data(self):\n",
    "        x,y = [],[]\n",
    "        for i in range(3):\n",
    "            ix,iy = self.get_individual_tool_wear_batches(self.max_tool_wear_data[i*315:(i+1)*315])\n",
    "            x.extend(ix)\n",
    "            y.extend(iy)\n",
    "           \n",
    "        dat_x,dat_y =  np.array(x),np.array(y)\n",
    "        return dat_x.reshape((dat_x.shape[0],dat_x.shape[1],1)),dat_y.reshape((dat_y.shape[0],dat_y.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (945, 3)\n",
      "after: (945,)\n",
      "Size : (855, 10, 1) (855, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "data = RNNSeriesDataSet(10,20)\n",
    "x,y = data.get_rnn_data()\n",
    "\n",
    "# ---- shuffle -----\n",
    "import random\n",
    "# set random seeds so that we can get the same random data!\n",
    "SEED = 12347\n",
    "random.seed(SEED)\n",
    "index = [i for i in range(len(y))]\n",
    "random.shuffle(index)\n",
    "train_y = y[index]\n",
    "train_x = x[index]\n",
    "\n",
    "print(\"Size :\",train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU,Dense,RepeatVector\n",
    "def build_stack_GRU(input_shape,output_length,output_dim):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(GRU(64,input_shape=input_shape,return_sequences=False))\n",
    "    #model.add(GRU(32,return_sequences=False))\n",
    "    model.add(Dense(32))\n",
    "    model.add(RepeatVector(output_length))\n",
    "    model.add(GRU(32,return_sequences=False))\n",
    "    #model.add(GRU(16,return_sequences=True))\n",
    "    model.add(Dense(output_dim))\n",
    "\n",
    "    model.compile(loss='mae', optimizer='adam', metrics=[\"mae\", \"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "tb_cb = TensorBoard(log_dir=\"train_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 684 samples, validate on 171 samples\n",
      "Epoch 1/2500\n",
      "684/684 [==============================] - 4s 5ms/sample - loss: 114.2801 - mae: 114.2801 - mse: 14366.3330 - val_loss: 116.5075 - val_mae: 116.5074 - val_mse: 15178.7080\n",
      "Epoch 2/2500\n",
      "684/684 [==============================] - 1s 780us/sample - loss: 110.8150 - mae: 110.8150 - mse: 13576.4414 - val_loss: 114.8001 - val_mae: 114.8001 - val_mse: 14783.1934\n",
      "Epoch 3/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 109.2215 - mae: 109.2215 - mse: 13226.8906 - val_loss: 113.2603 - val_mae: 113.2603 - val_mse: 14432.0029\n",
      "Epoch 4/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 107.7047 - mae: 107.7047 - mse: 12897.0879 - val_loss: 111.7637 - val_mae: 111.7637 - val_mse: 14095.2002\n",
      "Epoch 5/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 106.2192 - mae: 106.2192 - mse: 12580.8057 - val_loss: 110.2877 - val_mae: 110.2878 - val_mse: 13767.4551\n",
      "Epoch 6/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 104.7500 - mae: 104.7500 - mse: 12266.6885 - val_loss: 108.8245 - val_mae: 108.8245 - val_mse: 13446.8330\n",
      "Epoch 7/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 103.2909 - mae: 103.2909 - mse: 11965.4229 - val_loss: 107.3694 - val_mae: 107.3694 - val_mse: 13132.2432\n",
      "Epoch 8/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 101.8388 - mae: 101.8388 - mse: 11668.1729 - val_loss: 105.9201 - val_mae: 105.9201 - val_mse: 12823.1211\n",
      "Epoch 9/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 100.3917 - mae: 100.3917 - mse: 11374.8594 - val_loss: 104.4751 - val_mae: 104.4751 - val_mse: 12519.1113\n",
      "Epoch 10/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 98.9485 - mae: 98.9485 - mse: 11087.6670 - val_loss: 103.0336 - val_mae: 103.0336 - val_mse: 12219.9727\n",
      "Epoch 11/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 97.5082 - mae: 97.5082 - mse: 10804.9990 - val_loss: 101.5947 - val_mae: 101.5947 - val_mse: 11925.5352\n",
      "Epoch 12/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 96.0705 - mae: 96.0705 - mse: 10526.2100 - val_loss: 100.1580 - val_mae: 100.1580 - val_mse: 11635.6807\n",
      "Epoch 13/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 94.6347 - mae: 94.6347 - mse: 10252.4336 - val_loss: 98.7231 - val_mae: 98.7231 - val_mse: 11350.3164\n",
      "Epoch 14/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 93.2006 - mae: 93.2006 - mse: 9983.8652 - val_loss: 97.2898 - val_mae: 97.2898 - val_mse: 11069.3691\n",
      "Epoch 15/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 91.7680 - mae: 91.7680 - mse: 9718.2285 - val_loss: 95.8578 - val_mae: 95.8578 - val_mse: 10792.7842\n",
      "Epoch 16/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 90.3365 - mae: 90.3365 - mse: 9456.6406 - val_loss: 94.4270 - val_mae: 94.4270 - val_mse: 10520.5156\n",
      "Epoch 17/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 88.9062 - mae: 88.9062 - mse: 9202.5098 - val_loss: 92.9972 - val_mae: 92.9971 - val_mse: 10252.5283\n",
      "Epoch 18/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 87.4768 - mae: 87.4768 - mse: 8948.1162 - val_loss: 91.5682 - val_mae: 91.5682 - val_mse: 9988.7891\n",
      "Epoch 19/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 86.0482 - mae: 86.0482 - mse: 8699.9131 - val_loss: 90.1400 - val_mae: 90.1400 - val_mse: 9729.2734\n",
      "Epoch 20/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 84.6203 - mae: 84.6203 - mse: 8455.4854 - val_loss: 88.7125 - val_mae: 88.7125 - val_mse: 9473.9609\n",
      "Epoch 21/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 83.1931 - mae: 83.1931 - mse: 8216.3857 - val_loss: 87.2856 - val_mae: 87.2856 - val_mse: 9222.8301\n",
      "Epoch 22/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 81.7665 - mae: 81.7665 - mse: 7982.9058 - val_loss: 85.8593 - val_mae: 85.8593 - val_mse: 8975.8682\n",
      "Epoch 23/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 80.3404 - mae: 80.3404 - mse: 7752.3105 - val_loss: 84.4334 - val_mae: 84.4334 - val_mse: 8733.0596\n",
      "Epoch 24/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 78.9148 - mae: 78.9148 - mse: 7523.6001 - val_loss: 83.0080 - val_mae: 83.0080 - val_mse: 8494.3916\n",
      "Epoch 25/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 77.4897 - mae: 77.4897 - mse: 7301.9238 - val_loss: 81.5831 - val_mae: 81.5831 - val_mse: 8259.8564\n",
      "Epoch 26/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 76.0649 - mae: 76.0649 - mse: 7080.1812 - val_loss: 80.1585 - val_mae: 80.1585 - val_mse: 8029.4424\n",
      "Epoch 27/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 74.6405 - mae: 74.6405 - mse: 6868.0386 - val_loss: 78.7343 - val_mae: 78.7343 - val_mse: 7803.1401\n",
      "Epoch 28/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 73.2164 - mae: 73.2164 - mse: 6657.8735 - val_loss: 77.3104 - val_mae: 77.3103 - val_mse: 7580.9468\n",
      "Epoch 29/2500\n",
      "684/684 [==============================] - 1s 853us/sample - loss: 71.7926 - mae: 71.7926 - mse: 6450.2192 - val_loss: 75.8867 - val_mae: 75.8867 - val_mse: 7362.8530\n",
      "Epoch 30/2500\n",
      "684/684 [==============================] - 1s 846us/sample - loss: 70.3691 - mae: 70.3691 - mse: 6247.5620 - val_loss: 74.4634 - val_mae: 74.4634 - val_mse: 7148.8501\n",
      "Epoch 31/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 68.9459 - mae: 68.9459 - mse: 6049.1025 - val_loss: 73.0403 - val_mae: 73.0403 - val_mse: 6938.9385\n",
      "Epoch 32/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 67.5229 - mae: 67.5229 - mse: 5856.4702 - val_loss: 71.6174 - val_mae: 71.6174 - val_mse: 6733.1133\n",
      "Epoch 33/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 66.1002 - mae: 66.1002 - mse: 5666.1714 - val_loss: 70.1948 - val_mae: 70.1948 - val_mse: 6531.3628\n",
      "Epoch 34/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 64.6776 - mae: 64.6776 - mse: 5480.7783 - val_loss: 68.7723 - val_mae: 68.7723 - val_mse: 6333.6899\n",
      "Epoch 35/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 63.2554 - mae: 63.2554 - mse: 5298.8413 - val_loss: 67.3503 - val_mae: 67.3503 - val_mse: 6140.1157\n",
      "Epoch 36/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 61.8341 - mae: 61.8340 - mse: 5119.0981 - val_loss: 65.9286 - val_mae: 65.9286 - val_mse: 5950.6372\n",
      "Epoch 37/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 60.4140 - mae: 60.4140 - mse: 4943.8765 - val_loss: 64.5082 - val_mae: 64.5081 - val_mse: 5765.3584\n",
      "Epoch 38/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 58.9963 - mae: 58.9963 - mse: 4775.3901 - val_loss: 63.0894 - val_mae: 63.0894 - val_mse: 5584.3330\n",
      "Epoch 39/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 57.5816 - mae: 57.5816 - mse: 4612.1548 - val_loss: 61.6722 - val_mae: 61.6722 - val_mse: 5407.5127\n",
      "Epoch 40/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 56.1726 - mae: 56.1726 - mse: 4450.1934 - val_loss: 60.2580 - val_mae: 60.2580 - val_mse: 5235.0825\n",
      "Epoch 41/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 54.7770 - mae: 54.7770 - mse: 4293.4102 - val_loss: 58.8624 - val_mae: 58.8624 - val_mse: 5068.0078\n",
      "Epoch 42/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 53.4435 - mae: 53.4435 - mse: 4145.6694 - val_loss: 57.5307 - val_mae: 57.5307 - val_mse: 4909.3486\n",
      "Epoch 43/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 52.1477 - mae: 52.1477 - mse: 4001.9487 - val_loss: 56.2260 - val_mae: 56.2260 - val_mse: 4756.6113\n",
      "Epoch 44/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 50.8788 - mae: 50.8788 - mse: 3863.4321 - val_loss: 54.9178 - val_mae: 54.9179 - val_mse: 4606.3311\n",
      "Epoch 45/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 49.6242 - mae: 49.6242 - mse: 3728.5833 - val_loss: 53.6341 - val_mae: 53.6341 - val_mse: 4461.4512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 48.3875 - mae: 48.3875 - mse: 3599.2822 - val_loss: 52.3739 - val_mae: 52.3739 - val_mse: 4321.6035\n",
      "Epoch 47/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 47.1697 - mae: 47.1697 - mse: 3472.2664 - val_loss: 51.1270 - val_mae: 51.1270 - val_mse: 4185.5879\n",
      "Epoch 48/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 45.9707 - mae: 45.9707 - mse: 3353.1008 - val_loss: 49.8891 - val_mae: 49.8891 - val_mse: 4052.6021\n",
      "Epoch 49/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 44.7811 - mae: 44.7811 - mse: 3235.7698 - val_loss: 48.6861 - val_mae: 48.6861 - val_mse: 3925.3115\n",
      "Epoch 50/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 43.6088 - mae: 43.6088 - mse: 3123.8242 - val_loss: 47.4896 - val_mae: 47.4896 - val_mse: 3800.7410\n",
      "Epoch 51/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 42.4465 - mae: 42.4465 - mse: 3012.2991 - val_loss: 46.3168 - val_mae: 46.3168 - val_mse: 3680.9661\n",
      "Epoch 52/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 41.3012 - mae: 41.3012 - mse: 2905.9001 - val_loss: 45.1635 - val_mae: 45.1635 - val_mse: 3565.5771\n",
      "Epoch 53/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 40.1732 - mae: 40.1732 - mse: 2803.2476 - val_loss: 44.0214 - val_mae: 44.0214 - val_mse: 3453.6089\n",
      "Epoch 54/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 39.0636 - mae: 39.0636 - mse: 2706.9473 - val_loss: 42.8845 - val_mae: 42.8845 - val_mse: 3344.3733\n",
      "Epoch 55/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 37.9707 - mae: 37.9708 - mse: 2611.3862 - val_loss: 41.7628 - val_mae: 41.7628 - val_mse: 3238.8486\n",
      "Epoch 56/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 36.8940 - mae: 36.8940 - mse: 2522.0615 - val_loss: 40.6777 - val_mae: 40.6777 - val_mse: 3138.7583\n",
      "Epoch 57/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 35.8432 - mae: 35.8432 - mse: 2434.9280 - val_loss: 39.6159 - val_mae: 39.6159 - val_mse: 3042.6421\n",
      "Epoch 58/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 34.8302 - mae: 34.8302 - mse: 2353.6704 - val_loss: 38.6357 - val_mae: 38.6357 - val_mse: 2953.5317\n",
      "Epoch 59/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 33.9330 - mae: 33.9330 - mse: 2279.6956 - val_loss: 37.7280 - val_mae: 37.7280 - val_mse: 2869.3306\n",
      "Epoch 60/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 33.0733 - mae: 33.0733 - mse: 2208.8301 - val_loss: 36.8671 - val_mae: 36.8671 - val_mse: 2790.3167\n",
      "Epoch 61/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 32.2465 - mae: 32.2465 - mse: 2143.6050 - val_loss: 36.0280 - val_mae: 36.0280 - val_mse: 2714.0598\n",
      "Epoch 62/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 31.4526 - mae: 31.4526 - mse: 2076.6797 - val_loss: 35.2232 - val_mae: 35.2232 - val_mse: 2641.6323\n",
      "Epoch 63/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 30.6966 - mae: 30.6966 - mse: 2018.6880 - val_loss: 34.4686 - val_mae: 34.4686 - val_mse: 2574.1079\n",
      "Epoch 64/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 29.9953 - mae: 29.9953 - mse: 1962.1909 - val_loss: 33.7648 - val_mae: 33.7648 - val_mse: 2510.0952\n",
      "Epoch 65/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 29.4434 - mae: 29.4434 - mse: 1914.0826 - val_loss: 33.3292 - val_mae: 33.3292 - val_mse: 2460.3127\n",
      "Epoch 66/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 29.0955 - mae: 29.0955 - mse: 1876.9431 - val_loss: 32.9850 - val_mae: 32.9850 - val_mse: 2418.9414\n",
      "Epoch 67/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 28.7951 - mae: 28.7951 - mse: 1843.3882 - val_loss: 32.6739 - val_mae: 32.6739 - val_mse: 2381.4832\n",
      "Epoch 68/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 28.5232 - mae: 28.5232 - mse: 1812.2919 - val_loss: 32.3652 - val_mae: 32.3652 - val_mse: 2344.2256\n",
      "Epoch 69/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 28.2797 - mae: 28.2797 - mse: 1783.2603 - val_loss: 32.0996 - val_mae: 32.0996 - val_mse: 2310.6436\n",
      "Epoch 70/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 28.1312 - mae: 28.1312 - mse: 1759.8176 - val_loss: 31.9571 - val_mae: 31.9571 - val_mse: 2288.4905\n",
      "Epoch 71/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 28.0413 - mae: 28.0413 - mse: 1742.9576 - val_loss: 31.8159 - val_mae: 31.8159 - val_mse: 2266.1819\n",
      "Epoch 72/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 27.9545 - mae: 27.9545 - mse: 1727.3102 - val_loss: 31.7098 - val_mae: 31.7098 - val_mse: 2248.9495\n",
      "Epoch 73/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 27.8810 - mae: 27.8809 - mse: 1711.2196 - val_loss: 31.5887 - val_mae: 31.5887 - val_mse: 2228.6538\n",
      "Epoch 74/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 27.8103 - mae: 27.8103 - mse: 1696.2731 - val_loss: 31.4842 - val_mae: 31.4842 - val_mse: 2210.4824\n",
      "Epoch 75/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 27.7446 - mae: 27.7446 - mse: 1682.6030 - val_loss: 31.3980 - val_mae: 31.3980 - val_mse: 2194.9148\n",
      "Epoch 76/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 27.6869 - mae: 27.6869 - mse: 1669.2889 - val_loss: 31.3088 - val_mae: 31.3088 - val_mse: 2178.2061\n",
      "Epoch 77/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 27.6307 - mae: 27.6307 - mse: 1656.8525 - val_loss: 31.2351 - val_mae: 31.2351 - val_mse: 2163.7351\n",
      "Epoch 78/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 27.5822 - mae: 27.5822 - mse: 1645.6243 - val_loss: 31.1604 - val_mae: 31.1604 - val_mse: 2148.4663\n",
      "Epoch 79/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 27.5340 - mae: 27.5340 - mse: 1633.2100 - val_loss: 31.0888 - val_mae: 31.0888 - val_mse: 2133.4373\n",
      "Epoch 80/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 27.4878 - mae: 27.4878 - mse: 1622.5107 - val_loss: 31.0259 - val_mae: 31.0259 - val_mse: 2119.8586\n",
      "Epoch 81/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 27.4457 - mae: 27.4457 - mse: 1610.9415 - val_loss: 30.9622 - val_mae: 30.9622 - val_mse: 2105.7852\n",
      "Epoch 82/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 27.4055 - mae: 27.4055 - mse: 1600.6273 - val_loss: 30.9021 - val_mae: 30.9021 - val_mse: 2092.1628\n",
      "Epoch 83/2500\n",
      "684/684 [==============================] - 1s 843us/sample - loss: 27.3636 - mae: 27.3636 - mse: 1590.8907 - val_loss: 30.8546 - val_mae: 30.8546 - val_mse: 2081.1174\n",
      "Epoch 84/2500\n",
      "684/684 [==============================] - 1s 861us/sample - loss: 27.3273 - mae: 27.3273 - mse: 1581.6500 - val_loss: 30.8074 - val_mae: 30.8074 - val_mse: 2069.9424\n",
      "Epoch 85/2500\n",
      "684/684 [==============================] - 1s 902us/sample - loss: 27.2926 - mae: 27.2926 - mse: 1572.0688 - val_loss: 30.7500 - val_mae: 30.7500 - val_mse: 2055.8958\n",
      "Epoch 86/2500\n",
      "684/684 [==============================] - 1s 889us/sample - loss: 27.2591 - mae: 27.2591 - mse: 1561.9202 - val_loss: 30.6988 - val_mae: 30.6988 - val_mse: 2042.8909\n",
      "Epoch 87/2500\n",
      "684/684 [==============================] - 1s 907us/sample - loss: 27.2260 - mae: 27.2260 - mse: 1552.9479 - val_loss: 30.6576 - val_mae: 30.6576 - val_mse: 2032.2007\n",
      "Epoch 88/2500\n",
      "684/684 [==============================] - 1s 899us/sample - loss: 27.1952 - mae: 27.1952 - mse: 1544.9471 - val_loss: 30.6200 - val_mae: 30.6200 - val_mse: 2022.1521\n",
      "Epoch 89/2500\n",
      "684/684 [==============================] - 1s 846us/sample - loss: 27.1661 - mae: 27.1661 - mse: 1536.5320 - val_loss: 30.5795 - val_mae: 30.5795 - val_mse: 2010.9790\n",
      "Epoch 90/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 27.1377 - mae: 27.1376 - mse: 1528.9714 - val_loss: 30.5428 - val_mae: 30.5428 - val_mse: 2000.7136\n",
      "Epoch 91/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 795us/sample - loss: 27.1130 - mae: 27.1130 - mse: 1520.5697 - val_loss: 30.5104 - val_mae: 30.5104 - val_mse: 1991.3021\n",
      "Epoch 92/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 27.0882 - mae: 27.0882 - mse: 1512.7592 - val_loss: 30.4715 - val_mae: 30.4715 - val_mse: 1979.9028\n",
      "Epoch 93/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 27.0632 - mae: 27.0632 - mse: 1505.4896 - val_loss: 30.4452 - val_mae: 30.4452 - val_mse: 1971.9750\n",
      "Epoch 94/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 27.0422 - mae: 27.0422 - mse: 1498.7521 - val_loss: 30.4129 - val_mae: 30.4129 - val_mse: 1962.0269\n",
      "Epoch 95/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 27.0216 - mae: 27.0216 - mse: 1492.5328 - val_loss: 30.3877 - val_mae: 30.3877 - val_mse: 1954.1251\n",
      "Epoch 96/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 27.0009 - mae: 27.0009 - mse: 1485.3188 - val_loss: 30.3572 - val_mae: 30.3572 - val_mse: 1944.3646\n",
      "Epoch 97/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 26.9851 - mae: 26.9851 - mse: 1478.4677 - val_loss: 30.3289 - val_mae: 30.3289 - val_mse: 1935.0640\n",
      "Epoch 98/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 26.9638 - mae: 26.9638 - mse: 1473.3304 - val_loss: 30.3099 - val_mae: 30.3099 - val_mse: 1928.4709\n",
      "Epoch 99/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 26.9500 - mae: 26.9500 - mse: 1468.0851 - val_loss: 30.2938 - val_mae: 30.2938 - val_mse: 1922.2957\n",
      "Epoch 100/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 26.9401 - mae: 26.9401 - mse: 1462.5071 - val_loss: 30.2739 - val_mae: 30.2739 - val_mse: 1914.1521\n",
      "Epoch 101/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 26.9282 - mae: 26.9282 - mse: 1458.4860 - val_loss: 30.2627 - val_mae: 30.2627 - val_mse: 1909.3434\n",
      "Epoch 102/2500\n",
      "684/684 [==============================] - 1s 846us/sample - loss: 26.9194 - mae: 26.9194 - mse: 1455.0312 - val_loss: 30.2513 - val_mae: 30.2513 - val_mse: 1904.5282\n",
      "Epoch 103/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 26.9102 - mae: 26.9102 - mse: 1450.6157 - val_loss: 30.2358 - val_mae: 30.2358 - val_mse: 1897.8831\n",
      "Epoch 104/2500\n",
      "684/684 [==============================] - 1s 866us/sample - loss: 26.9011 - mae: 26.9011 - mse: 1446.0927 - val_loss: 30.2225 - val_mae: 30.2225 - val_mse: 1891.8635\n",
      "Epoch 105/2500\n",
      "684/684 [==============================] - 1s 839us/sample - loss: 26.8936 - mae: 26.8935 - mse: 1441.7986 - val_loss: 30.2115 - val_mae: 30.2115 - val_mse: 1886.8301\n",
      "Epoch 106/2500\n",
      "684/684 [==============================] - 1s 865us/sample - loss: 26.8855 - mae: 26.8855 - mse: 1439.0845 - val_loss: 30.2016 - val_mae: 30.2016 - val_mse: 1882.3275\n",
      "Epoch 107/2500\n",
      "684/684 [==============================] - 1s 831us/sample - loss: 26.8791 - mae: 26.8791 - mse: 1435.2451 - val_loss: 30.1933 - val_mae: 30.1933 - val_mse: 1878.2681\n",
      "Epoch 108/2500\n",
      "684/684 [==============================] - 1s 833us/sample - loss: 26.8742 - mae: 26.8742 - mse: 1430.7505 - val_loss: 30.1763 - val_mae: 30.1763 - val_mse: 1869.9478\n",
      "Epoch 109/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 26.8644 - mae: 26.8644 - mse: 1427.4131 - val_loss: 30.1693 - val_mae: 30.1693 - val_mse: 1866.5894\n",
      "Epoch 110/2500\n",
      "684/684 [==============================] - 1s 835us/sample - loss: 26.8591 - mae: 26.8591 - mse: 1424.0137 - val_loss: 30.1612 - val_mae: 30.1612 - val_mse: 1862.4043\n",
      "Epoch 111/2500\n",
      "684/684 [==============================] - 1s 830us/sample - loss: 26.8530 - mae: 26.8530 - mse: 1421.7175 - val_loss: 30.1524 - val_mae: 30.1524 - val_mse: 1857.6746\n",
      "Epoch 112/2500\n",
      "684/684 [==============================] - 1s 843us/sample - loss: 26.8489 - mae: 26.8489 - mse: 1417.3951 - val_loss: 30.1419 - val_mae: 30.1419 - val_mse: 1852.1158\n",
      "Epoch 113/2500\n",
      "684/684 [==============================] - 1s 839us/sample - loss: 26.8428 - mae: 26.8428 - mse: 1414.9750 - val_loss: 30.1358 - val_mae: 30.1358 - val_mse: 1848.7960\n",
      "Epoch 114/2500\n",
      "684/684 [==============================] - 1s 841us/sample - loss: 26.8388 - mae: 26.8388 - mse: 1411.7273 - val_loss: 30.1282 - val_mae: 30.1282 - val_mse: 1844.4955\n",
      "Epoch 115/2500\n",
      "684/684 [==============================] - 1s 842us/sample - loss: 26.8344 - mae: 26.8344 - mse: 1410.1859 - val_loss: 30.1248 - val_mae: 30.1248 - val_mse: 1842.5293\n",
      "Epoch 116/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 26.8311 - mae: 26.8311 - mse: 1408.2710 - val_loss: 30.1180 - val_mae: 30.1180 - val_mse: 1838.7111\n",
      "Epoch 117/2500\n",
      "684/684 [==============================] - 1s 862us/sample - loss: 26.8278 - mae: 26.8278 - mse: 1404.3956 - val_loss: 30.1075 - val_mae: 30.1075 - val_mse: 1832.5198\n",
      "Epoch 118/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 26.8229 - mae: 26.8229 - mse: 1402.3639 - val_loss: 30.1054 - val_mae: 30.1054 - val_mse: 1831.1804\n",
      "Epoch 119/2500\n",
      "684/684 [==============================] - 1s 861us/sample - loss: 26.8205 - mae: 26.8205 - mse: 1399.9829 - val_loss: 30.0981 - val_mae: 30.0981 - val_mse: 1826.6328\n",
      "Epoch 120/2500\n",
      "684/684 [==============================] - 1s 843us/sample - loss: 26.8173 - mae: 26.8173 - mse: 1398.1335 - val_loss: 30.0939 - val_mae: 30.0939 - val_mse: 1824.0413\n",
      "Epoch 121/2500\n",
      "684/684 [==============================] - 1s 861us/sample - loss: 26.8156 - mae: 26.8156 - mse: 1395.0892 - val_loss: 30.0877 - val_mae: 30.0877 - val_mse: 1820.1503\n",
      "Epoch 122/2500\n",
      "684/684 [==============================] - 1s 853us/sample - loss: 26.8129 - mae: 26.8129 - mse: 1393.6748 - val_loss: 30.0848 - val_mae: 30.0848 - val_mse: 1818.2299\n",
      "Epoch 123/2500\n",
      "684/684 [==============================] - 1s 836us/sample - loss: 26.8098 - mae: 26.8098 - mse: 1391.8628 - val_loss: 30.0809 - val_mae: 30.0809 - val_mse: 1815.6387\n",
      "Epoch 124/2500\n",
      "684/684 [==============================] - 1s 839us/sample - loss: 26.8092 - mae: 26.8092 - mse: 1389.3750 - val_loss: 30.0757 - val_mae: 30.0757 - val_mse: 1812.0618\n",
      "Epoch 125/2500\n",
      "684/684 [==============================] - 1s 855us/sample - loss: 26.8071 - mae: 26.8071 - mse: 1388.9087 - val_loss: 30.0743 - val_mae: 30.0743 - val_mse: 1811.0514\n",
      "Epoch 126/2500\n",
      "684/684 [==============================] - 1s 841us/sample - loss: 26.8058 - mae: 26.8058 - mse: 1388.0131 - val_loss: 30.0713 - val_mae: 30.0713 - val_mse: 1808.9868\n",
      "Epoch 127/2500\n",
      "684/684 [==============================] - 1s 847us/sample - loss: 26.7697 - mae: 26.7697 - mse: 1384.5558 - val_loss: 28.7652 - val_mae: 28.7652 - val_mse: 1811.4170\n",
      "Epoch 128/2500\n",
      "684/684 [==============================] - 1s 858us/sample - loss: 20.8001 - mae: 20.8001 - mse: 1199.7390 - val_loss: 22.8732 - val_mae: 22.8732 - val_mse: 1581.0405\n",
      "Epoch 129/2500\n",
      "684/684 [==============================] - 1s 863us/sample - loss: 18.6081 - mae: 18.6081 - mse: 1112.3759 - val_loss: 21.9732 - val_mae: 21.9732 - val_mse: 1508.1488\n",
      "Epoch 130/2500\n",
      "684/684 [==============================] - 1s 894us/sample - loss: 17.7662 - mae: 17.7662 - mse: 1052.5591 - val_loss: 21.1471 - val_mae: 21.1471 - val_mse: 1435.5688\n",
      "Epoch 131/2500\n",
      "684/684 [==============================] - 1s 885us/sample - loss: 17.0484 - mae: 17.0484 - mse: 1002.6406 - val_loss: 20.3113 - val_mae: 20.3113 - val_mse: 1372.3796\n",
      "Epoch 132/2500\n",
      "684/684 [==============================] - 1s 875us/sample - loss: 16.2454 - mae: 16.2454 - mse: 957.0335 - val_loss: 19.8885 - val_mae: 19.8885 - val_mse: 1329.7318\n",
      "Epoch 133/2500\n",
      "684/684 [==============================] - 1s 879us/sample - loss: 15.7782 - mae: 15.7782 - mse: 921.6270 - val_loss: 19.4373 - val_mae: 19.4373 - val_mse: 1282.8650\n",
      "Epoch 134/2500\n",
      "684/684 [==============================] - 1s 871us/sample - loss: 15.7947 - mae: 15.7947 - mse: 890.8242 - val_loss: 19.5735 - val_mae: 19.5735 - val_mse: 1243.1809\n",
      "Epoch 135/2500\n",
      "684/684 [==============================] - 1s 865us/sample - loss: 15.2404 - mae: 15.2404 - mse: 857.5587 - val_loss: 19.2303 - val_mae: 19.2303 - val_mse: 1205.9933\n",
      "Epoch 136/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 841us/sample - loss: 15.0294 - mae: 15.0294 - mse: 831.4263 - val_loss: 18.5729 - val_mae: 18.5729 - val_mse: 1166.6694\n",
      "Epoch 137/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 14.2366 - mae: 14.2366 - mse: 799.6932 - val_loss: 17.8810 - val_mae: 17.8810 - val_mse: 1128.9523\n",
      "Epoch 138/2500\n",
      "684/684 [==============================] - 1s 846us/sample - loss: 13.7299 - mae: 13.7299 - mse: 772.5759 - val_loss: 17.5710 - val_mae: 17.5710 - val_mse: 1094.2684\n",
      "Epoch 139/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 13.4244 - mae: 13.4244 - mse: 747.0544 - val_loss: 16.9700 - val_mae: 16.9700 - val_mse: 1057.8583\n",
      "Epoch 140/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 13.0424 - mae: 13.0424 - mse: 721.5464 - val_loss: 16.7059 - val_mae: 16.7059 - val_mse: 1024.6179\n",
      "Epoch 141/2500\n",
      "684/684 [==============================] - 1s 837us/sample - loss: 12.7356 - mae: 12.7356 - mse: 697.0811 - val_loss: 16.3653 - val_mae: 16.3653 - val_mse: 994.7319\n",
      "Epoch 142/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 12.5731 - mae: 12.5731 - mse: 676.7782 - val_loss: 16.8602 - val_mae: 16.8602 - val_mse: 969.2269\n",
      "Epoch 143/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 12.1902 - mae: 12.1902 - mse: 656.9501 - val_loss: 15.7137 - val_mae: 15.7137 - val_mse: 939.0690\n",
      "Epoch 144/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 11.8023 - mae: 11.8023 - mse: 636.5662 - val_loss: 15.6311 - val_mae: 15.6311 - val_mse: 911.2993\n",
      "Epoch 145/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 11.5016 - mae: 11.5016 - mse: 618.0715 - val_loss: 15.1376 - val_mae: 15.1376 - val_mse: 886.8048\n",
      "Epoch 146/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 11.2752 - mae: 11.2752 - mse: 600.6375 - val_loss: 15.0626 - val_mae: 15.0626 - val_mse: 861.3450\n",
      "Epoch 147/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 11.1227 - mae: 11.1227 - mse: 584.1675 - val_loss: 14.6756 - val_mae: 14.6756 - val_mse: 839.8138\n",
      "Epoch 148/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 10.9199 - mae: 10.9199 - mse: 569.3598 - val_loss: 14.4066 - val_mae: 14.4066 - val_mse: 819.2197\n",
      "Epoch 149/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 10.6629 - mae: 10.6629 - mse: 554.0646 - val_loss: 14.3229 - val_mae: 14.3229 - val_mse: 798.1724\n",
      "Epoch 150/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 10.5208 - mae: 10.5208 - mse: 541.2174 - val_loss: 14.3888 - val_mae: 14.3888 - val_mse: 780.5895\n",
      "Epoch 151/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 10.6347 - mae: 10.6347 - mse: 531.0317 - val_loss: 14.0976 - val_mae: 14.0976 - val_mse: 764.9490\n",
      "Epoch 152/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 10.2226 - mae: 10.2226 - mse: 517.5146 - val_loss: 13.6021 - val_mae: 13.6021 - val_mse: 744.5692\n",
      "Epoch 153/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 9.9578 - mae: 9.9578 - mse: 505.2093 - val_loss: 13.6156 - val_mae: 13.6156 - val_mse: 726.9001\n",
      "Epoch 154/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 9.9899 - mae: 9.9899 - mse: 493.5437 - val_loss: 13.2218 - val_mae: 13.2218 - val_mse: 708.9531\n",
      "Epoch 155/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 9.7974 - mae: 9.7974 - mse: 482.4803 - val_loss: 13.0924 - val_mae: 13.0924 - val_mse: 692.4145\n",
      "Epoch 156/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 9.6336 - mae: 9.6336 - mse: 471.0188 - val_loss: 12.8217 - val_mae: 12.8217 - val_mse: 675.3624\n",
      "Epoch 157/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 9.5211 - mae: 9.5211 - mse: 460.0403 - val_loss: 13.2920 - val_mae: 13.2920 - val_mse: 666.2330\n",
      "Epoch 158/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 9.3651 - mae: 9.3651 - mse: 450.8230 - val_loss: 12.3760 - val_mae: 12.3760 - val_mse: 644.5142\n",
      "Epoch 159/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 9.2624 - mae: 9.2624 - mse: 440.1406 - val_loss: 12.3209 - val_mae: 12.3209 - val_mse: 631.9477\n",
      "Epoch 160/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 9.1147 - mae: 9.1147 - mse: 430.6891 - val_loss: 12.3583 - val_mae: 12.3583 - val_mse: 617.8787\n",
      "Epoch 161/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 9.1492 - mae: 9.1492 - mse: 422.0782 - val_loss: 11.9049 - val_mae: 11.9049 - val_mse: 601.8893\n",
      "Epoch 162/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 8.8591 - mae: 8.8591 - mse: 412.1714 - val_loss: 11.7589 - val_mae: 11.7589 - val_mse: 589.3335\n",
      "Epoch 163/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 8.8527 - mae: 8.8527 - mse: 404.3795 - val_loss: 11.5742 - val_mae: 11.5742 - val_mse: 576.2979\n",
      "Epoch 164/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 8.6682 - mae: 8.6682 - mse: 395.6309 - val_loss: 11.4339 - val_mae: 11.4339 - val_mse: 564.0148\n",
      "Epoch 165/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 8.4495 - mae: 8.4495 - mse: 386.6576 - val_loss: 11.2673 - val_mae: 11.2673 - val_mse: 551.5941\n",
      "Epoch 166/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 8.3263 - mae: 8.3263 - mse: 378.6725 - val_loss: 11.2107 - val_mae: 11.2107 - val_mse: 539.2839\n",
      "Epoch 167/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 8.1869 - mae: 8.1869 - mse: 370.4731 - val_loss: 10.9351 - val_mae: 10.9351 - val_mse: 527.9872\n",
      "Epoch 168/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 8.2549 - mae: 8.2549 - mse: 364.1947 - val_loss: 11.4848 - val_mae: 11.4848 - val_mse: 521.5667\n",
      "Epoch 169/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 8.2885 - mae: 8.2885 - mse: 357.0834 - val_loss: 10.7259 - val_mae: 10.7259 - val_mse: 504.8081\n",
      "Epoch 170/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 8.0260 - mae: 8.0260 - mse: 348.8707 - val_loss: 10.5465 - val_mae: 10.5465 - val_mse: 493.7504\n",
      "Epoch 171/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 7.8923 - mae: 7.8923 - mse: 341.7838 - val_loss: 10.3403 - val_mae: 10.3403 - val_mse: 482.7100\n",
      "Epoch 172/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 7.7214 - mae: 7.7214 - mse: 333.9989 - val_loss: 10.2156 - val_mae: 10.2156 - val_mse: 472.4885\n",
      "Epoch 173/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 7.6823 - mae: 7.6823 - mse: 327.9013 - val_loss: 10.7555 - val_mae: 10.7555 - val_mse: 465.0082\n",
      "Epoch 174/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 7.7014 - mae: 7.7014 - mse: 321.4598 - val_loss: 9.9574 - val_mae: 9.9574 - val_mse: 452.5230\n",
      "Epoch 175/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 7.4325 - mae: 7.4325 - mse: 314.3285 - val_loss: 9.8067 - val_mae: 9.8067 - val_mse: 443.2589\n",
      "Epoch 176/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 7.3837 - mae: 7.3837 - mse: 308.6330 - val_loss: 10.1460 - val_mae: 10.1460 - val_mse: 435.4791\n",
      "Epoch 177/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 7.3958 - mae: 7.3958 - mse: 303.1552 - val_loss: 10.0807 - val_mae: 10.0807 - val_mse: 427.3111\n",
      "Epoch 178/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 7.5909 - mae: 7.5909 - mse: 299.8195 - val_loss: 9.8949 - val_mae: 9.8949 - val_mse: 418.1232\n",
      "Epoch 179/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 7.2175 - mae: 7.2175 - mse: 292.3023 - val_loss: 9.6028 - val_mae: 9.6028 - val_mse: 408.9380\n",
      "Epoch 180/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 7.1659 - mae: 7.1659 - mse: 286.7273 - val_loss: 9.2889 - val_mae: 9.2889 - val_mse: 400.1266\n",
      "Epoch 181/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 7.2191 - mae: 7.2191 - mse: 282.6641 - val_loss: 9.6275 - val_mae: 9.6275 - val_mse: 393.7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 7.0815 - mae: 7.0815 - mse: 277.3883 - val_loss: 9.1589 - val_mae: 9.1589 - val_mse: 386.3214\n",
      "Epoch 183/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 6.8425 - mae: 6.8425 - mse: 271.4530 - val_loss: 9.2623 - val_mae: 9.2623 - val_mse: 379.5103\n",
      "Epoch 184/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 6.8156 - mae: 6.8156 - mse: 266.4673 - val_loss: 9.1681 - val_mae: 9.1681 - val_mse: 373.6673\n",
      "Epoch 185/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 6.7641 - mae: 6.7641 - mse: 262.1577 - val_loss: 8.9099 - val_mae: 8.9099 - val_mse: 364.4803\n",
      "Epoch 186/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 6.6745 - mae: 6.6745 - mse: 256.9549 - val_loss: 8.6812 - val_mae: 8.6812 - val_mse: 356.4662\n",
      "Epoch 187/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 6.4883 - mae: 6.4883 - mse: 251.7390 - val_loss: 8.7038 - val_mae: 8.7038 - val_mse: 350.0631\n",
      "Epoch 188/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 6.4924 - mae: 6.4924 - mse: 247.5823 - val_loss: 8.4309 - val_mae: 8.4309 - val_mse: 341.7277\n",
      "Epoch 189/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 6.6377 - mae: 6.6377 - mse: 244.7649 - val_loss: 8.6446 - val_mae: 8.6446 - val_mse: 336.8060\n",
      "Epoch 190/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 6.5449 - mae: 6.5449 - mse: 240.6940 - val_loss: 8.2580 - val_mae: 8.2579 - val_mse: 330.6738\n",
      "Epoch 191/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 6.4081 - mae: 6.4081 - mse: 236.7920 - val_loss: 8.1721 - val_mae: 8.1721 - val_mse: 323.8430\n",
      "Epoch 192/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 6.2984 - mae: 6.2984 - mse: 232.2264 - val_loss: 8.1194 - val_mae: 8.1194 - val_mse: 318.7328\n",
      "Epoch 193/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 6.2935 - mae: 6.2935 - mse: 228.7153 - val_loss: 8.1238 - val_mae: 8.1238 - val_mse: 314.4340\n",
      "Epoch 194/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 6.3001 - mae: 6.3001 - mse: 225.3241 - val_loss: 8.0165 - val_mae: 8.0165 - val_mse: 308.5435\n",
      "Epoch 195/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 6.3113 - mae: 6.3113 - mse: 222.0413 - val_loss: 8.1677 - val_mae: 8.1677 - val_mse: 302.9818\n",
      "Epoch 196/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 6.2414 - mae: 6.2414 - mse: 218.6404 - val_loss: 8.0261 - val_mae: 8.0261 - val_mse: 297.9247\n",
      "Epoch 197/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 6.0689 - mae: 6.0689 - mse: 214.6594 - val_loss: 7.7125 - val_mae: 7.7125 - val_mse: 291.8376\n",
      "Epoch 198/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 6.0365 - mae: 6.0365 - mse: 211.6262 - val_loss: 7.6700 - val_mae: 7.6700 - val_mse: 286.4204\n",
      "Epoch 199/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.9873 - mae: 5.9873 - mse: 207.8281 - val_loss: 7.8737 - val_mae: 7.8737 - val_mse: 284.2048\n",
      "Epoch 200/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 5.9447 - mae: 5.9447 - mse: 205.0929 - val_loss: 7.8256 - val_mae: 7.8256 - val_mse: 278.0638\n",
      "Epoch 201/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 5.9785 - mae: 5.9785 - mse: 202.1756 - val_loss: 7.4647 - val_mae: 7.4647 - val_mse: 272.3966\n",
      "Epoch 202/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 5.8878 - mae: 5.8878 - mse: 199.0164 - val_loss: 7.5742 - val_mae: 7.5742 - val_mse: 269.5616\n",
      "Epoch 203/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.8121 - mae: 5.8121 - mse: 196.7443 - val_loss: 7.4115 - val_mae: 7.4115 - val_mse: 264.1946\n",
      "Epoch 204/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 5.8274 - mae: 5.8274 - mse: 193.7205 - val_loss: 7.3481 - val_mae: 7.3481 - val_mse: 260.2798\n",
      "Epoch 205/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 5.9988 - mae: 5.9988 - mse: 192.5367 - val_loss: 7.6570 - val_mae: 7.6570 - val_mse: 257.3155\n",
      "Epoch 206/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 5.7955 - mae: 5.7955 - mse: 188.7914 - val_loss: 7.0980 - val_mae: 7.0980 - val_mse: 251.7839\n",
      "Epoch 207/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.6292 - mae: 5.6292 - mse: 185.3403 - val_loss: 7.1784 - val_mae: 7.1785 - val_mse: 248.1828\n",
      "Epoch 208/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.9663 - mae: 5.9663 - mse: 185.1227 - val_loss: 7.2968 - val_mae: 7.2968 - val_mse: 244.4365\n",
      "Epoch 209/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 5.8058 - mae: 5.8058 - mse: 181.5236 - val_loss: 7.4438 - val_mae: 7.4438 - val_mse: 243.9521\n",
      "Epoch 210/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 5.6071 - mae: 5.6071 - mse: 178.3694 - val_loss: 6.9481 - val_mae: 6.9481 - val_mse: 236.9505\n",
      "Epoch 211/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 5.6120 - mae: 5.6120 - mse: 176.4064 - val_loss: 7.1318 - val_mae: 7.1318 - val_mse: 235.4291\n",
      "Epoch 212/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 5.7125 - mae: 5.7125 - mse: 174.8543 - val_loss: 7.1692 - val_mae: 7.1692 - val_mse: 233.2171\n",
      "Epoch 213/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 5.5217 - mae: 5.5217 - mse: 171.8282 - val_loss: 6.7252 - val_mae: 6.7252 - val_mse: 225.8884\n",
      "Epoch 214/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 5.4372 - mae: 5.4372 - mse: 168.5443 - val_loss: 6.6796 - val_mae: 6.6796 - val_mse: 222.6425\n",
      "Epoch 215/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 5.3756 - mae: 5.3756 - mse: 165.9516 - val_loss: 6.6971 - val_mae: 6.6971 - val_mse: 219.4838\n",
      "Epoch 216/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 5.3556 - mae: 5.3556 - mse: 163.8501 - val_loss: 6.7248 - val_mae: 6.7248 - val_mse: 215.0236\n",
      "Epoch 217/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 5.4468 - mae: 5.4468 - mse: 162.3020 - val_loss: 6.6926 - val_mae: 6.6926 - val_mse: 212.5888\n",
      "Epoch 218/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 5.5177 - mae: 5.5177 - mse: 160.6074 - val_loss: 7.2513 - val_mae: 7.2513 - val_mse: 216.3659\n",
      "Epoch 219/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 5.3750 - mae: 5.3750 - mse: 157.9745 - val_loss: 6.5988 - val_mae: 6.5988 - val_mse: 205.8632\n",
      "Epoch 220/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 5.3229 - mae: 5.3229 - mse: 155.2467 - val_loss: 6.3729 - val_mae: 6.3729 - val_mse: 202.5686\n",
      "Epoch 221/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.3068 - mae: 5.3068 - mse: 153.6528 - val_loss: 6.8530 - val_mae: 6.8530 - val_mse: 200.4113\n",
      "Epoch 222/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 5.3305 - mae: 5.3305 - mse: 151.4775 - val_loss: 6.5331 - val_mae: 6.5331 - val_mse: 198.2696\n",
      "Epoch 223/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 5.2576 - mae: 5.2576 - mse: 149.3084 - val_loss: 6.3197 - val_mae: 6.3197 - val_mse: 194.4259\n",
      "Epoch 224/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 5.1583 - mae: 5.1583 - mse: 147.3123 - val_loss: 6.2219 - val_mae: 6.2219 - val_mse: 189.8980\n",
      "Epoch 225/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.0692 - mae: 5.0692 - mse: 144.4358 - val_loss: 6.5494 - val_mae: 6.5494 - val_mse: 188.0506\n",
      "Epoch 226/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 5.1304 - mae: 5.1304 - mse: 143.1536 - val_loss: 6.1052 - val_mae: 6.1052 - val_mse: 183.9211\n",
      "Epoch 227/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 5.0778 - mae: 5.0778 - mse: 140.6230 - val_loss: 6.1345 - val_mae: 6.1345 - val_mse: 182.8249\n",
      "Epoch 228/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 807us/sample - loss: 5.1746 - mae: 5.1746 - mse: 139.6420 - val_loss: 6.0601 - val_mae: 6.0601 - val_mse: 178.6880\n",
      "Epoch 229/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 4.9829 - mae: 4.9829 - mse: 136.4694 - val_loss: 6.1093 - val_mae: 6.1093 - val_mse: 178.3801\n",
      "Epoch 230/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 5.0020 - mae: 5.0020 - mse: 134.8842 - val_loss: 5.9798 - val_mae: 5.9798 - val_mse: 171.7934\n",
      "Epoch 231/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 5.1187 - mae: 5.1187 - mse: 133.6974 - val_loss: 5.9859 - val_mae: 5.9859 - val_mse: 170.7043\n",
      "Epoch 232/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 4.9189 - mae: 4.9189 - mse: 131.0176 - val_loss: 6.1245 - val_mae: 6.1245 - val_mse: 167.0709\n",
      "Epoch 233/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 4.9491 - mae: 4.9491 - mse: 129.2346 - val_loss: 5.8361 - val_mae: 5.8361 - val_mse: 164.3353\n",
      "Epoch 234/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 4.8827 - mae: 4.8827 - mse: 127.7829 - val_loss: 5.8501 - val_mae: 5.8501 - val_mse: 161.2520\n",
      "Epoch 235/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 5.0213 - mae: 5.0213 - mse: 126.6055 - val_loss: 6.0857 - val_mae: 6.0857 - val_mse: 160.2704\n",
      "Epoch 236/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 4.7905 - mae: 4.7905 - mse: 123.3056 - val_loss: 5.7605 - val_mae: 5.7605 - val_mse: 155.8585\n",
      "Epoch 237/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 4.8007 - mae: 4.8007 - mse: 122.1044 - val_loss: 5.7197 - val_mae: 5.7197 - val_mse: 153.6390\n",
      "Epoch 238/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 4.9112 - mae: 4.9112 - mse: 120.6934 - val_loss: 5.8105 - val_mae: 5.8105 - val_mse: 150.7578\n",
      "Epoch 239/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 4.7115 - mae: 4.7115 - mse: 118.1071 - val_loss: 5.6235 - val_mae: 5.6235 - val_mse: 148.3732\n",
      "Epoch 240/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 4.7333 - mae: 4.7333 - mse: 116.5979 - val_loss: 5.7563 - val_mae: 5.7563 - val_mse: 148.9800\n",
      "Epoch 241/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 4.6806 - mae: 4.6806 - mse: 114.7632 - val_loss: 5.5769 - val_mae: 5.5769 - val_mse: 144.4429\n",
      "Epoch 242/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 4.7452 - mae: 4.7452 - mse: 113.6397 - val_loss: 5.4491 - val_mae: 5.4491 - val_mse: 140.5822\n",
      "Epoch 243/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 4.7026 - mae: 4.7026 - mse: 111.9543 - val_loss: 5.4132 - val_mae: 5.4132 - val_mse: 140.5769\n",
      "Epoch 244/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 4.6037 - mae: 4.6037 - mse: 109.8542 - val_loss: 5.4531 - val_mae: 5.4531 - val_mse: 136.3298\n",
      "Epoch 245/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 4.7373 - mae: 4.7373 - mse: 109.7011 - val_loss: 5.5771 - val_mae: 5.5771 - val_mse: 136.7953\n",
      "Epoch 246/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 4.7034 - mae: 4.7034 - mse: 107.9428 - val_loss: 5.5105 - val_mae: 5.5105 - val_mse: 133.5966\n",
      "Epoch 247/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 4.7028 - mae: 4.7028 - mse: 106.6288 - val_loss: 5.3751 - val_mae: 5.3751 - val_mse: 131.1333\n",
      "Epoch 248/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 4.5927 - mae: 4.5927 - mse: 104.2577 - val_loss: 5.2255 - val_mae: 5.2255 - val_mse: 128.7382\n",
      "Epoch 249/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 4.5269 - mae: 4.5269 - mse: 102.5651 - val_loss: 5.1414 - val_mae: 5.1414 - val_mse: 125.9622\n",
      "Epoch 250/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 4.4640 - mae: 4.4640 - mse: 101.2211 - val_loss: 5.1339 - val_mae: 5.1339 - val_mse: 124.3009\n",
      "Epoch 251/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 4.4123 - mae: 4.4123 - mse: 99.6693 - val_loss: 5.1880 - val_mae: 5.1880 - val_mse: 122.0520\n",
      "Epoch 252/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 4.6264 - mae: 4.6264 - mse: 99.8309 - val_loss: 5.1401 - val_mae: 5.1401 - val_mse: 119.7099\n",
      "Epoch 253/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 4.4890 - mae: 4.4890 - mse: 97.6349 - val_loss: 5.2035 - val_mae: 5.2036 - val_mse: 119.9784\n",
      "Epoch 254/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 4.7205 - mae: 4.7205 - mse: 100.3239 - val_loss: 5.0525 - val_mae: 5.0525 - val_mse: 116.4376\n",
      "Epoch 255/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 4.5152 - mae: 4.5152 - mse: 96.5760 - val_loss: 5.4341 - val_mae: 5.4341 - val_mse: 117.6038\n",
      "Epoch 256/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 4.5154 - mae: 4.5154 - mse: 94.2489 - val_loss: 5.0171 - val_mae: 5.0171 - val_mse: 112.3458\n",
      "Epoch 257/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 4.2720 - mae: 4.2720 - mse: 91.8899 - val_loss: 4.9661 - val_mae: 4.9661 - val_mse: 110.7335\n",
      "Epoch 258/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 4.2569 - mae: 4.2569 - mse: 90.4899 - val_loss: 4.9495 - val_mae: 4.9495 - val_mse: 108.9291\n",
      "Epoch 259/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 4.2470 - mae: 4.2470 - mse: 89.1862 - val_loss: 4.9818 - val_mae: 4.9818 - val_mse: 109.7154\n",
      "Epoch 260/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 4.3061 - mae: 4.3061 - mse: 88.6340 - val_loss: 5.1781 - val_mae: 5.1781 - val_mse: 108.7785\n",
      "Epoch 261/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 4.2308 - mae: 4.2308 - mse: 87.1971 - val_loss: 4.7836 - val_mae: 4.7836 - val_mse: 104.4948\n",
      "Epoch 262/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 4.2519 - mae: 4.2519 - mse: 86.3092 - val_loss: 4.7709 - val_mae: 4.7709 - val_mse: 103.3650\n",
      "Epoch 263/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 4.2449 - mae: 4.2449 - mse: 85.3111 - val_loss: 4.8316 - val_mae: 4.8316 - val_mse: 102.5175\n",
      "Epoch 264/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 4.1617 - mae: 4.1617 - mse: 84.0291 - val_loss: 4.6790 - val_mae: 4.6790 - val_mse: 99.8657\n",
      "Epoch 265/2500\n",
      "684/684 [==============================] - 1s 841us/sample - loss: 4.2068 - mae: 4.2068 - mse: 83.2586 - val_loss: 4.9709 - val_mae: 4.9709 - val_mse: 102.5821\n",
      "Epoch 266/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 4.2685 - mae: 4.2685 - mse: 83.2465 - val_loss: 4.6898 - val_mae: 4.6898 - val_mse: 96.9029\n",
      "Epoch 267/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 4.2061 - mae: 4.2061 - mse: 81.1005 - val_loss: 4.6344 - val_mae: 4.6344 - val_mse: 96.2474\n",
      "Epoch 268/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 4.0943 - mae: 4.0943 - mse: 79.6999 - val_loss: 4.6606 - val_mae: 4.6606 - val_mse: 94.5312\n",
      "Epoch 269/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 4.0630 - mae: 4.0630 - mse: 78.5739 - val_loss: 4.5530 - val_mae: 4.5530 - val_mse: 93.4986\n",
      "Epoch 270/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 4.1013 - mae: 4.1013 - mse: 77.7247 - val_loss: 4.5508 - val_mae: 4.5508 - val_mse: 91.6150\n",
      "Epoch 271/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 4.1080 - mae: 4.1080 - mse: 77.1945 - val_loss: 4.5722 - val_mae: 4.5722 - val_mse: 90.8713\n",
      "Epoch 272/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 4.0052 - mae: 4.0052 - mse: 75.6860 - val_loss: 4.5841 - val_mae: 4.5841 - val_mse: 89.5762\n",
      "Epoch 273/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 4.0114 - mae: 4.0114 - mse: 74.4823 - val_loss: 4.4710 - val_mae: 4.4710 - val_mse: 87.5561\n",
      "Epoch 274/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 4.0103 - mae: 4.0103 - mse: 74.0428 - val_loss: 4.4787 - val_mae: 4.4787 - val_mse: 87.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 4.1873 - mae: 4.1873 - mse: 73.8688 - val_loss: 4.4937 - val_mae: 4.4937 - val_mse: 87.3446\n",
      "Epoch 276/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 4.2502 - mae: 4.2502 - mse: 74.7873 - val_loss: 4.6272 - val_mae: 4.6272 - val_mse: 87.0638\n",
      "Epoch 277/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 4.0726 - mae: 4.0726 - mse: 71.8408 - val_loss: 4.6412 - val_mae: 4.6412 - val_mse: 84.1510\n",
      "Epoch 278/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.9672 - mae: 3.9672 - mse: 70.6321 - val_loss: 4.5155 - val_mae: 4.5155 - val_mse: 84.5596\n",
      "Epoch 279/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.9123 - mae: 3.9123 - mse: 69.4929 - val_loss: 4.3128 - val_mae: 4.3128 - val_mse: 81.1161\n",
      "Epoch 280/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 3.9284 - mae: 3.9284 - mse: 68.7929 - val_loss: 4.5771 - val_mae: 4.5771 - val_mse: 82.6245\n",
      "Epoch 281/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 4.0638 - mae: 4.0638 - mse: 69.1091 - val_loss: 4.6500 - val_mae: 4.6500 - val_mse: 80.8592\n",
      "Epoch 282/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 3.9376 - mae: 3.9376 - mse: 67.5700 - val_loss: 4.3523 - val_mae: 4.3523 - val_mse: 78.1123\n",
      "Epoch 283/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.9114 - mae: 3.9114 - mse: 66.8556 - val_loss: 4.3104 - val_mae: 4.3104 - val_mse: 76.5568\n",
      "Epoch 284/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.9438 - mae: 3.9438 - mse: 65.9297 - val_loss: 4.5556 - val_mae: 4.5556 - val_mse: 80.0247\n",
      "Epoch 285/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.8818 - mae: 3.8818 - mse: 65.1514 - val_loss: 4.3493 - val_mae: 4.3492 - val_mse: 75.6636\n",
      "Epoch 286/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.9535 - mae: 3.9535 - mse: 64.9351 - val_loss: 4.3536 - val_mae: 4.3536 - val_mse: 74.9469\n",
      "Epoch 287/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 3.8972 - mae: 3.8972 - mse: 63.8657 - val_loss: 4.2657 - val_mae: 4.2657 - val_mse: 72.9156\n",
      "Epoch 288/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.8969 - mae: 3.8969 - mse: 63.0443 - val_loss: 4.4150 - val_mae: 4.4150 - val_mse: 73.8271\n",
      "Epoch 289/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.8624 - mae: 3.8624 - mse: 62.5207 - val_loss: 4.2463 - val_mae: 4.2463 - val_mse: 71.6133\n",
      "Epoch 290/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 3.7923 - mae: 3.7923 - mse: 61.5628 - val_loss: 4.2330 - val_mae: 4.2330 - val_mse: 69.8782\n",
      "Epoch 291/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 3.8190 - mae: 3.8190 - mse: 60.7304 - val_loss: 4.3032 - val_mae: 4.3032 - val_mse: 69.3420\n",
      "Epoch 292/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.8135 - mae: 3.8135 - mse: 60.3283 - val_loss: 4.3015 - val_mae: 4.3015 - val_mse: 70.6413\n",
      "Epoch 293/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.8055 - mae: 3.8055 - mse: 59.5952 - val_loss: 4.1237 - val_mae: 4.1237 - val_mse: 67.9139\n",
      "Epoch 294/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.8227 - mae: 3.8227 - mse: 58.9769 - val_loss: 4.4317 - val_mae: 4.4317 - val_mse: 69.7393\n",
      "Epoch 295/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.7838 - mae: 3.7838 - mse: 58.4042 - val_loss: 4.0492 - val_mae: 4.0492 - val_mse: 65.7002\n",
      "Epoch 296/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 4.0178 - mae: 4.0178 - mse: 59.6358 - val_loss: 4.1182 - val_mae: 4.1182 - val_mse: 64.7631\n",
      "Epoch 297/2500\n",
      "684/684 [==============================] - 1s 842us/sample - loss: 3.7387 - mae: 3.7387 - mse: 57.1142 - val_loss: 4.1346 - val_mae: 4.1346 - val_mse: 64.8321\n",
      "Epoch 298/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.7219 - mae: 3.7219 - mse: 56.4188 - val_loss: 4.1718 - val_mae: 4.1718 - val_mse: 62.9532\n",
      "Epoch 299/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.6955 - mae: 3.6955 - mse: 55.5834 - val_loss: 3.9404 - val_mae: 3.9404 - val_mse: 61.9575\n",
      "Epoch 300/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.6642 - mae: 3.6642 - mse: 54.6691 - val_loss: 4.0698 - val_mae: 4.0698 - val_mse: 61.6637\n",
      "Epoch 301/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.6869 - mae: 3.6869 - mse: 54.7723 - val_loss: 4.0216 - val_mae: 4.0216 - val_mse: 62.2705\n",
      "Epoch 302/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.6388 - mae: 3.6388 - mse: 53.8023 - val_loss: 3.8850 - val_mae: 3.8850 - val_mse: 60.4811\n",
      "Epoch 303/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.6115 - mae: 3.6115 - mse: 53.2040 - val_loss: 3.9012 - val_mae: 3.9012 - val_mse: 59.0078\n",
      "Epoch 304/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.6572 - mae: 3.6572 - mse: 52.9820 - val_loss: 3.8947 - val_mae: 3.8947 - val_mse: 58.9936\n",
      "Epoch 305/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.6174 - mae: 3.6174 - mse: 52.0186 - val_loss: 3.8718 - val_mae: 3.8718 - val_mse: 57.6265\n",
      "Epoch 306/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.6974 - mae: 3.6974 - mse: 52.0974 - val_loss: 3.8497 - val_mae: 3.8497 - val_mse: 56.6134\n",
      "Epoch 307/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 3.5677 - mae: 3.5677 - mse: 50.6601 - val_loss: 3.8595 - val_mae: 3.8595 - val_mse: 56.3398\n",
      "Epoch 308/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.6193 - mae: 3.6193 - mse: 50.8677 - val_loss: 3.8528 - val_mae: 3.8528 - val_mse: 55.2439\n",
      "Epoch 309/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.5664 - mae: 3.5664 - mse: 49.9052 - val_loss: 3.8692 - val_mae: 3.8692 - val_mse: 55.3510\n",
      "Epoch 310/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.5257 - mae: 3.5257 - mse: 49.0074 - val_loss: 3.8028 - val_mae: 3.8028 - val_mse: 53.6554\n",
      "Epoch 311/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.5719 - mae: 3.5719 - mse: 48.9896 - val_loss: 4.0773 - val_mae: 4.0773 - val_mse: 57.7484\n",
      "Epoch 312/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.6174 - mae: 3.6174 - mse: 48.9199 - val_loss: 3.9295 - val_mae: 3.9295 - val_mse: 55.4866\n",
      "Epoch 313/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.5194 - mae: 3.5194 - mse: 47.6678 - val_loss: 3.7892 - val_mae: 3.7892 - val_mse: 51.9444\n",
      "Epoch 314/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.6552 - mae: 3.6552 - mse: 47.7054 - val_loss: 3.9060 - val_mae: 3.9060 - val_mse: 53.9204\n",
      "Epoch 315/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.5720 - mae: 3.5720 - mse: 47.4929 - val_loss: 3.6831 - val_mae: 3.6831 - val_mse: 50.5036\n",
      "Epoch 316/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.4507 - mae: 3.4507 - mse: 45.9266 - val_loss: 3.6780 - val_mae: 3.6780 - val_mse: 50.4643\n",
      "Epoch 317/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.4489 - mae: 3.4489 - mse: 45.5385 - val_loss: 3.7912 - val_mae: 3.7912 - val_mse: 49.8716\n",
      "Epoch 318/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 3.6017 - mae: 3.6017 - mse: 46.0426 - val_loss: 3.6825 - val_mae: 3.6825 - val_mse: 50.1787\n",
      "Epoch 319/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 3.4462 - mae: 3.4462 - mse: 44.6579 - val_loss: 3.6587 - val_mae: 3.6587 - val_mse: 48.8164\n",
      "Epoch 320/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.4898 - mae: 3.4898 - mse: 44.4167 - val_loss: 3.6725 - val_mae: 3.6725 - val_mse: 48.5570\n",
      "Epoch 321/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.4323 - mae: 3.4323 - mse: 43.4955 - val_loss: 3.7915 - val_mae: 3.7915 - val_mse: 47.8296\n",
      "Epoch 322/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 809us/sample - loss: 3.4374 - mae: 3.4374 - mse: 43.3228 - val_loss: 3.7569 - val_mae: 3.7569 - val_mse: 46.8917\n",
      "Epoch 323/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.4229 - mae: 3.4229 - mse: 42.6788 - val_loss: 3.8092 - val_mae: 3.8092 - val_mse: 48.3559\n",
      "Epoch 324/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 3.5834 - mae: 3.5834 - mse: 43.7112 - val_loss: 3.8266 - val_mae: 3.8266 - val_mse: 48.4508\n",
      "Epoch 325/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.4507 - mae: 3.4507 - mse: 42.4415 - val_loss: 3.5217 - val_mae: 3.5217 - val_mse: 44.5135\n",
      "Epoch 326/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.4214 - mae: 3.4214 - mse: 41.5582 - val_loss: 3.6601 - val_mae: 3.6601 - val_mse: 45.0961\n",
      "Epoch 327/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 3.5001 - mae: 3.5001 - mse: 42.1880 - val_loss: 3.6575 - val_mae: 3.6575 - val_mse: 45.1258\n",
      "Epoch 328/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.4604 - mae: 3.4604 - mse: 41.4367 - val_loss: 3.5505 - val_mae: 3.5505 - val_mse: 45.0220\n",
      "Epoch 329/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 3.4185 - mae: 3.4185 - mse: 40.4580 - val_loss: 3.6469 - val_mae: 3.6469 - val_mse: 43.4237\n",
      "Epoch 330/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 3.4296 - mae: 3.4296 - mse: 40.5473 - val_loss: 3.7419 - val_mae: 3.7419 - val_mse: 47.3317\n",
      "Epoch 331/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 3.3268 - mae: 3.3268 - mse: 39.4420 - val_loss: 3.5873 - val_mae: 3.5873 - val_mse: 42.7006\n",
      "Epoch 332/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 3.4670 - mae: 3.4670 - mse: 39.8086 - val_loss: 3.6681 - val_mae: 3.6681 - val_mse: 43.0477\n",
      "Epoch 333/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.3735 - mae: 3.3735 - mse: 38.9337 - val_loss: 3.5740 - val_mae: 3.5740 - val_mse: 40.8250\n",
      "Epoch 334/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.3096 - mae: 3.3096 - mse: 38.0863 - val_loss: 3.4274 - val_mae: 3.4274 - val_mse: 40.6293\n",
      "Epoch 335/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.3356 - mae: 3.3356 - mse: 38.0509 - val_loss: 3.4055 - val_mae: 3.4055 - val_mse: 39.8127\n",
      "Epoch 336/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 3.3027 - mae: 3.3027 - mse: 37.4359 - val_loss: 3.4563 - val_mae: 3.4563 - val_mse: 39.4764\n",
      "Epoch 337/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.3520 - mae: 3.3520 - mse: 37.4492 - val_loss: 3.6655 - val_mae: 3.6655 - val_mse: 41.9825\n",
      "Epoch 338/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.2970 - mae: 3.2970 - mse: 36.7836 - val_loss: 3.5173 - val_mae: 3.5173 - val_mse: 39.2655\n",
      "Epoch 339/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.3122 - mae: 3.3122 - mse: 36.6201 - val_loss: 3.5524 - val_mae: 3.5524 - val_mse: 38.6211\n",
      "Epoch 340/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 3.2918 - mae: 3.2918 - mse: 36.1747 - val_loss: 3.4075 - val_mae: 3.4075 - val_mse: 38.8420\n",
      "Epoch 341/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.3736 - mae: 3.3736 - mse: 36.2983 - val_loss: 3.5983 - val_mae: 3.5983 - val_mse: 38.0096\n",
      "Epoch 342/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.2550 - mae: 3.2550 - mse: 35.2542 - val_loss: 3.3765 - val_mae: 3.3765 - val_mse: 37.5310\n",
      "Epoch 343/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.2872 - mae: 3.2872 - mse: 35.2008 - val_loss: 3.3653 - val_mae: 3.3653 - val_mse: 36.3229\n",
      "Epoch 344/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.3398 - mae: 3.3398 - mse: 35.1662 - val_loss: 3.6015 - val_mae: 3.6015 - val_mse: 42.8944\n",
      "Epoch 345/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 3.2430 - mae: 3.2430 - mse: 34.5887 - val_loss: 3.3042 - val_mae: 3.3042 - val_mse: 35.9871\n",
      "Epoch 346/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.2606 - mae: 3.2606 - mse: 34.3359 - val_loss: 3.3110 - val_mae: 3.3110 - val_mse: 36.0330\n",
      "Epoch 347/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.2478 - mae: 3.2478 - mse: 34.0504 - val_loss: 3.3016 - val_mae: 3.3016 - val_mse: 35.0087\n",
      "Epoch 348/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 3.1773 - mae: 3.1773 - mse: 33.1382 - val_loss: 3.3409 - val_mae: 3.3409 - val_mse: 35.5820\n",
      "Epoch 349/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.2974 - mae: 3.2974 - mse: 33.8209 - val_loss: 3.6182 - val_mae: 3.6182 - val_mse: 36.4068\n",
      "Epoch 350/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 3.3073 - mae: 3.3073 - mse: 33.8136 - val_loss: 3.3215 - val_mae: 3.3215 - val_mse: 34.5448\n",
      "Epoch 351/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 3.1474 - mae: 3.1474 - mse: 32.0518 - val_loss: 3.3039 - val_mae: 3.3039 - val_mse: 33.5841\n",
      "Epoch 352/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 3.2101 - mae: 3.2101 - mse: 32.2565 - val_loss: 3.2501 - val_mae: 3.2501 - val_mse: 32.9988\n",
      "Epoch 353/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 3.2494 - mae: 3.2494 - mse: 32.3739 - val_loss: 3.2787 - val_mae: 3.2787 - val_mse: 33.9187\n",
      "Epoch 354/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 3.1613 - mae: 3.1613 - mse: 31.3529 - val_loss: 3.2531 - val_mae: 3.2531 - val_mse: 33.1078\n",
      "Epoch 355/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.3300 - mae: 3.3300 - mse: 32.4643 - val_loss: 3.6091 - val_mae: 3.6091 - val_mse: 36.8305\n",
      "Epoch 356/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.2097 - mae: 3.2097 - mse: 31.3637 - val_loss: 3.2161 - val_mae: 3.2161 - val_mse: 32.4606\n",
      "Epoch 357/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 3.1359 - mae: 3.1359 - mse: 30.5716 - val_loss: 3.2093 - val_mae: 3.2093 - val_mse: 31.4488\n",
      "Epoch 358/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.1628 - mae: 3.1628 - mse: 30.7205 - val_loss: 3.3233 - val_mae: 3.3233 - val_mse: 32.0771\n",
      "Epoch 359/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.1721 - mae: 3.1721 - mse: 30.3675 - val_loss: 3.3073 - val_mae: 3.3073 - val_mse: 31.9860\n",
      "Epoch 360/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.1240 - mae: 3.1240 - mse: 29.9322 - val_loss: 3.2038 - val_mae: 3.2038 - val_mse: 30.5323\n",
      "Epoch 361/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.1149 - mae: 3.1149 - mse: 29.7626 - val_loss: 3.2072 - val_mae: 3.2072 - val_mse: 30.7351\n",
      "Epoch 362/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.2570 - mae: 3.2570 - mse: 30.0843 - val_loss: 3.5962 - val_mae: 3.5962 - val_mse: 32.1402\n",
      "Epoch 363/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 3.1389 - mae: 3.1389 - mse: 29.3744 - val_loss: 3.1922 - val_mae: 3.1922 - val_mse: 30.7880\n",
      "Epoch 364/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.1443 - mae: 3.1443 - mse: 29.1683 - val_loss: 3.3327 - val_mae: 3.3327 - val_mse: 29.5967\n",
      "Epoch 365/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.1298 - mae: 3.1298 - mse: 28.7726 - val_loss: 3.1165 - val_mae: 3.1165 - val_mse: 29.3847\n",
      "Epoch 366/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 3.0397 - mae: 3.0397 - mse: 28.0661 - val_loss: 3.1196 - val_mae: 3.1196 - val_mse: 29.4942\n",
      "Epoch 367/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.0959 - mae: 3.0959 - mse: 28.1463 - val_loss: 3.1061 - val_mae: 3.1061 - val_mse: 28.6894\n",
      "Epoch 368/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.1605 - mae: 3.1605 - mse: 28.4787 - val_loss: 3.3479 - val_mae: 3.3479 - val_mse: 30.2488\n",
      "Epoch 369/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 808us/sample - loss: 3.1263 - mae: 3.1263 - mse: 28.0859 - val_loss: 3.2325 - val_mae: 3.2325 - val_mse: 28.9017\n",
      "Epoch 370/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 3.1453 - mae: 3.1453 - mse: 27.9658 - val_loss: 3.2490 - val_mae: 3.2490 - val_mse: 29.3061\n",
      "Epoch 371/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 3.1264 - mae: 3.1264 - mse: 27.5860 - val_loss: 3.1986 - val_mae: 3.1986 - val_mse: 29.4262\n",
      "Epoch 372/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 3.1861 - mae: 3.1861 - mse: 28.0566 - val_loss: 3.1414 - val_mae: 3.1414 - val_mse: 28.8767\n",
      "Epoch 373/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 3.1059 - mae: 3.1059 - mse: 27.0550 - val_loss: 3.2831 - val_mae: 3.2831 - val_mse: 28.3139\n",
      "Epoch 374/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.0260 - mae: 3.0260 - mse: 26.5207 - val_loss: 3.1290 - val_mae: 3.1290 - val_mse: 27.0219\n",
      "Epoch 375/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.0556 - mae: 3.0556 - mse: 26.2838 - val_loss: 3.1020 - val_mae: 3.1020 - val_mse: 27.6766\n",
      "Epoch 376/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.9881 - mae: 2.9881 - mse: 25.8999 - val_loss: 3.0303 - val_mae: 3.0303 - val_mse: 26.3787\n",
      "Epoch 377/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 3.1836 - mae: 3.1836 - mse: 26.8215 - val_loss: 3.1449 - val_mae: 3.1449 - val_mse: 27.4892\n",
      "Epoch 378/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 3.1414 - mae: 3.1414 - mse: 26.6049 - val_loss: 3.1833 - val_mae: 3.1833 - val_mse: 27.6010\n",
      "Epoch 379/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.9756 - mae: 2.9756 - mse: 25.1450 - val_loss: 3.0681 - val_mae: 3.0681 - val_mse: 26.2126\n",
      "Epoch 380/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 3.0007 - mae: 3.0007 - mse: 25.5193 - val_loss: 3.0712 - val_mae: 3.0712 - val_mse: 26.3878\n",
      "Epoch 381/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 3.0452 - mae: 3.0452 - mse: 25.4293 - val_loss: 3.0352 - val_mae: 3.0352 - val_mse: 25.3514\n",
      "Epoch 382/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.9479 - mae: 2.9479 - mse: 24.5803 - val_loss: 3.0579 - val_mae: 3.0579 - val_mse: 25.1518\n",
      "Epoch 383/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.0476 - mae: 3.0476 - mse: 25.1899 - val_loss: 3.2751 - val_mae: 3.2751 - val_mse: 25.9310\n",
      "Epoch 384/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.9713 - mae: 2.9713 - mse: 24.5909 - val_loss: 2.9740 - val_mae: 2.9740 - val_mse: 24.6687\n",
      "Epoch 385/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.9763 - mae: 2.9763 - mse: 24.4868 - val_loss: 3.0828 - val_mae: 3.0828 - val_mse: 26.4205\n",
      "Epoch 386/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 3.0270 - mae: 3.0270 - mse: 24.3354 - val_loss: 3.1854 - val_mae: 3.1854 - val_mse: 28.9401\n",
      "Epoch 387/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 3.0294 - mae: 3.0294 - mse: 24.5612 - val_loss: 3.0312 - val_mae: 3.0312 - val_mse: 24.5946\n",
      "Epoch 388/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 3.0589 - mae: 3.0589 - mse: 24.6930 - val_loss: 3.0913 - val_mae: 3.0913 - val_mse: 24.3862\n",
      "Epoch 389/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 3.0912 - mae: 3.0912 - mse: 24.7515 - val_loss: 3.1162 - val_mae: 3.1162 - val_mse: 26.0086\n",
      "Epoch 390/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 3.0286 - mae: 3.0286 - mse: 24.2437 - val_loss: 3.3200 - val_mae: 3.3200 - val_mse: 29.1346\n",
      "Epoch 391/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 3.0372 - mae: 3.0372 - mse: 24.0150 - val_loss: 3.1832 - val_mae: 3.1832 - val_mse: 25.8163\n",
      "Epoch 392/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.9790 - mae: 2.9790 - mse: 23.3183 - val_loss: 2.9703 - val_mae: 2.9703 - val_mse: 23.5913\n",
      "Epoch 393/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.9688 - mae: 2.9688 - mse: 23.0804 - val_loss: 3.0847 - val_mae: 3.0847 - val_mse: 24.1832\n",
      "Epoch 394/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.9174 - mae: 2.9174 - mse: 22.7495 - val_loss: 3.1729 - val_mae: 3.1729 - val_mse: 23.9771\n",
      "Epoch 395/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.9593 - mae: 2.9593 - mse: 22.9440 - val_loss: 3.0796 - val_mae: 3.0796 - val_mse: 23.7339\n",
      "Epoch 396/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.8699 - mae: 2.8699 - mse: 22.1259 - val_loss: 2.9630 - val_mae: 2.9630 - val_mse: 22.6191\n",
      "Epoch 397/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.9082 - mae: 2.9082 - mse: 22.1604 - val_loss: 2.9617 - val_mae: 2.9617 - val_mse: 23.9424\n",
      "Epoch 398/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 3.0064 - mae: 3.0064 - mse: 22.8253 - val_loss: 3.0220 - val_mae: 3.0220 - val_mse: 23.4329\n",
      "Epoch 399/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.9514 - mae: 2.9514 - mse: 22.4648 - val_loss: 2.9973 - val_mae: 2.9973 - val_mse: 24.0759\n",
      "Epoch 400/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.8801 - mae: 2.8801 - mse: 21.7763 - val_loss: 2.8792 - val_mae: 2.8792 - val_mse: 21.9613\n",
      "Epoch 401/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.8467 - mae: 2.8467 - mse: 21.4731 - val_loss: 2.9596 - val_mae: 2.9596 - val_mse: 22.3210\n",
      "Epoch 402/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.9455 - mae: 2.9455 - mse: 21.7189 - val_loss: 2.9850 - val_mae: 2.9850 - val_mse: 22.7894\n",
      "Epoch 403/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.9506 - mae: 2.9506 - mse: 22.1386 - val_loss: 2.9237 - val_mae: 2.9237 - val_mse: 22.8789\n",
      "Epoch 404/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.8703 - mae: 2.8703 - mse: 21.3967 - val_loss: 2.9840 - val_mae: 2.9840 - val_mse: 22.3154\n",
      "Epoch 405/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.8156 - mae: 2.8156 - mse: 20.7254 - val_loss: 2.9196 - val_mae: 2.9196 - val_mse: 21.2738\n",
      "Epoch 406/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.8641 - mae: 2.8641 - mse: 20.9197 - val_loss: 2.9126 - val_mae: 2.9126 - val_mse: 21.4122\n",
      "Epoch 407/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.9098 - mae: 2.9098 - mse: 21.1714 - val_loss: 2.9058 - val_mae: 2.9058 - val_mse: 20.9818\n",
      "Epoch 408/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.8364 - mae: 2.8364 - mse: 20.5870 - val_loss: 2.8753 - val_mae: 2.8753 - val_mse: 21.5846\n",
      "Epoch 409/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.8881 - mae: 2.8881 - mse: 20.6588 - val_loss: 2.9726 - val_mae: 2.9726 - val_mse: 21.9560\n",
      "Epoch 410/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.8538 - mae: 2.8538 - mse: 20.5777 - val_loss: 2.9456 - val_mae: 2.9456 - val_mse: 21.4835\n",
      "Epoch 411/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.9229 - mae: 2.9229 - mse: 20.7993 - val_loss: 2.9739 - val_mae: 2.9739 - val_mse: 20.8328\n",
      "Epoch 412/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.8475 - mae: 2.8475 - mse: 20.2719 - val_loss: 3.0122 - val_mae: 3.0122 - val_mse: 21.6584\n",
      "Epoch 413/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.8270 - mae: 2.8270 - mse: 20.0067 - val_loss: 3.2717 - val_mae: 3.2717 - val_mse: 22.2570\n",
      "Epoch 414/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.9207 - mae: 2.9207 - mse: 20.8370 - val_loss: 2.8888 - val_mae: 2.8888 - val_mse: 20.2877\n",
      "Epoch 415/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.9936 - mae: 2.9936 - mse: 21.3220 - val_loss: 3.4071 - val_mae: 3.4071 - val_mse: 26.3906\n",
      "Epoch 416/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 809us/sample - loss: 2.9756 - mae: 2.9756 - mse: 21.3835 - val_loss: 2.8577 - val_mae: 2.8577 - val_mse: 20.3273\n",
      "Epoch 417/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.8865 - mae: 2.8865 - mse: 19.8770 - val_loss: 2.9592 - val_mae: 2.9592 - val_mse: 22.6362\n",
      "Epoch 418/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.8256 - mae: 2.8256 - mse: 19.5879 - val_loss: 2.8509 - val_mae: 2.8509 - val_mse: 20.2623\n",
      "Epoch 419/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.8083 - mae: 2.8083 - mse: 19.3050 - val_loss: 2.8455 - val_mae: 2.8455 - val_mse: 19.3361\n",
      "Epoch 420/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.8607 - mae: 2.8607 - mse: 19.5261 - val_loss: 3.0897 - val_mae: 3.0897 - val_mse: 20.5445\n",
      "Epoch 421/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.9051 - mae: 2.9051 - mse: 19.5775 - val_loss: 2.9722 - val_mae: 2.9722 - val_mse: 22.2983\n",
      "Epoch 422/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.7951 - mae: 2.7951 - mse: 19.0056 - val_loss: 2.8225 - val_mae: 2.8225 - val_mse: 19.4340\n",
      "Epoch 423/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.8334 - mae: 2.8334 - mse: 19.3817 - val_loss: 2.8928 - val_mae: 2.8928 - val_mse: 20.9979\n",
      "Epoch 424/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.8220 - mae: 2.8220 - mse: 19.1037 - val_loss: 2.8007 - val_mae: 2.8007 - val_mse: 19.0708\n",
      "Epoch 425/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.8857 - mae: 2.8857 - mse: 20.0161 - val_loss: 3.0200 - val_mae: 3.0200 - val_mse: 19.9091\n",
      "Epoch 426/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.7699 - mae: 2.7699 - mse: 18.5361 - val_loss: 2.8416 - val_mae: 2.8416 - val_mse: 19.6366\n",
      "Epoch 427/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.7688 - mae: 2.7688 - mse: 18.5163 - val_loss: 2.8698 - val_mae: 2.8698 - val_mse: 19.3185\n",
      "Epoch 428/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.8572 - mae: 2.8572 - mse: 19.0728 - val_loss: 2.8226 - val_mae: 2.8226 - val_mse: 19.0988\n",
      "Epoch 429/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.7923 - mae: 2.7923 - mse: 18.5590 - val_loss: 2.9283 - val_mae: 2.9283 - val_mse: 18.9997\n",
      "Epoch 430/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.8022 - mae: 2.8022 - mse: 18.3724 - val_loss: 2.9304 - val_mae: 2.9304 - val_mse: 20.4923\n",
      "Epoch 431/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.8352 - mae: 2.8352 - mse: 18.7990 - val_loss: 3.0392 - val_mae: 3.0392 - val_mse: 19.3803\n",
      "Epoch 432/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.7610 - mae: 2.7610 - mse: 17.9621 - val_loss: 2.8303 - val_mae: 2.8303 - val_mse: 18.4046\n",
      "Epoch 433/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.7956 - mae: 2.7956 - mse: 17.9474 - val_loss: 3.1660 - val_mae: 3.1660 - val_mse: 22.2919\n",
      "Epoch 434/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.7873 - mae: 2.7873 - mse: 18.1593 - val_loss: 2.7920 - val_mae: 2.7920 - val_mse: 18.2150\n",
      "Epoch 435/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.7927 - mae: 2.7927 - mse: 18.0758 - val_loss: 3.0454 - val_mae: 3.0454 - val_mse: 19.0040\n",
      "Epoch 436/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.7752 - mae: 2.7752 - mse: 18.0000 - val_loss: 2.7486 - val_mae: 2.7486 - val_mse: 18.0217\n",
      "Epoch 437/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.7057 - mae: 2.7057 - mse: 17.4092 - val_loss: 2.8066 - val_mae: 2.8066 - val_mse: 18.7358\n",
      "Epoch 438/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.8015 - mae: 2.8015 - mse: 17.8653 - val_loss: 2.8080 - val_mae: 2.8080 - val_mse: 18.2671\n",
      "Epoch 439/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.7796 - mae: 2.7796 - mse: 18.0114 - val_loss: 2.8794 - val_mae: 2.8794 - val_mse: 19.1974\n",
      "Epoch 440/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.7682 - mae: 2.7682 - mse: 17.9646 - val_loss: 2.8071 - val_mae: 2.8071 - val_mse: 18.0015\n",
      "Epoch 441/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.7014 - mae: 2.7014 - mse: 17.0871 - val_loss: 2.9472 - val_mae: 2.9472 - val_mse: 18.4637\n",
      "Epoch 442/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.7025 - mae: 2.7025 - mse: 17.1719 - val_loss: 2.8244 - val_mae: 2.8244 - val_mse: 18.7249\n",
      "Epoch 443/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.8160 - mae: 2.8160 - mse: 18.0009 - val_loss: 2.7937 - val_mae: 2.7937 - val_mse: 19.5387\n",
      "Epoch 444/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.7112 - mae: 2.7112 - mse: 17.1967 - val_loss: 2.9656 - val_mae: 2.9656 - val_mse: 18.4517\n",
      "Epoch 445/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.7074 - mae: 2.7074 - mse: 17.1667 - val_loss: 2.7265 - val_mae: 2.7265 - val_mse: 17.5582\n",
      "Epoch 446/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.7641 - mae: 2.7641 - mse: 17.1604 - val_loss: 2.8186 - val_mae: 2.8186 - val_mse: 17.8553\n",
      "Epoch 447/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.8180 - mae: 2.8180 - mse: 18.2526 - val_loss: 2.9922 - val_mae: 2.9922 - val_mse: 21.1059\n",
      "Epoch 448/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.8033 - mae: 2.8033 - mse: 17.6687 - val_loss: 3.0553 - val_mae: 3.0553 - val_mse: 18.3154\n",
      "Epoch 449/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.7273 - mae: 2.7273 - mse: 16.9664 - val_loss: 2.7344 - val_mae: 2.7344 - val_mse: 17.6938\n",
      "Epoch 450/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.8043 - mae: 2.8043 - mse: 17.4448 - val_loss: 2.7771 - val_mae: 2.7771 - val_mse: 18.2379\n",
      "Epoch 451/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.7035 - mae: 2.7035 - mse: 16.7402 - val_loss: 2.8571 - val_mae: 2.8571 - val_mse: 17.8482\n",
      "Epoch 452/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.7711 - mae: 2.7711 - mse: 17.1452 - val_loss: 2.8346 - val_mae: 2.8346 - val_mse: 18.8282\n",
      "Epoch 453/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.7075 - mae: 2.7075 - mse: 16.5939 - val_loss: 2.7226 - val_mae: 2.7226 - val_mse: 17.7574\n",
      "Epoch 454/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.6728 - mae: 2.6728 - mse: 16.3894 - val_loss: 2.8138 - val_mae: 2.8138 - val_mse: 16.9801\n",
      "Epoch 455/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.6943 - mae: 2.6943 - mse: 16.4915 - val_loss: 2.7142 - val_mae: 2.7142 - val_mse: 17.8865\n",
      "Epoch 456/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.6639 - mae: 2.6639 - mse: 16.2738 - val_loss: 2.8302 - val_mae: 2.8302 - val_mse: 17.4378\n",
      "Epoch 457/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.7407 - mae: 2.7407 - mse: 16.7230 - val_loss: 2.7764 - val_mae: 2.7764 - val_mse: 17.9985\n",
      "Epoch 458/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.8572 - mae: 2.8572 - mse: 17.7272 - val_loss: 2.8292 - val_mae: 2.8292 - val_mse: 17.9749\n",
      "Epoch 459/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.7022 - mae: 2.7022 - mse: 16.5927 - val_loss: 2.8895 - val_mae: 2.8895 - val_mse: 17.2796\n",
      "Epoch 460/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.7554 - mae: 2.7554 - mse: 17.1853 - val_loss: 2.9994 - val_mae: 2.9994 - val_mse: 20.3785\n",
      "Epoch 461/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.6990 - mae: 2.6990 - mse: 16.8379 - val_loss: 2.7450 - val_mae: 2.7450 - val_mse: 18.0127\n",
      "Epoch 462/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.6982 - mae: 2.6982 - mse: 16.4492 - val_loss: 2.7487 - val_mae: 2.7487 - val_mse: 18.7900\n",
      "Epoch 463/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 812us/sample - loss: 2.6377 - mae: 2.6377 - mse: 15.7913 - val_loss: 2.7676 - val_mae: 2.7676 - val_mse: 17.2420\n",
      "Epoch 464/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.7002 - mae: 2.7002 - mse: 16.1226 - val_loss: 2.7968 - val_mae: 2.7968 - val_mse: 19.3135\n",
      "Epoch 465/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.5847 - mae: 2.5847 - mse: 15.4729 - val_loss: 2.7635 - val_mae: 2.7635 - val_mse: 16.5296\n",
      "Epoch 466/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.6261 - mae: 2.6261 - mse: 15.7791 - val_loss: 2.7228 - val_mae: 2.7228 - val_mse: 16.4865\n",
      "Epoch 467/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.6035 - mae: 2.6035 - mse: 15.6574 - val_loss: 2.6662 - val_mae: 2.6662 - val_mse: 16.2930\n",
      "Epoch 468/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.6433 - mae: 2.6433 - mse: 15.8192 - val_loss: 2.7262 - val_mae: 2.7262 - val_mse: 16.8545\n",
      "Epoch 469/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.6977 - mae: 2.6977 - mse: 16.0524 - val_loss: 3.0975 - val_mae: 3.0975 - val_mse: 22.9872\n",
      "Epoch 470/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.6957 - mae: 2.6957 - mse: 16.1806 - val_loss: 2.7894 - val_mae: 2.7894 - val_mse: 16.9264\n",
      "Epoch 471/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.6506 - mae: 2.6506 - mse: 15.6653 - val_loss: 2.7100 - val_mae: 2.7100 - val_mse: 16.1747\n",
      "Epoch 472/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.7487 - mae: 2.7487 - mse: 16.3060 - val_loss: 2.9578 - val_mae: 2.9578 - val_mse: 19.1649\n",
      "Epoch 473/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.7938 - mae: 2.7938 - mse: 16.5096 - val_loss: 2.8299 - val_mae: 2.8299 - val_mse: 16.9695\n",
      "Epoch 474/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.8050 - mae: 2.8050 - mse: 16.6935 - val_loss: 2.7233 - val_mae: 2.7233 - val_mse: 16.6201\n",
      "Epoch 475/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.6271 - mae: 2.6271 - mse: 15.5657 - val_loss: 2.7073 - val_mae: 2.7073 - val_mse: 16.0414\n",
      "Epoch 476/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.6387 - mae: 2.6387 - mse: 15.4794 - val_loss: 2.7259 - val_mae: 2.7259 - val_mse: 16.6616\n",
      "Epoch 477/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.6643 - mae: 2.6643 - mse: 15.6210 - val_loss: 2.6875 - val_mae: 2.6875 - val_mse: 16.1447\n",
      "Epoch 478/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.6443 - mae: 2.6443 - mse: 15.1866 - val_loss: 2.8285 - val_mae: 2.8285 - val_mse: 16.1106\n",
      "Epoch 479/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.6016 - mae: 2.6016 - mse: 15.1311 - val_loss: 2.6285 - val_mae: 2.6285 - val_mse: 16.2930\n",
      "Epoch 480/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.6060 - mae: 2.6060 - mse: 15.2212 - val_loss: 2.6519 - val_mae: 2.6519 - val_mse: 15.9648\n",
      "Epoch 481/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.6225 - mae: 2.6225 - mse: 15.0446 - val_loss: 2.6958 - val_mae: 2.6958 - val_mse: 16.1451\n",
      "Epoch 482/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.6308 - mae: 2.6308 - mse: 15.1544 - val_loss: 2.9727 - val_mae: 2.9727 - val_mse: 16.9855\n",
      "Epoch 483/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.6397 - mae: 2.6397 - mse: 15.1538 - val_loss: 2.9309 - val_mae: 2.9309 - val_mse: 17.6158\n",
      "Epoch 484/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.7175 - mae: 2.7175 - mse: 15.8427 - val_loss: 2.6296 - val_mae: 2.6296 - val_mse: 16.0889\n",
      "Epoch 485/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.5851 - mae: 2.5851 - mse: 14.8161 - val_loss: 2.7772 - val_mae: 2.7772 - val_mse: 16.3177\n",
      "Epoch 486/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5768 - mae: 2.5768 - mse: 14.7978 - val_loss: 2.6211 - val_mae: 2.6211 - val_mse: 16.0708\n",
      "Epoch 487/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.5970 - mae: 2.5970 - mse: 14.8679 - val_loss: 2.6897 - val_mae: 2.6897 - val_mse: 16.4202\n",
      "Epoch 488/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.6436 - mae: 2.6436 - mse: 15.1172 - val_loss: 2.9154 - val_mae: 2.9154 - val_mse: 17.3531\n",
      "Epoch 489/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.6251 - mae: 2.6251 - mse: 15.0580 - val_loss: 2.6546 - val_mae: 2.6546 - val_mse: 15.9267\n",
      "Epoch 490/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.5854 - mae: 2.5854 - mse: 14.6311 - val_loss: 3.1056 - val_mae: 3.1056 - val_mse: 17.3678\n",
      "Epoch 491/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.7058 - mae: 2.7058 - mse: 15.6424 - val_loss: 2.7644 - val_mae: 2.7644 - val_mse: 17.6831\n",
      "Epoch 492/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.6815 - mae: 2.6815 - mse: 15.3691 - val_loss: 2.7391 - val_mae: 2.7391 - val_mse: 16.5787\n",
      "Epoch 493/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.6779 - mae: 2.6779 - mse: 15.4528 - val_loss: 2.6858 - val_mae: 2.6858 - val_mse: 16.9440\n",
      "Epoch 494/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.5465 - mae: 2.5465 - mse: 14.4879 - val_loss: 2.6063 - val_mae: 2.6063 - val_mse: 16.0212\n",
      "Epoch 495/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.5660 - mae: 2.5660 - mse: 14.5729 - val_loss: 2.6297 - val_mae: 2.6297 - val_mse: 16.5916\n",
      "Epoch 496/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.5876 - mae: 2.5876 - mse: 14.7742 - val_loss: 2.7854 - val_mae: 2.7854 - val_mse: 17.3375\n",
      "Epoch 497/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.6028 - mae: 2.6028 - mse: 14.8497 - val_loss: 2.7308 - val_mae: 2.7308 - val_mse: 16.7081\n",
      "Epoch 498/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.6017 - mae: 2.6017 - mse: 14.7084 - val_loss: 2.9096 - val_mae: 2.9096 - val_mse: 16.3026\n",
      "Epoch 499/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.5606 - mae: 2.5606 - mse: 14.4220 - val_loss: 2.6133 - val_mae: 2.6133 - val_mse: 15.6789\n",
      "Epoch 500/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.6267 - mae: 2.6267 - mse: 14.9657 - val_loss: 3.0789 - val_mae: 3.0789 - val_mse: 18.2120\n",
      "Epoch 501/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.6158 - mae: 2.6158 - mse: 14.7336 - val_loss: 2.5777 - val_mae: 2.5777 - val_mse: 15.4190\n",
      "Epoch 502/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.5531 - mae: 2.5531 - mse: 14.4950 - val_loss: 2.6361 - val_mae: 2.6361 - val_mse: 15.2891\n",
      "Epoch 503/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.5188 - mae: 2.5188 - mse: 14.1084 - val_loss: 2.7653 - val_mae: 2.7653 - val_mse: 16.4438\n",
      "Epoch 504/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5827 - mae: 2.5827 - mse: 14.9061 - val_loss: 2.6997 - val_mae: 2.6997 - val_mse: 15.5928\n",
      "Epoch 505/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5570 - mae: 2.5570 - mse: 14.5608 - val_loss: 2.7383 - val_mae: 2.7383 - val_mse: 15.5486\n",
      "Epoch 506/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.5182 - mae: 2.5182 - mse: 14.1809 - val_loss: 2.5801 - val_mae: 2.5801 - val_mse: 15.2426\n",
      "Epoch 507/2500\n",
      "684/684 [==============================] - 1s 941us/sample - loss: 2.6272 - mae: 2.6272 - mse: 14.6455 - val_loss: 2.8290 - val_mae: 2.8290 - val_mse: 16.2692\n",
      "Epoch 508/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.5588 - mae: 2.5588 - mse: 14.3574 - val_loss: 2.6676 - val_mae: 2.6676 - val_mse: 16.9222\n",
      "Epoch 509/2500\n",
      "684/684 [==============================] - 1s 831us/sample - loss: 2.6681 - mae: 2.6681 - mse: 15.0775 - val_loss: 2.7140 - val_mae: 2.7140 - val_mse: 16.4682\n",
      "Epoch 510/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 814us/sample - loss: 2.5408 - mae: 2.5408 - mse: 14.1861 - val_loss: 2.6870 - val_mae: 2.6870 - val_mse: 15.9885\n",
      "Epoch 511/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5453 - mae: 2.5453 - mse: 14.2642 - val_loss: 2.7382 - val_mae: 2.7382 - val_mse: 16.6084\n",
      "Epoch 512/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.5199 - mae: 2.5199 - mse: 14.1440 - val_loss: 2.6088 - val_mae: 2.6088 - val_mse: 15.7616\n",
      "Epoch 513/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.6034 - mae: 2.6034 - mse: 14.8242 - val_loss: 2.6201 - val_mae: 2.6201 - val_mse: 15.3691\n",
      "Epoch 514/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.5710 - mae: 2.5710 - mse: 14.5087 - val_loss: 2.6819 - val_mae: 2.6819 - val_mse: 15.6834\n",
      "Epoch 515/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.5163 - mae: 2.5163 - mse: 14.1522 - val_loss: 2.5749 - val_mae: 2.5749 - val_mse: 15.6872\n",
      "Epoch 516/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.5399 - mae: 2.5399 - mse: 14.1483 - val_loss: 2.7649 - val_mae: 2.7649 - val_mse: 15.8796\n",
      "Epoch 517/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5747 - mae: 2.5747 - mse: 14.3816 - val_loss: 2.9220 - val_mae: 2.9220 - val_mse: 16.8650\n",
      "Epoch 518/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5945 - mae: 2.5945 - mse: 14.5994 - val_loss: 2.5712 - val_mae: 2.5712 - val_mse: 15.2084\n",
      "Epoch 519/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.6582 - mae: 2.6582 - mse: 15.0631 - val_loss: 2.7312 - val_mae: 2.7312 - val_mse: 17.2207\n",
      "Epoch 520/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.5439 - mae: 2.5439 - mse: 14.4008 - val_loss: 2.6539 - val_mae: 2.6539 - val_mse: 16.2284\n",
      "Epoch 521/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.5299 - mae: 2.5299 - mse: 14.1982 - val_loss: 2.6235 - val_mae: 2.6235 - val_mse: 16.3575\n",
      "Epoch 522/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.6880 - mae: 2.6880 - mse: 15.3837 - val_loss: 2.5587 - val_mae: 2.5587 - val_mse: 15.2593\n",
      "Epoch 523/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5786 - mae: 2.5786 - mse: 14.4045 - val_loss: 2.8379 - val_mae: 2.8379 - val_mse: 17.4208\n",
      "Epoch 524/2500\n",
      "684/684 [==============================] - 1s 837us/sample - loss: 2.6231 - mae: 2.6231 - mse: 14.8490 - val_loss: 2.7198 - val_mae: 2.7198 - val_mse: 15.8979\n",
      "Epoch 525/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.5088 - mae: 2.5088 - mse: 13.8895 - val_loss: 2.7109 - val_mae: 2.7109 - val_mse: 16.6307\n",
      "Epoch 526/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5313 - mae: 2.5313 - mse: 14.2551 - val_loss: 2.5341 - val_mae: 2.5341 - val_mse: 15.1080\n",
      "Epoch 527/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4863 - mae: 2.4863 - mse: 13.6472 - val_loss: 2.6005 - val_mae: 2.6005 - val_mse: 15.6375\n",
      "Epoch 528/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.5012 - mae: 2.5012 - mse: 14.1738 - val_loss: 2.9759 - val_mae: 2.9759 - val_mse: 15.9824\n",
      "Epoch 529/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5622 - mae: 2.5622 - mse: 14.2918 - val_loss: 2.7597 - val_mae: 2.7597 - val_mse: 15.0190\n",
      "Epoch 530/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5535 - mae: 2.5535 - mse: 14.1294 - val_loss: 2.5764 - val_mae: 2.5764 - val_mse: 15.1584\n",
      "Epoch 531/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.5351 - mae: 2.5351 - mse: 14.1806 - val_loss: 2.7075 - val_mae: 2.7075 - val_mse: 18.0242\n",
      "Epoch 532/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.5188 - mae: 2.5188 - mse: 14.1912 - val_loss: 2.5559 - val_mae: 2.5559 - val_mse: 14.9983\n",
      "Epoch 533/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5064 - mae: 2.5064 - mse: 13.8556 - val_loss: 2.6281 - val_mae: 2.6281 - val_mse: 15.6347\n",
      "Epoch 534/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.5448 - mae: 2.5448 - mse: 14.1862 - val_loss: 2.6351 - val_mae: 2.6351 - val_mse: 14.8390\n",
      "Epoch 535/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.4776 - mae: 2.4776 - mse: 13.7601 - val_loss: 2.5508 - val_mae: 2.5508 - val_mse: 15.1410\n",
      "Epoch 536/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.5527 - mae: 2.5527 - mse: 13.9384 - val_loss: 2.5747 - val_mae: 2.5747 - val_mse: 15.3427\n",
      "Epoch 537/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4614 - mae: 2.4614 - mse: 13.6964 - val_loss: 2.6241 - val_mae: 2.6241 - val_mse: 14.9949\n",
      "Epoch 538/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.5944 - mae: 2.5944 - mse: 14.6087 - val_loss: 2.7709 - val_mae: 2.7709 - val_mse: 17.1262\n",
      "Epoch 539/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4963 - mae: 2.4963 - mse: 13.9984 - val_loss: 2.6488 - val_mae: 2.6488 - val_mse: 15.8151\n",
      "Epoch 540/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.6519 - mae: 2.6519 - mse: 15.0879 - val_loss: 2.6770 - val_mae: 2.6770 - val_mse: 15.1053\n",
      "Epoch 541/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.5323 - mae: 2.5323 - mse: 14.3948 - val_loss: 2.6084 - val_mae: 2.6084 - val_mse: 15.7398\n",
      "Epoch 542/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4715 - mae: 2.4715 - mse: 13.8657 - val_loss: 2.5922 - val_mae: 2.5922 - val_mse: 16.8780\n",
      "Epoch 543/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5682 - mae: 2.5682 - mse: 14.6813 - val_loss: 2.6088 - val_mae: 2.6088 - val_mse: 15.0044\n",
      "Epoch 544/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4421 - mae: 2.4421 - mse: 13.6287 - val_loss: 2.5071 - val_mae: 2.5071 - val_mse: 14.5925\n",
      "Epoch 545/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4605 - mae: 2.4605 - mse: 13.5902 - val_loss: 2.6812 - val_mae: 2.6812 - val_mse: 15.5802\n",
      "Epoch 546/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.5176 - mae: 2.5176 - mse: 14.0258 - val_loss: 2.5300 - val_mae: 2.5300 - val_mse: 15.0862\n",
      "Epoch 547/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.5414 - mae: 2.5414 - mse: 14.1147 - val_loss: 2.7599 - val_mae: 2.7599 - val_mse: 15.5682\n",
      "Epoch 548/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.5532 - mae: 2.5532 - mse: 14.1924 - val_loss: 2.7703 - val_mae: 2.7703 - val_mse: 15.0321\n",
      "Epoch 549/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4815 - mae: 2.4815 - mse: 13.6784 - val_loss: 2.6409 - val_mae: 2.6409 - val_mse: 16.1173\n",
      "Epoch 550/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.5064 - mae: 2.5064 - mse: 13.9078 - val_loss: 2.5556 - val_mae: 2.5556 - val_mse: 15.4520\n",
      "Epoch 551/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.5366 - mae: 2.5366 - mse: 14.0286 - val_loss: 2.5557 - val_mae: 2.5557 - val_mse: 15.3827\n",
      "Epoch 552/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5046 - mae: 2.5046 - mse: 13.9310 - val_loss: 2.5287 - val_mae: 2.5287 - val_mse: 14.9909\n",
      "Epoch 553/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.5064 - mae: 2.5064 - mse: 13.8434 - val_loss: 2.6033 - val_mae: 2.6033 - val_mse: 15.2200\n",
      "Epoch 554/2500\n",
      "684/684 [==============================] - 1s 841us/sample - loss: 2.6078 - mae: 2.6078 - mse: 14.6224 - val_loss: 2.7315 - val_mae: 2.7315 - val_mse: 17.0714\n",
      "Epoch 555/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.6386 - mae: 2.6386 - mse: 15.1699 - val_loss: 2.6511 - val_mae: 2.6511 - val_mse: 16.3740\n",
      "Epoch 556/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.6291 - mae: 2.6291 - mse: 14.8059 - val_loss: 2.6093 - val_mae: 2.6093 - val_mse: 14.6330\n",
      "Epoch 557/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4710 - mae: 2.4710 - mse: 13.5360 - val_loss: 2.6474 - val_mae: 2.6474 - val_mse: 17.8984\n",
      "Epoch 558/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4810 - mae: 2.4810 - mse: 13.6025 - val_loss: 2.6311 - val_mae: 2.6311 - val_mse: 15.3372\n",
      "Epoch 559/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4570 - mae: 2.4570 - mse: 13.6438 - val_loss: 2.5111 - val_mae: 2.5111 - val_mse: 14.3735\n",
      "Epoch 560/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.6588 - mae: 2.6588 - mse: 15.2138 - val_loss: 2.6535 - val_mae: 2.6535 - val_mse: 15.7052\n",
      "Epoch 561/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.5223 - mae: 2.5223 - mse: 14.0164 - val_loss: 2.6261 - val_mae: 2.6261 - val_mse: 14.3784\n",
      "Epoch 562/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4984 - mae: 2.4984 - mse: 13.7417 - val_loss: 2.8107 - val_mae: 2.8107 - val_mse: 15.5489\n",
      "Epoch 563/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5039 - mae: 2.5039 - mse: 13.7662 - val_loss: 2.5004 - val_mae: 2.5004 - val_mse: 14.6227\n",
      "Epoch 564/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3884 - mae: 2.3884 - mse: 13.1487 - val_loss: 2.5053 - val_mae: 2.5053 - val_mse: 14.9238\n",
      "Epoch 565/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.3931 - mae: 2.3931 - mse: 13.0826 - val_loss: 2.5009 - val_mae: 2.5009 - val_mse: 14.4409\n",
      "Epoch 566/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4592 - mae: 2.4592 - mse: 13.4786 - val_loss: 2.5468 - val_mae: 2.5468 - val_mse: 14.3851\n",
      "Epoch 567/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4810 - mae: 2.4810 - mse: 13.9582 - val_loss: 2.5350 - val_mae: 2.5350 - val_mse: 14.9867\n",
      "Epoch 568/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4763 - mae: 2.4763 - mse: 13.8486 - val_loss: 2.5422 - val_mae: 2.5422 - val_mse: 15.4074\n",
      "Epoch 569/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4251 - mae: 2.4251 - mse: 13.5278 - val_loss: 2.6013 - val_mae: 2.6013 - val_mse: 14.4091\n",
      "Epoch 570/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4291 - mae: 2.4291 - mse: 13.2913 - val_loss: 2.5093 - val_mae: 2.5093 - val_mse: 14.3785\n",
      "Epoch 571/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4943 - mae: 2.4943 - mse: 13.8925 - val_loss: 2.4986 - val_mae: 2.4986 - val_mse: 14.5907\n",
      "Epoch 572/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4025 - mae: 2.4025 - mse: 13.1880 - val_loss: 2.4707 - val_mae: 2.4707 - val_mse: 14.3587\n",
      "Epoch 573/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4369 - mae: 2.4369 - mse: 13.3852 - val_loss: 2.5187 - val_mae: 2.5187 - val_mse: 15.1894\n",
      "Epoch 574/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4417 - mae: 2.4417 - mse: 13.4482 - val_loss: 2.5644 - val_mae: 2.5644 - val_mse: 14.3626\n",
      "Epoch 575/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3966 - mae: 2.3966 - mse: 13.2796 - val_loss: 2.5252 - val_mae: 2.5252 - val_mse: 15.0746\n",
      "Epoch 576/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4701 - mae: 2.4701 - mse: 13.6874 - val_loss: 2.5289 - val_mae: 2.5289 - val_mse: 14.2634\n",
      "Epoch 577/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4282 - mae: 2.4282 - mse: 13.3332 - val_loss: 2.6113 - val_mae: 2.6113 - val_mse: 16.5703\n",
      "Epoch 578/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4865 - mae: 2.4865 - mse: 13.8007 - val_loss: 2.6374 - val_mae: 2.6374 - val_mse: 14.4051\n",
      "Epoch 579/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4553 - mae: 2.4553 - mse: 13.6225 - val_loss: 2.6122 - val_mae: 2.6122 - val_mse: 15.1608\n",
      "Epoch 580/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4387 - mae: 2.4387 - mse: 13.4872 - val_loss: 2.6485 - val_mae: 2.6485 - val_mse: 16.2952\n",
      "Epoch 581/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4455 - mae: 2.4455 - mse: 13.4935 - val_loss: 2.5463 - val_mae: 2.5463 - val_mse: 14.9524\n",
      "Epoch 582/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4220 - mae: 2.4220 - mse: 13.3689 - val_loss: 2.6620 - val_mae: 2.6620 - val_mse: 15.9557\n",
      "Epoch 583/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4856 - mae: 2.4856 - mse: 13.7710 - val_loss: 2.4922 - val_mae: 2.4922 - val_mse: 14.3079\n",
      "Epoch 584/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4056 - mae: 2.4056 - mse: 13.2635 - val_loss: 2.4929 - val_mae: 2.4929 - val_mse: 14.1576\n",
      "Epoch 585/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.5019 - mae: 2.5019 - mse: 13.8024 - val_loss: 2.6882 - val_mae: 2.6882 - val_mse: 15.2910\n",
      "Epoch 586/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4009 - mae: 2.4009 - mse: 13.0957 - val_loss: 2.4853 - val_mae: 2.4853 - val_mse: 14.3585\n",
      "Epoch 587/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4479 - mae: 2.4479 - mse: 13.4470 - val_loss: 2.5676 - val_mae: 2.5676 - val_mse: 14.7230\n",
      "Epoch 588/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4229 - mae: 2.4229 - mse: 13.3897 - val_loss: 2.5561 - val_mae: 2.5561 - val_mse: 15.0676\n",
      "Epoch 589/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4593 - mae: 2.4593 - mse: 13.4427 - val_loss: 2.8335 - val_mae: 2.8335 - val_mse: 16.1900\n",
      "Epoch 590/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.5928 - mae: 2.5928 - mse: 14.3505 - val_loss: 2.5954 - val_mae: 2.5954 - val_mse: 14.5932\n",
      "Epoch 591/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4360 - mae: 2.4360 - mse: 13.6867 - val_loss: 2.4876 - val_mae: 2.4876 - val_mse: 14.5902\n",
      "Epoch 592/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4372 - mae: 2.4372 - mse: 13.4865 - val_loss: 2.6450 - val_mae: 2.6450 - val_mse: 15.3510\n",
      "Epoch 593/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4983 - mae: 2.4983 - mse: 13.8462 - val_loss: 2.5049 - val_mae: 2.5049 - val_mse: 14.5662\n",
      "Epoch 594/2500\n",
      "684/684 [==============================] - 1s 831us/sample - loss: 2.3959 - mae: 2.3959 - mse: 13.2738 - val_loss: 2.4992 - val_mae: 2.4992 - val_mse: 14.8047\n",
      "Epoch 595/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.3664 - mae: 2.3664 - mse: 12.8892 - val_loss: 2.4931 - val_mae: 2.4931 - val_mse: 14.4760\n",
      "Epoch 596/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3879 - mae: 2.3879 - mse: 13.0814 - val_loss: 2.5128 - val_mae: 2.5128 - val_mse: 14.3349\n",
      "Epoch 597/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4292 - mae: 2.4292 - mse: 13.2911 - val_loss: 2.4570 - val_mae: 2.4570 - val_mse: 14.0091\n",
      "Epoch 598/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4622 - mae: 2.4622 - mse: 13.7887 - val_loss: 2.7358 - val_mae: 2.7358 - val_mse: 15.9844\n",
      "Epoch 599/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.5814 - mae: 2.5814 - mse: 14.7475 - val_loss: 2.6963 - val_mae: 2.6963 - val_mse: 16.5809\n",
      "Epoch 600/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.5093 - mae: 2.5093 - mse: 14.0001 - val_loss: 2.7083 - val_mae: 2.7083 - val_mse: 15.1137\n",
      "Epoch 601/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4486 - mae: 2.4486 - mse: 13.5012 - val_loss: 2.5571 - val_mae: 2.5571 - val_mse: 15.8763\n",
      "Epoch 602/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4735 - mae: 2.4735 - mse: 13.7639 - val_loss: 2.4974 - val_mae: 2.4974 - val_mse: 14.8961\n",
      "Epoch 603/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4426 - mae: 2.4426 - mse: 13.4636 - val_loss: 2.4927 - val_mae: 2.4927 - val_mse: 14.5721\n",
      "Epoch 604/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4629 - mae: 2.4629 - mse: 13.5559 - val_loss: 2.5744 - val_mae: 2.5744 - val_mse: 15.4972\n",
      "Epoch 605/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4446 - mae: 2.4446 - mse: 13.4874 - val_loss: 2.6630 - val_mae: 2.6630 - val_mse: 15.6374\n",
      "Epoch 606/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4763 - mae: 2.4763 - mse: 13.6124 - val_loss: 2.5201 - val_mae: 2.5201 - val_mse: 15.0769\n",
      "Epoch 607/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3900 - mae: 2.3900 - mse: 12.9597 - val_loss: 2.4876 - val_mae: 2.4876 - val_mse: 14.4064\n",
      "Epoch 608/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5000 - mae: 2.5000 - mse: 13.8446 - val_loss: 2.7591 - val_mae: 2.7591 - val_mse: 16.2570\n",
      "Epoch 609/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4789 - mae: 2.4789 - mse: 13.8494 - val_loss: 2.6507 - val_mae: 2.6507 - val_mse: 14.5425\n",
      "Epoch 610/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4598 - mae: 2.4598 - mse: 13.6232 - val_loss: 2.5437 - val_mae: 2.5437 - val_mse: 14.8281\n",
      "Epoch 611/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.5171 - mae: 2.5171 - mse: 14.0103 - val_loss: 2.8321 - val_mae: 2.8321 - val_mse: 17.2131\n",
      "Epoch 612/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4155 - mae: 2.4155 - mse: 13.3934 - val_loss: 2.5515 - val_mae: 2.5515 - val_mse: 14.9966\n",
      "Epoch 613/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5140 - mae: 2.5140 - mse: 13.6624 - val_loss: 2.7148 - val_mae: 2.7148 - val_mse: 16.1612\n",
      "Epoch 614/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 2.4203 - mae: 2.4203 - mse: 13.1887 - val_loss: 2.5766 - val_mae: 2.5766 - val_mse: 14.9254\n",
      "Epoch 615/2500\n",
      "684/684 [==============================] - 1s 837us/sample - loss: 2.4121 - mae: 2.4121 - mse: 13.2553 - val_loss: 2.6268 - val_mae: 2.6268 - val_mse: 14.1873\n",
      "Epoch 616/2500\n",
      "684/684 [==============================] - 1s 834us/sample - loss: 2.5072 - mae: 2.5072 - mse: 13.8572 - val_loss: 2.5883 - val_mae: 2.5883 - val_mse: 15.3653\n",
      "Epoch 617/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4549 - mae: 2.4549 - mse: 13.5286 - val_loss: 2.4689 - val_mae: 2.4689 - val_mse: 14.5425\n",
      "Epoch 618/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4017 - mae: 2.4017 - mse: 13.1598 - val_loss: 2.5429 - val_mae: 2.5429 - val_mse: 14.4361\n",
      "Epoch 619/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4644 - mae: 2.4644 - mse: 13.5058 - val_loss: 2.5581 - val_mae: 2.5581 - val_mse: 14.7236\n",
      "Epoch 620/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3835 - mae: 2.3835 - mse: 13.2279 - val_loss: 2.5898 - val_mae: 2.5898 - val_mse: 14.2990\n",
      "Epoch 621/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4552 - mae: 2.4552 - mse: 13.3602 - val_loss: 2.5965 - val_mae: 2.5965 - val_mse: 14.8952\n",
      "Epoch 622/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3925 - mae: 2.3925 - mse: 13.3245 - val_loss: 2.5067 - val_mae: 2.5067 - val_mse: 14.0452\n",
      "Epoch 623/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4508 - mae: 2.4508 - mse: 13.5441 - val_loss: 2.5389 - val_mae: 2.5389 - val_mse: 14.9106\n",
      "Epoch 624/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.5057 - mae: 2.5057 - mse: 13.6094 - val_loss: 2.5121 - val_mae: 2.5121 - val_mse: 14.4451\n",
      "Epoch 625/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4624 - mae: 2.4624 - mse: 13.6145 - val_loss: 2.5348 - val_mae: 2.5348 - val_mse: 14.6169\n",
      "Epoch 626/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3997 - mae: 2.3997 - mse: 13.0673 - val_loss: 2.5011 - val_mae: 2.5011 - val_mse: 14.2419\n",
      "Epoch 627/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4405 - mae: 2.4405 - mse: 13.2682 - val_loss: 2.4801 - val_mae: 2.4801 - val_mse: 14.3623\n",
      "Epoch 628/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3923 - mae: 2.3923 - mse: 13.0246 - val_loss: 2.4975 - val_mae: 2.4975 - val_mse: 15.0571\n",
      "Epoch 629/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4088 - mae: 2.4088 - mse: 13.2536 - val_loss: 2.5485 - val_mae: 2.5485 - val_mse: 14.5733\n",
      "Epoch 630/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4352 - mae: 2.4352 - mse: 13.2329 - val_loss: 2.4779 - val_mae: 2.4779 - val_mse: 14.7427\n",
      "Epoch 631/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4294 - mae: 2.4294 - mse: 13.1999 - val_loss: 2.5107 - val_mae: 2.5107 - val_mse: 14.4021\n",
      "Epoch 632/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4600 - mae: 2.4600 - mse: 13.6903 - val_loss: 2.4969 - val_mae: 2.4969 - val_mse: 14.6002\n",
      "Epoch 633/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4611 - mae: 2.4611 - mse: 13.5710 - val_loss: 2.7583 - val_mae: 2.7583 - val_mse: 14.9835\n",
      "Epoch 634/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4821 - mae: 2.4821 - mse: 13.7047 - val_loss: 2.4780 - val_mae: 2.4780 - val_mse: 14.2382\n",
      "Epoch 635/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4414 - mae: 2.4414 - mse: 13.2704 - val_loss: 2.5266 - val_mae: 2.5266 - val_mse: 15.0473\n",
      "Epoch 636/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4136 - mae: 2.4136 - mse: 13.1832 - val_loss: 2.5019 - val_mae: 2.5019 - val_mse: 14.2256\n",
      "Epoch 637/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3960 - mae: 2.3960 - mse: 13.0507 - val_loss: 2.5505 - val_mae: 2.5505 - val_mse: 14.1072\n",
      "Epoch 638/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4156 - mae: 2.4156 - mse: 13.2145 - val_loss: 2.4527 - val_mae: 2.4527 - val_mse: 14.1805\n",
      "Epoch 639/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4096 - mae: 2.4096 - mse: 13.0188 - val_loss: 2.6241 - val_mae: 2.6241 - val_mse: 14.4718\n",
      "Epoch 640/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3886 - mae: 2.3886 - mse: 12.9306 - val_loss: 2.5442 - val_mae: 2.5442 - val_mse: 15.0258\n",
      "Epoch 641/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4195 - mae: 2.4195 - mse: 13.1256 - val_loss: 2.4418 - val_mae: 2.4418 - val_mse: 14.0125\n",
      "Epoch 642/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4021 - mae: 2.4021 - mse: 13.0824 - val_loss: 2.4835 - val_mae: 2.4835 - val_mse: 14.6380\n",
      "Epoch 643/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3848 - mae: 2.3848 - mse: 13.0102 - val_loss: 2.6833 - val_mae: 2.6833 - val_mse: 15.8954\n",
      "Epoch 644/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.5078 - mae: 2.5078 - mse: 14.0423 - val_loss: 2.5369 - val_mae: 2.5369 - val_mse: 15.7167\n",
      "Epoch 645/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4389 - mae: 2.4389 - mse: 13.2815 - val_loss: 2.6575 - val_mae: 2.6575 - val_mse: 15.8096\n",
      "Epoch 646/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.5078 - mae: 2.5078 - mse: 13.9854 - val_loss: 2.5099 - val_mae: 2.5099 - val_mse: 14.0799\n",
      "Epoch 647/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3970 - mae: 2.3970 - mse: 13.1797 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 13.9309\n",
      "Epoch 648/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3777 - mae: 2.3777 - mse: 12.8602 - val_loss: 2.4600 - val_mae: 2.4600 - val_mse: 14.4937\n",
      "Epoch 649/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3741 - mae: 2.3741 - mse: 12.8945 - val_loss: 2.4843 - val_mae: 2.4843 - val_mse: 14.7482\n",
      "Epoch 650/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4580 - mae: 2.4580 - mse: 13.5676 - val_loss: 2.4458 - val_mae: 2.4458 - val_mse: 14.2488\n",
      "Epoch 651/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3672 - mae: 2.3672 - mse: 12.8645 - val_loss: 2.4413 - val_mae: 2.4413 - val_mse: 14.0291\n",
      "Epoch 652/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4352 - mae: 2.4352 - mse: 13.2671 - val_loss: 2.8429 - val_mae: 2.8429 - val_mse: 17.0214\n",
      "Epoch 653/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.5198 - mae: 2.5198 - mse: 13.8697 - val_loss: 2.5947 - val_mae: 2.5947 - val_mse: 15.9801\n",
      "Epoch 654/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3956 - mae: 2.3956 - mse: 13.0268 - val_loss: 2.4855 - val_mae: 2.4855 - val_mse: 15.2361\n",
      "Epoch 655/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4194 - mae: 2.4194 - mse: 13.2537 - val_loss: 2.6085 - val_mae: 2.6085 - val_mse: 14.1787\n",
      "Epoch 656/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4627 - mae: 2.4627 - mse: 13.6286 - val_loss: 2.4878 - val_mae: 2.4878 - val_mse: 14.9786\n",
      "Epoch 657/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4890 - mae: 2.4890 - mse: 13.8383 - val_loss: 2.7477 - val_mae: 2.7477 - val_mse: 15.1269\n",
      "Epoch 658/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.4505 - mae: 2.4505 - mse: 13.3777 - val_loss: 2.6268 - val_mae: 2.6268 - val_mse: 14.8443\n",
      "Epoch 659/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4198 - mae: 2.4198 - mse: 13.1186 - val_loss: 2.4520 - val_mae: 2.4520 - val_mse: 13.9847\n",
      "Epoch 660/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4154 - mae: 2.4154 - mse: 13.1173 - val_loss: 2.6634 - val_mae: 2.6634 - val_mse: 14.5217\n",
      "Epoch 661/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4186 - mae: 2.4186 - mse: 13.2019 - val_loss: 2.4763 - val_mae: 2.4763 - val_mse: 14.1370\n",
      "Epoch 662/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4054 - mae: 2.4054 - mse: 13.0916 - val_loss: 2.4629 - val_mae: 2.4629 - val_mse: 14.2291\n",
      "Epoch 663/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4282 - mae: 2.4282 - mse: 13.3166 - val_loss: 2.5255 - val_mae: 2.5255 - val_mse: 15.1296\n",
      "Epoch 664/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4106 - mae: 2.4106 - mse: 13.2485 - val_loss: 2.4835 - val_mae: 2.4835 - val_mse: 13.7537\n",
      "Epoch 665/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.3896 - mae: 2.3896 - mse: 12.9978 - val_loss: 2.5689 - val_mae: 2.5689 - val_mse: 14.4168\n",
      "Epoch 666/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4970 - mae: 2.4970 - mse: 13.6941 - val_loss: 2.5004 - val_mae: 2.5004 - val_mse: 14.9701\n",
      "Epoch 667/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4441 - mae: 2.4441 - mse: 13.4788 - val_loss: 2.6164 - val_mae: 2.6164 - val_mse: 14.3380\n",
      "Epoch 668/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 2.4509 - mae: 2.4509 - mse: 13.5363 - val_loss: 2.6856 - val_mae: 2.6856 - val_mse: 14.4258\n",
      "Epoch 669/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4083 - mae: 2.4083 - mse: 12.9830 - val_loss: 2.4429 - val_mae: 2.4429 - val_mse: 14.0737\n",
      "Epoch 670/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.4718 - mae: 2.4718 - mse: 13.5502 - val_loss: 2.7299 - val_mae: 2.7299 - val_mse: 16.7910\n",
      "Epoch 671/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4000 - mae: 2.4000 - mse: 13.1108 - val_loss: 2.4307 - val_mae: 2.4307 - val_mse: 14.0447\n",
      "Epoch 672/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3999 - mae: 2.3999 - mse: 12.9615 - val_loss: 2.6610 - val_mae: 2.6610 - val_mse: 14.7312\n",
      "Epoch 673/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4635 - mae: 2.4635 - mse: 13.5235 - val_loss: 2.4388 - val_mae: 2.4388 - val_mse: 13.9051\n",
      "Epoch 674/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3533 - mae: 2.3533 - mse: 12.7036 - val_loss: 2.5249 - val_mae: 2.5249 - val_mse: 14.2602\n",
      "Epoch 675/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4227 - mae: 2.4227 - mse: 13.1729 - val_loss: 2.5945 - val_mae: 2.5945 - val_mse: 14.7634\n",
      "Epoch 676/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5411 - mae: 2.5411 - mse: 13.8986 - val_loss: 2.8364 - val_mae: 2.8364 - val_mse: 17.3563\n",
      "Epoch 677/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.5842 - mae: 2.5842 - mse: 14.6762 - val_loss: 2.5576 - val_mae: 2.5576 - val_mse: 14.1524\n",
      "Epoch 678/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3869 - mae: 2.3869 - mse: 13.0112 - val_loss: 2.4773 - val_mae: 2.4773 - val_mse: 14.5276\n",
      "Epoch 679/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3880 - mae: 2.3880 - mse: 13.0621 - val_loss: 2.4818 - val_mae: 2.4818 - val_mse: 14.4029\n",
      "Epoch 680/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.4121 - mae: 2.4121 - mse: 13.2436 - val_loss: 2.7652 - val_mae: 2.7652 - val_mse: 18.3479\n",
      "Epoch 681/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4224 - mae: 2.4224 - mse: 13.3527 - val_loss: 2.4728 - val_mae: 2.4728 - val_mse: 14.7832\n",
      "Epoch 682/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4030 - mae: 2.4030 - mse: 12.9301 - val_loss: 2.4381 - val_mae: 2.4381 - val_mse: 14.2999\n",
      "Epoch 683/2500\n",
      "684/684 [==============================] - 1s 830us/sample - loss: 2.3638 - mae: 2.3638 - mse: 12.8881 - val_loss: 2.7258 - val_mae: 2.7258 - val_mse: 15.2272\n",
      "Epoch 684/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.4655 - mae: 2.4655 - mse: 13.6043 - val_loss: 2.4608 - val_mae: 2.4608 - val_mse: 14.2055\n",
      "Epoch 685/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4232 - mae: 2.4232 - mse: 13.2294 - val_loss: 2.5745 - val_mae: 2.5745 - val_mse: 14.6216\n",
      "Epoch 686/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4043 - mae: 2.4043 - mse: 13.1199 - val_loss: 2.4358 - val_mae: 2.4358 - val_mse: 13.9712\n",
      "Epoch 687/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4068 - mae: 2.4068 - mse: 13.1826 - val_loss: 2.4685 - val_mae: 2.4685 - val_mse: 14.1106\n",
      "Epoch 688/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4889 - mae: 2.4889 - mse: 13.6431 - val_loss: 2.6863 - val_mae: 2.6863 - val_mse: 14.4640\n",
      "Epoch 689/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4785 - mae: 2.4785 - mse: 13.7106 - val_loss: 2.7446 - val_mae: 2.7446 - val_mse: 14.7419\n",
      "Epoch 690/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4757 - mae: 2.4757 - mse: 13.7115 - val_loss: 2.5536 - val_mae: 2.5536 - val_mse: 14.1668\n",
      "Epoch 691/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4307 - mae: 2.4307 - mse: 13.4397 - val_loss: 2.4542 - val_mae: 2.4542 - val_mse: 14.3334\n",
      "Epoch 692/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3905 - mae: 2.3905 - mse: 13.0209 - val_loss: 2.4853 - val_mae: 2.4853 - val_mse: 14.0569\n",
      "Epoch 693/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.4130 - mae: 2.4130 - mse: 13.0773 - val_loss: 2.5402 - val_mae: 2.5402 - val_mse: 15.8365\n",
      "Epoch 694/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4946 - mae: 2.4946 - mse: 13.7037 - val_loss: 2.4843 - val_mae: 2.4843 - val_mse: 14.0102\n",
      "Epoch 695/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.4874 - mae: 2.4874 - mse: 13.6026 - val_loss: 2.6603 - val_mae: 2.6603 - val_mse: 15.4985\n",
      "Epoch 696/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4390 - mae: 2.4390 - mse: 13.3129 - val_loss: 2.5456 - val_mae: 2.5456 - val_mse: 14.5381\n",
      "Epoch 697/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.4183 - mae: 2.4183 - mse: 13.2304 - val_loss: 2.4925 - val_mae: 2.4925 - val_mse: 14.0550\n",
      "Epoch 698/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4014 - mae: 2.4014 - mse: 12.9789 - val_loss: 2.5802 - val_mae: 2.5802 - val_mse: 14.8738\n",
      "Epoch 699/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3884 - mae: 2.3884 - mse: 12.9099 - val_loss: 2.4985 - val_mae: 2.4985 - val_mse: 14.8240\n",
      "Epoch 700/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3425 - mae: 2.3425 - mse: 12.6398 - val_loss: 2.4247 - val_mae: 2.4247 - val_mse: 13.7723\n",
      "Epoch 701/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3837 - mae: 2.3837 - mse: 12.8230 - val_loss: 2.5249 - val_mae: 2.5249 - val_mse: 14.6494\n",
      "Epoch 702/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.5031 - mae: 2.5031 - mse: 13.9957 - val_loss: 2.6232 - val_mae: 2.6232 - val_mse: 15.8932\n",
      "Epoch 703/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4601 - mae: 2.4601 - mse: 13.6700 - val_loss: 2.5356 - val_mae: 2.5356 - val_mse: 14.4063\n",
      "Epoch 704/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4278 - mae: 2.4278 - mse: 13.0982 - val_loss: 2.4492 - val_mae: 2.4492 - val_mse: 13.7593\n",
      "Epoch 705/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3694 - mae: 2.3694 - mse: 12.7363 - val_loss: 2.4329 - val_mae: 2.4329 - val_mse: 14.0147\n",
      "Epoch 706/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3790 - mae: 2.3790 - mse: 12.9734 - val_loss: 2.5829 - val_mae: 2.5829 - val_mse: 14.8491\n",
      "Epoch 707/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.3806 - mae: 2.3807 - mse: 13.0542 - val_loss: 2.5364 - val_mae: 2.5364 - val_mse: 16.1822\n",
      "Epoch 708/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4225 - mae: 2.4225 - mse: 13.4026 - val_loss: 2.4791 - val_mae: 2.4791 - val_mse: 14.2924\n",
      "Epoch 709/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4032 - mae: 2.4032 - mse: 12.9041 - val_loss: 2.6885 - val_mae: 2.6885 - val_mse: 16.4431\n",
      "Epoch 710/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4468 - mae: 2.4468 - mse: 13.1652 - val_loss: 2.9313 - val_mae: 2.9313 - val_mse: 17.8728\n",
      "Epoch 711/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4509 - mae: 2.4509 - mse: 13.3755 - val_loss: 2.5431 - val_mae: 2.5431 - val_mse: 14.6855\n",
      "Epoch 712/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.4190 - mae: 2.4190 - mse: 13.1352 - val_loss: 3.0630 - val_mae: 3.0630 - val_mse: 16.6923\n",
      "Epoch 713/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3954 - mae: 2.3954 - mse: 13.0879 - val_loss: 2.4381 - val_mae: 2.4381 - val_mse: 13.9977\n",
      "Epoch 714/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4061 - mae: 2.4061 - mse: 13.1248 - val_loss: 2.4428 - val_mae: 2.4428 - val_mse: 14.0008\n",
      "Epoch 715/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3715 - mae: 2.3715 - mse: 12.9143 - val_loss: 2.5125 - val_mae: 2.5125 - val_mse: 14.4701\n",
      "Epoch 716/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3755 - mae: 2.3755 - mse: 12.8587 - val_loss: 2.4640 - val_mae: 2.4640 - val_mse: 13.8892\n",
      "Epoch 717/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3837 - mae: 2.3837 - mse: 12.9533 - val_loss: 2.4698 - val_mae: 2.4698 - val_mse: 13.9936\n",
      "Epoch 718/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4653 - mae: 2.4653 - mse: 13.5320 - val_loss: 2.6120 - val_mae: 2.6120 - val_mse: 14.1452\n",
      "Epoch 719/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4825 - mae: 2.4825 - mse: 13.6234 - val_loss: 2.4451 - val_mae: 2.4451 - val_mse: 13.9886\n",
      "Epoch 720/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3856 - mae: 2.3856 - mse: 13.1377 - val_loss: 2.5152 - val_mae: 2.5152 - val_mse: 14.9262\n",
      "Epoch 721/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4806 - mae: 2.4806 - mse: 13.5125 - val_loss: 2.4831 - val_mae: 2.4831 - val_mse: 13.8804\n",
      "Epoch 722/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 2.3985 - mae: 2.3985 - mse: 13.0550 - val_loss: 2.4311 - val_mae: 2.4311 - val_mse: 13.9353\n",
      "Epoch 723/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3782 - mae: 2.3782 - mse: 12.9126 - val_loss: 2.4655 - val_mae: 2.4655 - val_mse: 14.4086\n",
      "Epoch 724/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4202 - mae: 2.4202 - mse: 13.1258 - val_loss: 2.4640 - val_mae: 2.4640 - val_mse: 14.5625\n",
      "Epoch 725/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3394 - mae: 2.3394 - mse: 12.6499 - val_loss: 2.4278 - val_mae: 2.4278 - val_mse: 13.6779\n",
      "Epoch 726/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3471 - mae: 2.3471 - mse: 12.6768 - val_loss: 2.4748 - val_mae: 2.4748 - val_mse: 14.4046\n",
      "Epoch 727/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3877 - mae: 2.3877 - mse: 13.1950 - val_loss: 2.5125 - val_mae: 2.5125 - val_mse: 14.0662\n",
      "Epoch 728/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4299 - mae: 2.4299 - mse: 13.2074 - val_loss: 2.4831 - val_mae: 2.4831 - val_mse: 14.9050\n",
      "Epoch 729/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4286 - mae: 2.4286 - mse: 12.9761 - val_loss: 2.5210 - val_mae: 2.5210 - val_mse: 14.4899\n",
      "Epoch 730/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3747 - mae: 2.3747 - mse: 12.8984 - val_loss: 2.5165 - val_mae: 2.5165 - val_mse: 14.1684\n",
      "Epoch 731/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.4356 - mae: 2.4356 - mse: 13.3441 - val_loss: 2.5395 - val_mae: 2.5395 - val_mse: 14.3287\n",
      "Epoch 732/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3760 - mae: 2.3760 - mse: 12.8779 - val_loss: 2.4220 - val_mae: 2.4220 - val_mse: 13.9741\n",
      "Epoch 733/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3759 - mae: 2.3759 - mse: 13.0227 - val_loss: 2.7389 - val_mae: 2.7389 - val_mse: 14.8715\n",
      "Epoch 734/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4416 - mae: 2.4416 - mse: 13.1597 - val_loss: 2.5906 - val_mae: 2.5906 - val_mse: 15.0360\n",
      "Epoch 735/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4004 - mae: 2.4004 - mse: 12.9376 - val_loss: 2.5427 - val_mae: 2.5427 - val_mse: 14.0327\n",
      "Epoch 736/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3796 - mae: 2.3796 - mse: 12.8357 - val_loss: 2.4505 - val_mae: 2.4505 - val_mse: 13.9797\n",
      "Epoch 737/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3571 - mae: 2.3571 - mse: 12.7920 - val_loss: 2.5544 - val_mae: 2.5544 - val_mse: 13.9010\n",
      "Epoch 738/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4920 - mae: 2.4920 - mse: 13.7381 - val_loss: 2.5711 - val_mae: 2.5711 - val_mse: 14.8080\n",
      "Epoch 739/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4529 - mae: 2.4529 - mse: 13.4445 - val_loss: 2.4250 - val_mae: 2.4250 - val_mse: 13.8837\n",
      "Epoch 740/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.3962 - mae: 2.3962 - mse: 13.0965 - val_loss: 2.6222 - val_mae: 2.6222 - val_mse: 16.1482\n",
      "Epoch 741/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3953 - mae: 2.3953 - mse: 12.8979 - val_loss: 2.4408 - val_mae: 2.4408 - val_mse: 14.0785\n",
      "Epoch 742/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3764 - mae: 2.3764 - mse: 12.8420 - val_loss: 2.5106 - val_mae: 2.5106 - val_mse: 14.3878\n",
      "Epoch 743/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3745 - mae: 2.3745 - mse: 12.8403 - val_loss: 2.4291 - val_mae: 2.4291 - val_mse: 13.9940\n",
      "Epoch 744/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3917 - mae: 2.3917 - mse: 13.0793 - val_loss: 2.4807 - val_mae: 2.4807 - val_mse: 14.0043\n",
      "Epoch 745/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 802us/sample - loss: 2.4241 - mae: 2.4241 - mse: 13.4112 - val_loss: 2.5348 - val_mae: 2.5348 - val_mse: 14.7101\n",
      "Epoch 746/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.4146 - mae: 2.4146 - mse: 12.9785 - val_loss: 2.7023 - val_mae: 2.7023 - val_mse: 15.6913\n",
      "Epoch 747/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.4089 - mae: 2.4089 - mse: 13.0653 - val_loss: 2.4865 - val_mae: 2.4865 - val_mse: 14.2508\n",
      "Epoch 748/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4746 - mae: 2.4746 - mse: 13.4148 - val_loss: 2.5234 - val_mae: 2.5234 - val_mse: 15.1132\n",
      "Epoch 749/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3667 - mae: 2.3667 - mse: 12.9164 - val_loss: 2.6530 - val_mae: 2.6530 - val_mse: 15.3342\n",
      "Epoch 750/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4638 - mae: 2.4638 - mse: 13.7550 - val_loss: 2.6411 - val_mae: 2.6411 - val_mse: 17.0967\n",
      "Epoch 751/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.5655 - mae: 2.5655 - mse: 14.0933 - val_loss: 2.6008 - val_mae: 2.6008 - val_mse: 16.0392\n",
      "Epoch 752/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.5679 - mae: 2.5679 - mse: 14.6759 - val_loss: 2.5085 - val_mae: 2.5085 - val_mse: 14.8321\n",
      "Epoch 753/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4807 - mae: 2.4807 - mse: 13.5696 - val_loss: 2.4897 - val_mae: 2.4897 - val_mse: 14.7135\n",
      "Epoch 754/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4378 - mae: 2.4378 - mse: 13.2986 - val_loss: 2.4436 - val_mae: 2.4436 - val_mse: 13.8150\n",
      "Epoch 755/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3660 - mae: 2.3660 - mse: 12.8556 - val_loss: 2.5210 - val_mae: 2.5210 - val_mse: 14.0275\n",
      "Epoch 756/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4007 - mae: 2.4007 - mse: 13.0710 - val_loss: 2.4357 - val_mae: 2.4357 - val_mse: 13.8231\n",
      "Epoch 757/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3875 - mae: 2.3875 - mse: 12.9155 - val_loss: 2.5276 - val_mae: 2.5276 - val_mse: 13.9641\n",
      "Epoch 758/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3905 - mae: 2.3905 - mse: 12.9899 - val_loss: 2.4985 - val_mae: 2.4985 - val_mse: 14.4869\n",
      "Epoch 759/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4135 - mae: 2.4135 - mse: 13.0687 - val_loss: 2.6354 - val_mae: 2.6354 - val_mse: 14.9628\n",
      "Epoch 760/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3831 - mae: 2.3831 - mse: 12.9948 - val_loss: 2.4217 - val_mae: 2.4217 - val_mse: 13.8629\n",
      "Epoch 761/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4008 - mae: 2.4008 - mse: 13.0025 - val_loss: 2.4530 - val_mae: 2.4530 - val_mse: 14.1973\n",
      "Epoch 762/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3663 - mae: 2.3663 - mse: 12.6914 - val_loss: 2.4440 - val_mae: 2.4440 - val_mse: 13.7357\n",
      "Epoch 763/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.4014 - mae: 2.4014 - mse: 12.9812 - val_loss: 2.4602 - val_mae: 2.4602 - val_mse: 14.0215\n",
      "Epoch 764/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3666 - mae: 2.3666 - mse: 12.9042 - val_loss: 2.4301 - val_mae: 2.4301 - val_mse: 14.1597\n",
      "Epoch 765/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3601 - mae: 2.3601 - mse: 12.9319 - val_loss: 2.4614 - val_mae: 2.4614 - val_mse: 14.0074\n",
      "Epoch 766/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3696 - mae: 2.3696 - mse: 12.6757 - val_loss: 2.5113 - val_mae: 2.5113 - val_mse: 13.7222\n",
      "Epoch 767/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.4753 - mae: 2.4753 - mse: 13.3184 - val_loss: 2.7362 - val_mae: 2.7362 - val_mse: 15.2129\n",
      "Epoch 768/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.6139 - mae: 2.6139 - mse: 15.1059 - val_loss: 2.5286 - val_mae: 2.5286 - val_mse: 14.1809\n",
      "Epoch 769/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3954 - mae: 2.3954 - mse: 12.9782 - val_loss: 2.4549 - val_mae: 2.4549 - val_mse: 13.7571\n",
      "Epoch 770/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4098 - mae: 2.4098 - mse: 13.1996 - val_loss: 2.4742 - val_mae: 2.4742 - val_mse: 14.5037\n",
      "Epoch 771/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4203 - mae: 2.4203 - mse: 13.1493 - val_loss: 2.5398 - val_mae: 2.5398 - val_mse: 13.9372\n",
      "Epoch 772/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3907 - mae: 2.3907 - mse: 12.8111 - val_loss: 2.4307 - val_mae: 2.4307 - val_mse: 13.9255\n",
      "Epoch 773/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3347 - mae: 2.3347 - mse: 12.6773 - val_loss: 2.4910 - val_mae: 2.4910 - val_mse: 14.1724\n",
      "Epoch 774/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3902 - mae: 2.3902 - mse: 12.9492 - val_loss: 2.5181 - val_mae: 2.5181 - val_mse: 14.3091\n",
      "Epoch 775/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3795 - mae: 2.3795 - mse: 12.7597 - val_loss: 2.4784 - val_mae: 2.4784 - val_mse: 14.7665\n",
      "Epoch 776/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.3410 - mae: 2.3410 - mse: 12.6421 - val_loss: 2.4316 - val_mae: 2.4316 - val_mse: 13.5904\n",
      "Epoch 777/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4470 - mae: 2.4470 - mse: 13.0770 - val_loss: 2.8409 - val_mae: 2.8409 - val_mse: 16.7859\n",
      "Epoch 778/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5068 - mae: 2.5068 - mse: 13.8020 - val_loss: 2.5018 - val_mae: 2.5018 - val_mse: 14.9889\n",
      "Epoch 779/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4262 - mae: 2.4262 - mse: 13.2834 - val_loss: 2.4314 - val_mae: 2.4314 - val_mse: 13.8361\n",
      "Epoch 780/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3770 - mae: 2.3770 - mse: 12.8835 - val_loss: 2.5330 - val_mae: 2.5330 - val_mse: 14.3717\n",
      "Epoch 781/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.3912 - mae: 2.3912 - mse: 12.9818 - val_loss: 2.4920 - val_mae: 2.4920 - val_mse: 14.0950\n",
      "Epoch 782/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3613 - mae: 2.3613 - mse: 12.8249 - val_loss: 2.4212 - val_mae: 2.4212 - val_mse: 13.8264\n",
      "Epoch 783/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.4059 - mae: 2.4059 - mse: 13.0655 - val_loss: 2.4512 - val_mae: 2.4512 - val_mse: 13.9840\n",
      "Epoch 784/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3853 - mae: 2.3853 - mse: 12.9087 - val_loss: 2.5280 - val_mae: 2.5280 - val_mse: 14.6588\n",
      "Epoch 785/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.5152 - mae: 2.5152 - mse: 14.1488 - val_loss: 2.7541 - val_mae: 2.7541 - val_mse: 15.7841\n",
      "Epoch 786/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4527 - mae: 2.4527 - mse: 13.2778 - val_loss: 2.4975 - val_mae: 2.4975 - val_mse: 14.3376\n",
      "Epoch 787/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3661 - mae: 2.3661 - mse: 12.6740 - val_loss: 2.6533 - val_mae: 2.6533 - val_mse: 15.0435\n",
      "Epoch 788/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3855 - mae: 2.3855 - mse: 12.8989 - val_loss: 2.4231 - val_mae: 2.4231 - val_mse: 13.6779\n",
      "Epoch 789/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3864 - mae: 2.3864 - mse: 13.0659 - val_loss: 2.4865 - val_mae: 2.4865 - val_mse: 13.9096\n",
      "Epoch 790/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4140 - mae: 2.4140 - mse: 13.0520 - val_loss: 2.5084 - val_mae: 2.5084 - val_mse: 13.8614\n",
      "Epoch 791/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3453 - mae: 2.3453 - mse: 12.5880 - val_loss: 2.4727 - val_mae: 2.4727 - val_mse: 13.9316\n",
      "Epoch 792/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3751 - mae: 2.3751 - mse: 12.8138 - val_loss: 2.4703 - val_mae: 2.4703 - val_mse: 14.9769\n",
      "Epoch 793/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3710 - mae: 2.3710 - mse: 12.8544 - val_loss: 2.4418 - val_mae: 2.4418 - val_mse: 14.1679\n",
      "Epoch 794/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.3829 - mae: 2.3829 - mse: 12.9579 - val_loss: 2.5080 - val_mae: 2.5080 - val_mse: 14.4103\n",
      "Epoch 795/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5018 - mae: 2.5018 - mse: 13.4903 - val_loss: 2.6231 - val_mae: 2.6231 - val_mse: 15.0809\n",
      "Epoch 796/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.4193 - mae: 2.4193 - mse: 13.2951 - val_loss: 2.4789 - val_mae: 2.4789 - val_mse: 13.7121\n",
      "Epoch 797/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3869 - mae: 2.3869 - mse: 13.1792 - val_loss: 2.5339 - val_mae: 2.5339 - val_mse: 13.8850\n",
      "Epoch 798/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4127 - mae: 2.4127 - mse: 13.1685 - val_loss: 2.4338 - val_mae: 2.4338 - val_mse: 14.0039\n",
      "Epoch 799/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3607 - mae: 2.3607 - mse: 12.7735 - val_loss: 2.4314 - val_mae: 2.4314 - val_mse: 13.7151\n",
      "Epoch 800/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3669 - mae: 2.3669 - mse: 12.6373 - val_loss: 2.5023 - val_mae: 2.5023 - val_mse: 15.7010\n",
      "Epoch 801/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4029 - mae: 2.4029 - mse: 13.0202 - val_loss: 2.4341 - val_mae: 2.4341 - val_mse: 13.9439\n",
      "Epoch 802/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3288 - mae: 2.3288 - mse: 12.5315 - val_loss: 2.4269 - val_mae: 2.4269 - val_mse: 13.9669\n",
      "Epoch 803/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.4526 - mae: 2.4526 - mse: 13.3586 - val_loss: 2.4427 - val_mae: 2.4427 - val_mse: 14.3274\n",
      "Epoch 804/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3865 - mae: 2.3865 - mse: 13.1373 - val_loss: 2.5616 - val_mae: 2.5616 - val_mse: 14.9903\n",
      "Epoch 805/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3964 - mae: 2.3964 - mse: 12.9307 - val_loss: 2.4832 - val_mae: 2.4832 - val_mse: 14.2002\n",
      "Epoch 806/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3281 - mae: 2.3281 - mse: 12.5202 - val_loss: 2.4660 - val_mae: 2.4660 - val_mse: 13.6770\n",
      "Epoch 807/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.4187 - mae: 2.4187 - mse: 12.9482 - val_loss: 2.5404 - val_mae: 2.5404 - val_mse: 14.0205\n",
      "Epoch 808/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.4618 - mae: 2.4618 - mse: 13.3194 - val_loss: 2.4802 - val_mae: 2.4802 - val_mse: 13.7810\n",
      "Epoch 809/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4271 - mae: 2.4271 - mse: 13.4374 - val_loss: 2.5409 - val_mae: 2.5409 - val_mse: 14.9033\n",
      "Epoch 810/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3793 - mae: 2.3793 - mse: 12.8320 - val_loss: 2.4670 - val_mae: 2.4670 - val_mse: 14.2684\n",
      "Epoch 811/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3585 - mae: 2.3585 - mse: 12.5394 - val_loss: 2.4719 - val_mae: 2.4719 - val_mse: 14.0568\n",
      "Epoch 812/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3505 - mae: 2.3505 - mse: 12.6633 - val_loss: 2.4789 - val_mae: 2.4789 - val_mse: 14.2717\n",
      "Epoch 813/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4011 - mae: 2.4011 - mse: 12.9426 - val_loss: 2.4372 - val_mae: 2.4372 - val_mse: 14.2923\n",
      "Epoch 814/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3378 - mae: 2.3378 - mse: 12.6805 - val_loss: 2.5716 - val_mae: 2.5716 - val_mse: 14.1863\n",
      "Epoch 815/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4139 - mae: 2.4139 - mse: 13.2617 - val_loss: 2.4633 - val_mae: 2.4633 - val_mse: 13.9989\n",
      "Epoch 816/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3511 - mae: 2.3511 - mse: 12.7149 - val_loss: 2.5145 - val_mae: 2.5145 - val_mse: 13.7741\n",
      "Epoch 817/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3460 - mae: 2.3460 - mse: 12.6370 - val_loss: 2.4394 - val_mae: 2.4394 - val_mse: 13.8949\n",
      "Epoch 818/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4124 - mae: 2.4124 - mse: 12.9749 - val_loss: 2.6214 - val_mae: 2.6214 - val_mse: 14.5394\n",
      "Epoch 819/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3603 - mae: 2.3603 - mse: 12.8721 - val_loss: 2.4480 - val_mae: 2.4480 - val_mse: 13.8673\n",
      "Epoch 820/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3827 - mae: 2.3827 - mse: 12.7634 - val_loss: 2.4413 - val_mae: 2.4413 - val_mse: 13.6747\n",
      "Epoch 821/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3957 - mae: 2.3957 - mse: 13.0731 - val_loss: 2.5714 - val_mae: 2.5714 - val_mse: 14.3609\n",
      "Epoch 822/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3559 - mae: 2.3559 - mse: 12.6527 - val_loss: 2.4503 - val_mae: 2.4503 - val_mse: 14.3502\n",
      "Epoch 823/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.4801 - mae: 2.4801 - mse: 13.5852 - val_loss: 2.6985 - val_mae: 2.6985 - val_mse: 15.6774\n",
      "Epoch 824/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4985 - mae: 2.4985 - mse: 13.9289 - val_loss: 2.6159 - val_mae: 2.6159 - val_mse: 15.6352\n",
      "Epoch 825/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.4979 - mae: 2.4979 - mse: 13.9142 - val_loss: 2.5572 - val_mae: 2.5572 - val_mse: 14.9128\n",
      "Epoch 826/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4366 - mae: 2.4366 - mse: 13.4785 - val_loss: 2.7906 - val_mae: 2.7906 - val_mse: 15.8447\n",
      "Epoch 827/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4748 - mae: 2.4748 - mse: 13.7996 - val_loss: 2.5878 - val_mae: 2.5878 - val_mse: 14.2510\n",
      "Epoch 828/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4021 - mae: 2.4021 - mse: 13.0426 - val_loss: 2.5807 - val_mae: 2.5807 - val_mse: 14.9034\n",
      "Epoch 829/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4037 - mae: 2.4037 - mse: 12.9936 - val_loss: 2.4753 - val_mae: 2.4753 - val_mse: 13.6323\n",
      "Epoch 830/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.4336 - mae: 2.4336 - mse: 13.2283 - val_loss: 2.5196 - val_mae: 2.5196 - val_mse: 14.7828\n",
      "Epoch 831/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3980 - mae: 2.3980 - mse: 12.9925 - val_loss: 2.5042 - val_mae: 2.5042 - val_mse: 13.7390\n",
      "Epoch 832/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3463 - mae: 2.3463 - mse: 12.6746 - val_loss: 2.5033 - val_mae: 2.5033 - val_mse: 15.1154\n",
      "Epoch 833/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3564 - mae: 2.3564 - mse: 12.6779 - val_loss: 2.4766 - val_mae: 2.4766 - val_mse: 14.7074\n",
      "Epoch 834/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.4946 - mae: 2.4946 - mse: 13.5712 - val_loss: 2.4660 - val_mae: 2.4660 - val_mse: 14.5455\n",
      "Epoch 835/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3680 - mae: 2.3680 - mse: 12.6787 - val_loss: 2.7826 - val_mae: 2.7826 - val_mse: 16.1001\n",
      "Epoch 836/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3960 - mae: 2.3960 - mse: 12.9978 - val_loss: 2.4316 - val_mae: 2.4316 - val_mse: 13.5241\n",
      "Epoch 837/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3736 - mae: 2.3736 - mse: 12.8362 - val_loss: 2.4959 - val_mae: 2.4959 - val_mse: 14.3272\n",
      "Epoch 838/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3482 - mae: 2.3482 - mse: 12.6848 - val_loss: 2.4039 - val_mae: 2.4039 - val_mse: 13.6142\n",
      "Epoch 839/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 818us/sample - loss: 2.4249 - mae: 2.4249 - mse: 13.2233 - val_loss: 2.5867 - val_mae: 2.5867 - val_mse: 15.8413\n",
      "Epoch 840/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3816 - mae: 2.3816 - mse: 12.9364 - val_loss: 2.4786 - val_mae: 2.4786 - val_mse: 14.3171\n",
      "Epoch 841/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4199 - mae: 2.4199 - mse: 13.0789 - val_loss: 2.4306 - val_mae: 2.4306 - val_mse: 13.8680\n",
      "Epoch 842/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3741 - mae: 2.3741 - mse: 12.8480 - val_loss: 2.4997 - val_mae: 2.4997 - val_mse: 14.2207\n",
      "Epoch 843/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3508 - mae: 2.3508 - mse: 12.6729 - val_loss: 2.4911 - val_mae: 2.4911 - val_mse: 14.4487\n",
      "Epoch 844/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3731 - mae: 2.3731 - mse: 12.8943 - val_loss: 2.4152 - val_mae: 2.4152 - val_mse: 13.9039\n",
      "Epoch 845/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3648 - mae: 2.3648 - mse: 12.6280 - val_loss: 2.4478 - val_mae: 2.4478 - val_mse: 14.0206\n",
      "Epoch 846/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3962 - mae: 2.3962 - mse: 12.8726 - val_loss: 2.4537 - val_mae: 2.4537 - val_mse: 13.6280\n",
      "Epoch 847/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3953 - mae: 2.3953 - mse: 12.9835 - val_loss: 2.4660 - val_mae: 2.4660 - val_mse: 13.9727\n",
      "Epoch 848/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3602 - mae: 2.3602 - mse: 12.8856 - val_loss: 2.4477 - val_mae: 2.4477 - val_mse: 13.5727\n",
      "Epoch 849/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3639 - mae: 2.3639 - mse: 12.6029 - val_loss: 2.4525 - val_mae: 2.4525 - val_mse: 13.7749\n",
      "Epoch 850/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3577 - mae: 2.3577 - mse: 12.7283 - val_loss: 2.5012 - val_mae: 2.5012 - val_mse: 14.6815\n",
      "Epoch 851/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3602 - mae: 2.3602 - mse: 12.8574 - val_loss: 2.4576 - val_mae: 2.4576 - val_mse: 13.6868\n",
      "Epoch 852/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3734 - mae: 2.3734 - mse: 12.8244 - val_loss: 2.4644 - val_mae: 2.4644 - val_mse: 14.0814\n",
      "Epoch 853/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4900 - mae: 2.4900 - mse: 14.0683 - val_loss: 2.4546 - val_mae: 2.4546 - val_mse: 14.1659\n",
      "Epoch 854/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3725 - mae: 2.3725 - mse: 12.9141 - val_loss: 2.4331 - val_mae: 2.4331 - val_mse: 13.8120\n",
      "Epoch 855/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3576 - mae: 2.3576 - mse: 12.7593 - val_loss: 2.4307 - val_mae: 2.4307 - val_mse: 14.0009\n",
      "Epoch 856/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3751 - mae: 2.3751 - mse: 12.9576 - val_loss: 2.6384 - val_mae: 2.6384 - val_mse: 14.2288\n",
      "Epoch 857/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4255 - mae: 2.4255 - mse: 13.1768 - val_loss: 2.4623 - val_mae: 2.4623 - val_mse: 14.0751\n",
      "Epoch 858/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3517 - mae: 2.3517 - mse: 12.7877 - val_loss: 2.4530 - val_mae: 2.4530 - val_mse: 13.7906\n",
      "Epoch 859/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3377 - mae: 2.3377 - mse: 12.5603 - val_loss: 2.3836 - val_mae: 2.3836 - val_mse: 13.6147\n",
      "Epoch 860/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4153 - mae: 2.4153 - mse: 13.0146 - val_loss: 2.6255 - val_mae: 2.6255 - val_mse: 15.6721\n",
      "Epoch 861/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3794 - mae: 2.3794 - mse: 12.8450 - val_loss: 2.4692 - val_mae: 2.4692 - val_mse: 13.8230\n",
      "Epoch 862/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3984 - mae: 2.3984 - mse: 13.2187 - val_loss: 2.4407 - val_mae: 2.4407 - val_mse: 14.0786\n",
      "Epoch 863/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3680 - mae: 2.3680 - mse: 12.7783 - val_loss: 2.4286 - val_mae: 2.4286 - val_mse: 13.9112\n",
      "Epoch 864/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4418 - mae: 2.4418 - mse: 13.3599 - val_loss: 2.4853 - val_mae: 2.4853 - val_mse: 13.7717\n",
      "Epoch 865/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4034 - mae: 2.4034 - mse: 13.4202 - val_loss: 2.4577 - val_mae: 2.4577 - val_mse: 13.7683\n",
      "Epoch 866/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3848 - mae: 2.3848 - mse: 12.8112 - val_loss: 2.4434 - val_mae: 2.4434 - val_mse: 13.8478\n",
      "Epoch 867/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3978 - mae: 2.3978 - mse: 13.0950 - val_loss: 2.4843 - val_mae: 2.4843 - val_mse: 14.7579\n",
      "Epoch 868/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3476 - mae: 2.3476 - mse: 12.6886 - val_loss: 2.4008 - val_mae: 2.4008 - val_mse: 13.8244\n",
      "Epoch 869/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3643 - mae: 2.3643 - mse: 12.7317 - val_loss: 2.4464 - val_mae: 2.4464 - val_mse: 14.2437\n",
      "Epoch 870/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3841 - mae: 2.3841 - mse: 13.1130 - val_loss: 2.4426 - val_mae: 2.4426 - val_mse: 13.6358\n",
      "Epoch 871/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3782 - mae: 2.3782 - mse: 12.7279 - val_loss: 2.4194 - val_mae: 2.4194 - val_mse: 13.8982\n",
      "Epoch 872/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3319 - mae: 2.3319 - mse: 12.6149 - val_loss: 2.4601 - val_mae: 2.4601 - val_mse: 14.2407\n",
      "Epoch 873/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3476 - mae: 2.3476 - mse: 12.6594 - val_loss: 2.7103 - val_mae: 2.7103 - val_mse: 15.1236\n",
      "Epoch 874/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.5445 - mae: 2.5445 - mse: 14.0993 - val_loss: 2.6105 - val_mae: 2.6105 - val_mse: 15.3502\n",
      "Epoch 875/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3895 - mae: 2.3895 - mse: 12.8915 - val_loss: 2.4924 - val_mae: 2.4924 - val_mse: 13.9000\n",
      "Epoch 876/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3501 - mae: 2.3501 - mse: 12.6426 - val_loss: 2.4384 - val_mae: 2.4384 - val_mse: 13.6679\n",
      "Epoch 877/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3212 - mae: 2.3212 - mse: 12.4781 - val_loss: 2.4285 - val_mae: 2.4285 - val_mse: 13.6797\n",
      "Epoch 878/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3361 - mae: 2.3361 - mse: 12.5288 - val_loss: 2.5194 - val_mae: 2.5194 - val_mse: 14.7542\n",
      "Epoch 879/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3802 - mae: 2.3802 - mse: 12.8031 - val_loss: 2.4469 - val_mae: 2.4469 - val_mse: 13.8382\n",
      "Epoch 880/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4619 - mae: 2.4619 - mse: 13.6041 - val_loss: 2.7562 - val_mae: 2.7562 - val_mse: 15.9843\n",
      "Epoch 881/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4398 - mae: 2.4398 - mse: 13.2236 - val_loss: 2.5273 - val_mae: 2.5273 - val_mse: 14.5621\n",
      "Epoch 882/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3876 - mae: 2.3876 - mse: 12.9150 - val_loss: 2.4698 - val_mae: 2.4698 - val_mse: 13.9476\n",
      "Epoch 883/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3792 - mae: 2.3792 - mse: 12.8773 - val_loss: 2.4443 - val_mae: 2.4443 - val_mse: 13.7895\n",
      "Epoch 884/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.3556 - mae: 2.3556 - mse: 12.6711 - val_loss: 2.4694 - val_mae: 2.4694 - val_mse: 14.1081\n",
      "Epoch 885/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3792 - mae: 2.3792 - mse: 12.8314 - val_loss: 2.4223 - val_mae: 2.4223 - val_mse: 13.8101\n",
      "Epoch 886/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3784 - mae: 2.3784 - mse: 13.1092 - val_loss: 2.4668 - val_mae: 2.4668 - val_mse: 14.6888\n",
      "Epoch 887/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3714 - mae: 2.3714 - mse: 12.8324 - val_loss: 2.4954 - val_mae: 2.4954 - val_mse: 13.7624\n",
      "Epoch 888/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3856 - mae: 2.3856 - mse: 12.8964 - val_loss: 2.6279 - val_mae: 2.6279 - val_mse: 16.0589\n",
      "Epoch 889/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3509 - mae: 2.3509 - mse: 12.6791 - val_loss: 2.4467 - val_mae: 2.4467 - val_mse: 13.7947\n",
      "Epoch 890/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3551 - mae: 2.3551 - mse: 12.6891 - val_loss: 2.4387 - val_mae: 2.4387 - val_mse: 13.8836\n",
      "Epoch 891/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3982 - mae: 2.3982 - mse: 13.0697 - val_loss: 2.5922 - val_mae: 2.5922 - val_mse: 14.6221\n",
      "Epoch 892/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4147 - mae: 2.4147 - mse: 13.1587 - val_loss: 2.5349 - val_mae: 2.5349 - val_mse: 14.3298\n",
      "Epoch 893/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.4741 - mae: 2.4741 - mse: 13.6280 - val_loss: 2.5359 - val_mae: 2.5359 - val_mse: 14.7109\n",
      "Epoch 894/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4267 - mae: 2.4267 - mse: 13.1769 - val_loss: 2.4912 - val_mae: 2.4912 - val_mse: 14.5189\n",
      "Epoch 895/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.3968 - mae: 2.3968 - mse: 12.8696 - val_loss: 2.5146 - val_mae: 2.5146 - val_mse: 15.1503\n",
      "Epoch 896/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3638 - mae: 2.3638 - mse: 13.0182 - val_loss: 2.4052 - val_mae: 2.4052 - val_mse: 13.9520\n",
      "Epoch 897/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3413 - mae: 2.3413 - mse: 12.6943 - val_loss: 2.4653 - val_mae: 2.4653 - val_mse: 14.3667\n",
      "Epoch 898/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.4119 - mae: 2.4119 - mse: 13.0284 - val_loss: 2.4757 - val_mae: 2.4757 - val_mse: 14.2540\n",
      "Epoch 899/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4059 - mae: 2.4059 - mse: 13.0489 - val_loss: 2.5431 - val_mae: 2.5431 - val_mse: 14.6780\n",
      "Epoch 900/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3501 - mae: 2.3501 - mse: 12.6086 - val_loss: 2.4090 - val_mae: 2.4090 - val_mse: 13.9649\n",
      "Epoch 901/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3273 - mae: 2.3273 - mse: 12.6164 - val_loss: 2.4069 - val_mae: 2.4069 - val_mse: 13.6031\n",
      "Epoch 902/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3623 - mae: 2.3623 - mse: 12.8675 - val_loss: 2.4192 - val_mae: 2.4192 - val_mse: 14.0368\n",
      "Epoch 903/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3252 - mae: 2.3252 - mse: 12.5587 - val_loss: 2.4537 - val_mae: 2.4537 - val_mse: 14.1513\n",
      "Epoch 904/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3366 - mae: 2.3366 - mse: 12.5062 - val_loss: 2.4676 - val_mae: 2.4676 - val_mse: 13.5448\n",
      "Epoch 905/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3887 - mae: 2.3887 - mse: 12.8316 - val_loss: 2.6668 - val_mae: 2.6668 - val_mse: 14.8731\n",
      "Epoch 906/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4263 - mae: 2.4263 - mse: 13.1967 - val_loss: 2.4468 - val_mae: 2.4468 - val_mse: 13.8536\n",
      "Epoch 907/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3608 - mae: 2.3608 - mse: 12.6339 - val_loss: 2.4481 - val_mae: 2.4481 - val_mse: 13.5718\n",
      "Epoch 908/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3724 - mae: 2.3724 - mse: 12.8005 - val_loss: 2.4622 - val_mae: 2.4622 - val_mse: 14.3164\n",
      "Epoch 909/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3813 - mae: 2.3813 - mse: 12.7437 - val_loss: 2.5953 - val_mae: 2.5953 - val_mse: 16.7736\n",
      "Epoch 910/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.4398 - mae: 2.4398 - mse: 13.3552 - val_loss: 2.4711 - val_mae: 2.4711 - val_mse: 14.2678\n",
      "Epoch 911/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3571 - mae: 2.3571 - mse: 12.7976 - val_loss: 2.4306 - val_mae: 2.4306 - val_mse: 13.5428\n",
      "Epoch 912/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3945 - mae: 2.3945 - mse: 12.8554 - val_loss: 2.5815 - val_mae: 2.5815 - val_mse: 14.2228\n",
      "Epoch 913/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3837 - mae: 2.3837 - mse: 12.9588 - val_loss: 2.5991 - val_mae: 2.5991 - val_mse: 14.5417\n",
      "Epoch 914/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3780 - mae: 2.3780 - mse: 12.8539 - val_loss: 2.5056 - val_mae: 2.5056 - val_mse: 14.2206\n",
      "Epoch 915/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3881 - mae: 2.3881 - mse: 12.8766 - val_loss: 2.4578 - val_mae: 2.4578 - val_mse: 14.0338\n",
      "Epoch 916/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4210 - mae: 2.4210 - mse: 13.2298 - val_loss: 2.4770 - val_mae: 2.4770 - val_mse: 13.8773\n",
      "Epoch 917/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3353 - mae: 2.3353 - mse: 12.5075 - val_loss: 2.4744 - val_mae: 2.4744 - val_mse: 13.7240\n",
      "Epoch 918/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3551 - mae: 2.3551 - mse: 12.7647 - val_loss: 2.4686 - val_mae: 2.4686 - val_mse: 13.7216\n",
      "Epoch 919/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4053 - mae: 2.4053 - mse: 13.0875 - val_loss: 2.5191 - val_mae: 2.5191 - val_mse: 13.9956\n",
      "Epoch 920/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3770 - mae: 2.3770 - mse: 12.7854 - val_loss: 2.6375 - val_mae: 2.6375 - val_mse: 15.9714\n",
      "Epoch 921/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4568 - mae: 2.4568 - mse: 13.7716 - val_loss: 2.3971 - val_mae: 2.3971 - val_mse: 13.7908\n",
      "Epoch 922/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3949 - mae: 2.3949 - mse: 12.8704 - val_loss: 2.4596 - val_mae: 2.4596 - val_mse: 13.9876\n",
      "Epoch 923/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3292 - mae: 2.3292 - mse: 12.5099 - val_loss: 2.4117 - val_mae: 2.4117 - val_mse: 13.5566\n",
      "Epoch 924/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3782 - mae: 2.3782 - mse: 12.8954 - val_loss: 2.4642 - val_mae: 2.4642 - val_mse: 14.0496\n",
      "Epoch 925/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3367 - mae: 2.3367 - mse: 12.6330 - val_loss: 2.4451 - val_mae: 2.4451 - val_mse: 13.9957\n",
      "Epoch 926/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3789 - mae: 2.3789 - mse: 12.6836 - val_loss: 2.5161 - val_mae: 2.5161 - val_mse: 14.6837\n",
      "Epoch 927/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.4167 - mae: 2.4167 - mse: 13.5652 - val_loss: 2.4901 - val_mae: 2.4901 - val_mse: 15.0883\n",
      "Epoch 928/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4268 - mae: 2.4268 - mse: 13.2372 - val_loss: 2.6139 - val_mae: 2.6139 - val_mse: 16.1375\n",
      "Epoch 929/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4168 - mae: 2.4168 - mse: 13.3170 - val_loss: 2.4652 - val_mae: 2.4652 - val_mse: 14.0990\n",
      "Epoch 930/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4735 - mae: 2.4735 - mse: 13.7854 - val_loss: 2.6297 - val_mae: 2.6297 - val_mse: 18.1805\n",
      "Epoch 931/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3816 - mae: 2.3816 - mse: 13.0924 - val_loss: 2.4725 - val_mae: 2.4725 - val_mse: 14.1668\n",
      "Epoch 932/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3771 - mae: 2.3771 - mse: 12.7016 - val_loss: 2.3973 - val_mae: 2.3973 - val_mse: 13.5863\n",
      "Epoch 933/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 803us/sample - loss: 2.3254 - mae: 2.3254 - mse: 12.3491 - val_loss: 2.4166 - val_mae: 2.4166 - val_mse: 13.4166\n",
      "Epoch 934/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3550 - mae: 2.3550 - mse: 12.6906 - val_loss: 2.4754 - val_mae: 2.4754 - val_mse: 14.0823\n",
      "Epoch 935/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3401 - mae: 2.3401 - mse: 12.6186 - val_loss: 2.4189 - val_mae: 2.4189 - val_mse: 13.9602\n",
      "Epoch 936/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3291 - mae: 2.3291 - mse: 12.4815 - val_loss: 2.4326 - val_mae: 2.4326 - val_mse: 13.8667\n",
      "Epoch 937/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3394 - mae: 2.3394 - mse: 12.5421 - val_loss: 2.4754 - val_mae: 2.4754 - val_mse: 14.2698\n",
      "Epoch 938/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3202 - mae: 2.3202 - mse: 12.4545 - val_loss: 2.5081 - val_mae: 2.5081 - val_mse: 14.6532\n",
      "Epoch 939/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3241 - mae: 2.3241 - mse: 12.4874 - val_loss: 2.4182 - val_mae: 2.4182 - val_mse: 13.6749\n",
      "Epoch 940/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3254 - mae: 2.3254 - mse: 12.5049 - val_loss: 2.4544 - val_mae: 2.4544 - val_mse: 14.1075\n",
      "Epoch 941/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3420 - mae: 2.3420 - mse: 12.5452 - val_loss: 2.4267 - val_mae: 2.4267 - val_mse: 13.9566\n",
      "Epoch 942/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3638 - mae: 2.3638 - mse: 12.8441 - val_loss: 2.4380 - val_mae: 2.4380 - val_mse: 14.0165\n",
      "Epoch 943/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3325 - mae: 2.3325 - mse: 12.5167 - val_loss: 2.5214 - val_mae: 2.5214 - val_mse: 14.5222\n",
      "Epoch 944/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3804 - mae: 2.3804 - mse: 12.8965 - val_loss: 2.5128 - val_mae: 2.5128 - val_mse: 15.0998\n",
      "Epoch 945/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3816 - mae: 2.3816 - mse: 13.0128 - val_loss: 2.4270 - val_mae: 2.4270 - val_mse: 14.5039\n",
      "Epoch 946/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4107 - mae: 2.4107 - mse: 12.9866 - val_loss: 2.5232 - val_mae: 2.5232 - val_mse: 14.3636\n",
      "Epoch 947/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3669 - mae: 2.3669 - mse: 12.7892 - val_loss: 2.3794 - val_mae: 2.3794 - val_mse: 13.6426\n",
      "Epoch 948/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3457 - mae: 2.3457 - mse: 12.5756 - val_loss: 2.4063 - val_mae: 2.4063 - val_mse: 13.6941\n",
      "Epoch 949/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3340 - mae: 2.3340 - mse: 12.6070 - val_loss: 2.5014 - val_mae: 2.5014 - val_mse: 14.9759\n",
      "Epoch 950/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3523 - mae: 2.3523 - mse: 12.7144 - val_loss: 2.4696 - val_mae: 2.4696 - val_mse: 13.9223\n",
      "Epoch 951/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.3804 - mae: 2.3804 - mse: 12.8761 - val_loss: 2.4723 - val_mae: 2.4723 - val_mse: 14.1521\n",
      "Epoch 952/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.4279 - mae: 2.4279 - mse: 13.3500 - val_loss: 2.5420 - val_mae: 2.5420 - val_mse: 14.0385\n",
      "Epoch 953/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3810 - mae: 2.3810 - mse: 12.8737 - val_loss: 2.5812 - val_mae: 2.5812 - val_mse: 15.6926\n",
      "Epoch 954/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4790 - mae: 2.4790 - mse: 13.3704 - val_loss: 2.4548 - val_mae: 2.4548 - val_mse: 13.9461\n",
      "Epoch 955/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4266 - mae: 2.4266 - mse: 13.1935 - val_loss: 2.5786 - val_mae: 2.5786 - val_mse: 16.0059\n",
      "Epoch 956/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4274 - mae: 2.4274 - mse: 13.1322 - val_loss: 2.4478 - val_mae: 2.4478 - val_mse: 14.2382\n",
      "Epoch 957/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4430 - mae: 2.4430 - mse: 13.4050 - val_loss: 2.4456 - val_mae: 2.4456 - val_mse: 14.3459\n",
      "Epoch 958/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3656 - mae: 2.3656 - mse: 12.8602 - val_loss: 2.4063 - val_mae: 2.4063 - val_mse: 13.6657\n",
      "Epoch 959/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3208 - mae: 2.3208 - mse: 12.4660 - val_loss: 2.3833 - val_mae: 2.3833 - val_mse: 13.4758\n",
      "Epoch 960/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3681 - mae: 2.3681 - mse: 12.6740 - val_loss: 2.4347 - val_mae: 2.4347 - val_mse: 13.7781\n",
      "Epoch 961/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3123 - mae: 2.3123 - mse: 12.4036 - val_loss: 2.4347 - val_mae: 2.4347 - val_mse: 13.7416\n",
      "Epoch 962/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3007 - mae: 2.3007 - mse: 12.3681 - val_loss: 2.4406 - val_mae: 2.4406 - val_mse: 13.9266\n",
      "Epoch 963/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4158 - mae: 2.4158 - mse: 13.1184 - val_loss: 2.6235 - val_mae: 2.6235 - val_mse: 14.5794\n",
      "Epoch 964/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.5032 - mae: 2.5032 - mse: 13.9096 - val_loss: 2.4726 - val_mae: 2.4726 - val_mse: 14.0691\n",
      "Epoch 965/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4012 - mae: 2.4012 - mse: 13.1109 - val_loss: 2.4588 - val_mae: 2.4588 - val_mse: 14.2517\n",
      "Epoch 966/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3662 - mae: 2.3662 - mse: 12.9494 - val_loss: 2.4338 - val_mae: 2.4338 - val_mse: 14.1481\n",
      "Epoch 967/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3766 - mae: 2.3766 - mse: 12.8395 - val_loss: 2.4425 - val_mae: 2.4425 - val_mse: 14.0153\n",
      "Epoch 968/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3359 - mae: 2.3359 - mse: 12.7456 - val_loss: 2.4471 - val_mae: 2.4471 - val_mse: 14.1621\n",
      "Epoch 969/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4114 - mae: 2.4114 - mse: 13.1957 - val_loss: 2.6631 - val_mae: 2.6631 - val_mse: 14.2424\n",
      "Epoch 970/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3880 - mae: 2.3880 - mse: 12.9812 - val_loss: 2.4512 - val_mae: 2.4512 - val_mse: 14.1643\n",
      "Epoch 971/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3232 - mae: 2.3232 - mse: 12.5400 - val_loss: 2.4285 - val_mae: 2.4285 - val_mse: 13.6552\n",
      "Epoch 972/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3248 - mae: 2.3248 - mse: 12.4509 - val_loss: 2.4004 - val_mae: 2.4004 - val_mse: 13.5375\n",
      "Epoch 973/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3058 - mae: 2.3058 - mse: 12.4419 - val_loss: 2.3895 - val_mae: 2.3895 - val_mse: 13.5986\n",
      "Epoch 974/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3273 - mae: 2.3273 - mse: 12.6445 - val_loss: 2.4276 - val_mae: 2.4276 - val_mse: 13.6351\n",
      "Epoch 975/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3230 - mae: 2.3230 - mse: 12.4387 - val_loss: 2.4274 - val_mae: 2.4274 - val_mse: 13.6473\n",
      "Epoch 976/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3241 - mae: 2.3241 - mse: 12.4917 - val_loss: 2.4204 - val_mae: 2.4204 - val_mse: 13.6346\n",
      "Epoch 977/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3376 - mae: 2.3376 - mse: 12.5451 - val_loss: 2.4345 - val_mae: 2.4345 - val_mse: 14.0004\n",
      "Epoch 978/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 2.3888 - mae: 2.3888 - mse: 12.9263 - val_loss: 2.5226 - val_mae: 2.5226 - val_mse: 15.9236\n",
      "Epoch 979/2500\n",
      "684/684 [==============================] - 1s 826us/sample - loss: 2.3806 - mae: 2.3806 - mse: 12.7639 - val_loss: 2.5437 - val_mae: 2.5437 - val_mse: 13.7602\n",
      "Epoch 980/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3975 - mae: 2.3975 - mse: 13.0691 - val_loss: 2.6290 - val_mae: 2.6290 - val_mse: 15.4513\n",
      "Epoch 981/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3636 - mae: 2.3636 - mse: 12.7535 - val_loss: 2.4581 - val_mae: 2.4581 - val_mse: 14.0194\n",
      "Epoch 982/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3428 - mae: 2.3428 - mse: 12.6693 - val_loss: 2.5460 - val_mae: 2.5460 - val_mse: 14.5062\n",
      "Epoch 983/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3582 - mae: 2.3582 - mse: 12.7610 - val_loss: 2.5180 - val_mae: 2.5180 - val_mse: 14.3211\n",
      "Epoch 984/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.4509 - mae: 2.4509 - mse: 13.4160 - val_loss: 2.6241 - val_mae: 2.6241 - val_mse: 14.8978\n",
      "Epoch 985/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3626 - mae: 2.3626 - mse: 12.7703 - val_loss: 2.4745 - val_mae: 2.4745 - val_mse: 13.5680\n",
      "Epoch 986/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3645 - mae: 2.3645 - mse: 12.8861 - val_loss: 2.5066 - val_mae: 2.5066 - val_mse: 14.2504\n",
      "Epoch 987/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3442 - mae: 2.3442 - mse: 12.7151 - val_loss: 2.4250 - val_mae: 2.4250 - val_mse: 14.3502\n",
      "Epoch 988/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3558 - mae: 2.3558 - mse: 12.7181 - val_loss: 2.4498 - val_mae: 2.4498 - val_mse: 13.9147\n",
      "Epoch 989/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3360 - mae: 2.3360 - mse: 12.7244 - val_loss: 2.4159 - val_mae: 2.4159 - val_mse: 13.4662\n",
      "Epoch 990/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3387 - mae: 2.3387 - mse: 12.6884 - val_loss: 2.4372 - val_mae: 2.4372 - val_mse: 14.5826\n",
      "Epoch 991/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3575 - mae: 2.3575 - mse: 12.7626 - val_loss: 2.4495 - val_mae: 2.4495 - val_mse: 14.0622\n",
      "Epoch 992/2500\n",
      "684/684 [==============================] - 1s 832us/sample - loss: 2.3842 - mae: 2.3842 - mse: 12.8124 - val_loss: 2.4579 - val_mae: 2.4579 - val_mse: 13.6320\n",
      "Epoch 993/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3631 - mae: 2.3631 - mse: 12.5996 - val_loss: 2.3943 - val_mae: 2.3943 - val_mse: 13.6651\n",
      "Epoch 994/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3414 - mae: 2.3414 - mse: 12.6893 - val_loss: 2.6164 - val_mae: 2.6164 - val_mse: 14.2504\n",
      "Epoch 995/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3654 - mae: 2.3654 - mse: 12.6509 - val_loss: 2.4139 - val_mae: 2.4139 - val_mse: 13.7694\n",
      "Epoch 996/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4431 - mae: 2.4431 - mse: 13.2896 - val_loss: 2.5377 - val_mae: 2.5377 - val_mse: 14.8489\n",
      "Epoch 997/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3619 - mae: 2.3619 - mse: 12.7942 - val_loss: 2.4070 - val_mae: 2.4070 - val_mse: 13.8737\n",
      "Epoch 998/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3475 - mae: 2.3475 - mse: 12.5544 - val_loss: 2.5709 - val_mae: 2.5709 - val_mse: 16.1391\n",
      "Epoch 999/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4497 - mae: 2.4497 - mse: 14.0219 - val_loss: 2.6648 - val_mae: 2.6648 - val_mse: 15.6037\n",
      "Epoch 1000/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4512 - mae: 2.4512 - mse: 13.5724 - val_loss: 2.4414 - val_mae: 2.4414 - val_mse: 13.9912\n",
      "Epoch 1001/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3382 - mae: 2.3382 - mse: 12.7229 - val_loss: 2.5107 - val_mae: 2.5107 - val_mse: 13.9157\n",
      "Epoch 1002/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4210 - mae: 2.4210 - mse: 13.3009 - val_loss: 2.4923 - val_mae: 2.4923 - val_mse: 13.9430\n",
      "Epoch 1003/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3876 - mae: 2.3876 - mse: 13.0219 - val_loss: 2.6344 - val_mae: 2.6344 - val_mse: 14.8213\n",
      "Epoch 1004/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.4251 - mae: 2.4251 - mse: 13.0659 - val_loss: 2.4009 - val_mae: 2.4009 - val_mse: 13.6386\n",
      "Epoch 1005/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3631 - mae: 2.3631 - mse: 12.7076 - val_loss: 2.4035 - val_mae: 2.4035 - val_mse: 13.7287\n",
      "Epoch 1006/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3507 - mae: 2.3507 - mse: 12.7157 - val_loss: 2.4352 - val_mae: 2.4352 - val_mse: 13.8934\n",
      "Epoch 1007/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3511 - mae: 2.3511 - mse: 12.8617 - val_loss: 2.4614 - val_mae: 2.4614 - val_mse: 14.1681\n",
      "Epoch 1008/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.4069 - mae: 2.4069 - mse: 13.0781 - val_loss: 2.4408 - val_mae: 2.4408 - val_mse: 13.6817\n",
      "Epoch 1009/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3662 - mae: 2.3662 - mse: 12.6475 - val_loss: 2.4147 - val_mae: 2.4147 - val_mse: 13.6549\n",
      "Epoch 1010/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3213 - mae: 2.3213 - mse: 12.4961 - val_loss: 2.5373 - val_mae: 2.5373 - val_mse: 14.7206\n",
      "Epoch 1011/2500\n",
      "684/684 [==============================] - 1s 845us/sample - loss: 2.4160 - mae: 2.4160 - mse: 13.0903 - val_loss: 2.6096 - val_mae: 2.6096 - val_mse: 14.2242\n",
      "Epoch 1012/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3617 - mae: 2.3617 - mse: 12.7386 - val_loss: 2.4345 - val_mae: 2.4345 - val_mse: 14.0562\n",
      "Epoch 1013/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3432 - mae: 2.3432 - mse: 12.7518 - val_loss: 2.4889 - val_mae: 2.4889 - val_mse: 13.6368\n",
      "Epoch 1014/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3653 - mae: 2.3653 - mse: 12.9540 - val_loss: 2.3855 - val_mae: 2.3855 - val_mse: 13.7928\n",
      "Epoch 1015/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3254 - mae: 2.3254 - mse: 12.5022 - val_loss: 2.4011 - val_mae: 2.4011 - val_mse: 13.6456\n",
      "Epoch 1016/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3045 - mae: 2.3045 - mse: 12.3820 - val_loss: 2.4536 - val_mae: 2.4536 - val_mse: 13.8771\n",
      "Epoch 1017/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3276 - mae: 2.3276 - mse: 12.6156 - val_loss: 2.4130 - val_mae: 2.4130 - val_mse: 13.6863\n",
      "Epoch 1018/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3345 - mae: 2.3345 - mse: 12.4996 - val_loss: 2.5973 - val_mae: 2.5973 - val_mse: 14.1438\n",
      "Epoch 1019/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3857 - mae: 2.3857 - mse: 12.9391 - val_loss: 2.4139 - val_mae: 2.4139 - val_mse: 13.9432\n",
      "Epoch 1020/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3644 - mae: 2.3644 - mse: 12.7738 - val_loss: 2.4212 - val_mae: 2.4212 - val_mse: 13.8491\n",
      "Epoch 1021/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3301 - mae: 2.3301 - mse: 12.6992 - val_loss: 2.3973 - val_mae: 2.3973 - val_mse: 13.4941\n",
      "Epoch 1022/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3447 - mae: 2.3447 - mse: 12.7389 - val_loss: 2.4402 - val_mae: 2.4402 - val_mse: 13.8581\n",
      "Epoch 1023/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3535 - mae: 2.3535 - mse: 12.7683 - val_loss: 2.4273 - val_mae: 2.4273 - val_mse: 13.6445\n",
      "Epoch 1024/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3160 - mae: 2.3160 - mse: 12.4572 - val_loss: 2.4542 - val_mae: 2.4542 - val_mse: 13.8386\n",
      "Epoch 1025/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3620 - mae: 2.3620 - mse: 12.7323 - val_loss: 2.4512 - val_mae: 2.4512 - val_mse: 13.6868\n",
      "Epoch 1026/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3795 - mae: 2.3795 - mse: 12.8598 - val_loss: 2.6740 - val_mae: 2.6740 - val_mse: 15.0649\n",
      "Epoch 1027/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3649 - mae: 2.3649 - mse: 12.7008 - val_loss: 2.4270 - val_mae: 2.4270 - val_mse: 13.6999\n",
      "Epoch 1028/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3401 - mae: 2.3401 - mse: 12.5455 - val_loss: 2.3954 - val_mae: 2.3954 - val_mse: 13.5365\n",
      "Epoch 1029/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3187 - mae: 2.3187 - mse: 12.4380 - val_loss: 2.4717 - val_mae: 2.4717 - val_mse: 13.6921\n",
      "Epoch 1030/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3341 - mae: 2.3341 - mse: 12.6003 - val_loss: 2.4338 - val_mae: 2.4338 - val_mse: 13.6891\n",
      "Epoch 1031/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3264 - mae: 2.3264 - mse: 12.4822 - val_loss: 2.4017 - val_mae: 2.4017 - val_mse: 13.8308\n",
      "Epoch 1032/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3315 - mae: 2.3315 - mse: 12.5341 - val_loss: 2.4364 - val_mae: 2.4364 - val_mse: 14.4061\n",
      "Epoch 1033/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3225 - mae: 2.3225 - mse: 12.5879 - val_loss: 2.4358 - val_mae: 2.4358 - val_mse: 13.6504\n",
      "Epoch 1034/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3602 - mae: 2.3602 - mse: 12.7103 - val_loss: 2.4479 - val_mae: 2.4479 - val_mse: 14.2050\n",
      "Epoch 1035/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3564 - mae: 2.3564 - mse: 12.8096 - val_loss: 2.4967 - val_mae: 2.4967 - val_mse: 14.1171\n",
      "Epoch 1036/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3583 - mae: 2.3583 - mse: 12.7982 - val_loss: 2.5106 - val_mae: 2.5106 - val_mse: 15.1345\n",
      "Epoch 1037/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.4262 - mae: 2.4262 - mse: 13.1137 - val_loss: 2.3993 - val_mae: 2.3993 - val_mse: 13.6578\n",
      "Epoch 1038/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3921 - mae: 2.3921 - mse: 13.1119 - val_loss: 2.4707 - val_mae: 2.4707 - val_mse: 14.0730\n",
      "Epoch 1039/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3606 - mae: 2.3606 - mse: 12.9485 - val_loss: 2.4392 - val_mae: 2.4392 - val_mse: 14.1478\n",
      "Epoch 1040/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3817 - mae: 2.3817 - mse: 13.0906 - val_loss: 2.4501 - val_mae: 2.4501 - val_mse: 13.8261\n",
      "Epoch 1041/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3739 - mae: 2.3739 - mse: 12.7555 - val_loss: 2.4517 - val_mae: 2.4517 - val_mse: 13.7643\n",
      "Epoch 1042/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4306 - mae: 2.4306 - mse: 13.4621 - val_loss: 2.4230 - val_mae: 2.4230 - val_mse: 13.9059\n",
      "Epoch 1043/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3821 - mae: 2.3821 - mse: 13.0303 - val_loss: 2.4426 - val_mae: 2.4426 - val_mse: 14.1877\n",
      "Epoch 1044/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3262 - mae: 2.3262 - mse: 12.6531 - val_loss: 2.4302 - val_mae: 2.4302 - val_mse: 13.9498\n",
      "Epoch 1045/2500\n",
      "684/684 [==============================] - 1s 834us/sample - loss: 2.3477 - mae: 2.3477 - mse: 12.5899 - val_loss: 2.4163 - val_mae: 2.4163 - val_mse: 13.5600\n",
      "Epoch 1046/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3576 - mae: 2.3576 - mse: 12.5864 - val_loss: 2.5671 - val_mae: 2.5671 - val_mse: 14.9076\n",
      "Epoch 1047/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3937 - mae: 2.3937 - mse: 12.9882 - val_loss: 2.4596 - val_mae: 2.4596 - val_mse: 14.4877\n",
      "Epoch 1048/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3189 - mae: 2.3189 - mse: 12.4995 - val_loss: 2.4020 - val_mae: 2.4020 - val_mse: 13.6816\n",
      "Epoch 1049/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3077 - mae: 2.3077 - mse: 12.4341 - val_loss: 2.4101 - val_mae: 2.4101 - val_mse: 13.5109\n",
      "Epoch 1050/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3377 - mae: 2.3377 - mse: 12.6419 - val_loss: 2.4808 - val_mae: 2.4808 - val_mse: 14.4406\n",
      "Epoch 1051/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3316 - mae: 2.3316 - mse: 12.6707 - val_loss: 2.4159 - val_mae: 2.4159 - val_mse: 14.1824\n",
      "Epoch 1052/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.3969 - mae: 2.3969 - mse: 12.9646 - val_loss: 2.4147 - val_mae: 2.4147 - val_mse: 13.8584\n",
      "Epoch 1053/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4512 - mae: 2.4512 - mse: 13.6750 - val_loss: 2.4777 - val_mae: 2.4777 - val_mse: 14.1577\n",
      "Epoch 1054/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3207 - mae: 2.3207 - mse: 12.4969 - val_loss: 2.4712 - val_mae: 2.4712 - val_mse: 13.9745\n",
      "Epoch 1055/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3402 - mae: 2.3402 - mse: 12.6672 - val_loss: 2.4093 - val_mae: 2.4093 - val_mse: 13.6438\n",
      "Epoch 1056/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4009 - mae: 2.4009 - mse: 12.9600 - val_loss: 2.5219 - val_mae: 2.5219 - val_mse: 15.1617\n",
      "Epoch 1057/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3834 - mae: 2.3834 - mse: 12.9577 - val_loss: 2.5431 - val_mae: 2.5431 - val_mse: 14.8830\n",
      "Epoch 1058/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3550 - mae: 2.3550 - mse: 12.6688 - val_loss: 2.4177 - val_mae: 2.4177 - val_mse: 14.1571\n",
      "Epoch 1059/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.4124 - mae: 2.4124 - mse: 13.0975 - val_loss: 2.3962 - val_mae: 2.3962 - val_mse: 13.5700\n",
      "Epoch 1060/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3149 - mae: 2.3149 - mse: 12.4450 - val_loss: 2.5508 - val_mae: 2.5508 - val_mse: 14.0454\n",
      "Epoch 1061/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3628 - mae: 2.3628 - mse: 12.7490 - val_loss: 2.4319 - val_mae: 2.4319 - val_mse: 13.8760\n",
      "Epoch 1062/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.3478 - mae: 2.3478 - mse: 12.6231 - val_loss: 2.4275 - val_mae: 2.4275 - val_mse: 13.9806\n",
      "Epoch 1063/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3377 - mae: 2.3377 - mse: 12.6523 - val_loss: 2.4100 - val_mae: 2.4100 - val_mse: 13.6128\n",
      "Epoch 1064/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3494 - mae: 2.3494 - mse: 12.7064 - val_loss: 2.5032 - val_mae: 2.5032 - val_mse: 14.5818\n",
      "Epoch 1065/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3712 - mae: 2.3712 - mse: 12.8613 - val_loss: 2.5189 - val_mae: 2.5189 - val_mse: 14.9039\n",
      "Epoch 1066/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4683 - mae: 2.4683 - mse: 13.3281 - val_loss: 2.4019 - val_mae: 2.4019 - val_mse: 13.6546\n",
      "Epoch 1067/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3193 - mae: 2.3193 - mse: 12.4091 - val_loss: 2.4556 - val_mae: 2.4556 - val_mse: 14.3804\n",
      "Epoch 1068/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3385 - mae: 2.3385 - mse: 12.6247 - val_loss: 2.5081 - val_mae: 2.5081 - val_mse: 15.3260\n",
      "Epoch 1069/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3188 - mae: 2.3188 - mse: 12.4290 - val_loss: 2.4706 - val_mae: 2.4706 - val_mse: 14.5195\n",
      "Epoch 1070/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3453 - mae: 2.3453 - mse: 12.5427 - val_loss: 2.3927 - val_mae: 2.3927 - val_mse: 13.3990\n",
      "Epoch 1071/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3934 - mae: 2.3934 - mse: 13.0789 - val_loss: 2.5491 - val_mae: 2.5491 - val_mse: 14.8450\n",
      "Epoch 1072/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3315 - mae: 2.3315 - mse: 12.5032 - val_loss: 2.4310 - val_mae: 2.4310 - val_mse: 13.8970\n",
      "Epoch 1073/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3282 - mae: 2.3282 - mse: 12.6672 - val_loss: 2.5568 - val_mae: 2.5568 - val_mse: 13.6995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1074/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3681 - mae: 2.3681 - mse: 12.6489 - val_loss: 2.7676 - val_mae: 2.7676 - val_mse: 16.3365\n",
      "Epoch 1075/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4341 - mae: 2.4341 - mse: 13.3931 - val_loss: 2.4738 - val_mae: 2.4738 - val_mse: 14.4024\n",
      "Epoch 1076/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3741 - mae: 2.3741 - mse: 12.8268 - val_loss: 2.4145 - val_mae: 2.4145 - val_mse: 13.8308\n",
      "Epoch 1077/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3822 - mae: 2.3822 - mse: 12.9900 - val_loss: 2.6536 - val_mae: 2.6536 - val_mse: 15.8724\n",
      "Epoch 1078/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4191 - mae: 2.4191 - mse: 13.1627 - val_loss: 2.5794 - val_mae: 2.5794 - val_mse: 16.1597\n",
      "Epoch 1079/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.4262 - mae: 2.4262 - mse: 13.1560 - val_loss: 2.5619 - val_mae: 2.5619 - val_mse: 15.1967\n",
      "Epoch 1080/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3824 - mae: 2.3824 - mse: 13.0658 - val_loss: 2.4537 - val_mae: 2.4537 - val_mse: 13.8215\n",
      "Epoch 1081/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.3278 - mae: 2.3278 - mse: 12.5767 - val_loss: 2.4226 - val_mae: 2.4226 - val_mse: 13.9186\n",
      "Epoch 1082/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3789 - mae: 2.3789 - mse: 12.8114 - val_loss: 2.4297 - val_mae: 2.4297 - val_mse: 13.8392\n",
      "Epoch 1083/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3969 - mae: 2.3969 - mse: 12.9404 - val_loss: 2.5271 - val_mae: 2.5271 - val_mse: 14.9545\n",
      "Epoch 1084/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4340 - mae: 2.4340 - mse: 13.1454 - val_loss: 2.4204 - val_mae: 2.4204 - val_mse: 13.8775\n",
      "Epoch 1085/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.3205 - mae: 2.3205 - mse: 12.5555 - val_loss: 2.4634 - val_mae: 2.4634 - val_mse: 13.9989\n",
      "Epoch 1086/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3725 - mae: 2.3725 - mse: 13.0224 - val_loss: 2.4626 - val_mae: 2.4626 - val_mse: 14.3623\n",
      "Epoch 1087/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3691 - mae: 2.3691 - mse: 12.8003 - val_loss: 2.5125 - val_mae: 2.5125 - val_mse: 13.8036\n",
      "Epoch 1088/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3216 - mae: 2.3216 - mse: 12.5392 - val_loss: 2.4303 - val_mae: 2.4303 - val_mse: 14.2317\n",
      "Epoch 1089/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3190 - mae: 2.3190 - mse: 12.5328 - val_loss: 2.3964 - val_mae: 2.3964 - val_mse: 13.4282\n",
      "Epoch 1090/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3479 - mae: 2.3479 - mse: 12.6117 - val_loss: 2.4292 - val_mae: 2.4292 - val_mse: 13.6636\n",
      "Epoch 1091/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.4438 - mae: 2.4438 - mse: 13.2115 - val_loss: 2.4845 - val_mae: 2.4845 - val_mse: 13.8104\n",
      "Epoch 1092/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3820 - mae: 2.3820 - mse: 12.9031 - val_loss: 2.5423 - val_mae: 2.5423 - val_mse: 13.9491\n",
      "Epoch 1093/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3281 - mae: 2.3281 - mse: 12.4904 - val_loss: 2.4534 - val_mae: 2.4534 - val_mse: 14.5773\n",
      "Epoch 1094/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3199 - mae: 2.3199 - mse: 12.5064 - val_loss: 2.4456 - val_mae: 2.4456 - val_mse: 13.5864\n",
      "Epoch 1095/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.3268 - mae: 2.3268 - mse: 12.4048 - val_loss: 2.3871 - val_mae: 2.3871 - val_mse: 13.5554\n",
      "Epoch 1096/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3139 - mae: 2.3139 - mse: 12.4737 - val_loss: 2.3864 - val_mae: 2.3864 - val_mse: 13.5218\n",
      "Epoch 1097/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.2987 - mae: 2.2987 - mse: 12.3782 - val_loss: 2.3994 - val_mae: 2.3994 - val_mse: 13.5585\n",
      "Epoch 1098/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.2915 - mae: 2.2915 - mse: 12.3398 - val_loss: 2.4147 - val_mae: 2.4147 - val_mse: 13.6880\n",
      "Epoch 1099/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3259 - mae: 2.3259 - mse: 12.5218 - val_loss: 2.3844 - val_mae: 2.3844 - val_mse: 13.5621\n",
      "Epoch 1100/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.3387 - mae: 2.3387 - mse: 12.5519 - val_loss: 2.4165 - val_mae: 2.4165 - val_mse: 13.8842\n",
      "Epoch 1101/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3490 - mae: 2.3490 - mse: 12.6744 - val_loss: 2.6479 - val_mae: 2.6479 - val_mse: 14.1327\n",
      "Epoch 1102/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3312 - mae: 2.3312 - mse: 12.4486 - val_loss: 2.3842 - val_mae: 2.3842 - val_mse: 13.5650\n",
      "Epoch 1103/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3211 - mae: 2.3211 - mse: 12.5520 - val_loss: 2.4856 - val_mae: 2.4856 - val_mse: 14.0800\n",
      "Epoch 1104/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3905 - mae: 2.3905 - mse: 13.0212 - val_loss: 2.4669 - val_mae: 2.4669 - val_mse: 14.4475\n",
      "Epoch 1105/2500\n",
      "684/684 [==============================] - 1s 823us/sample - loss: 2.3405 - mae: 2.3405 - mse: 12.6988 - val_loss: 2.4342 - val_mae: 2.4342 - val_mse: 13.7411\n",
      "Epoch 1106/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.2977 - mae: 2.2977 - mse: 12.2701 - val_loss: 2.3803 - val_mae: 2.3803 - val_mse: 13.4848\n",
      "Epoch 1107/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3465 - mae: 2.3465 - mse: 12.6942 - val_loss: 2.4589 - val_mae: 2.4589 - val_mse: 13.9048\n",
      "Epoch 1108/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3960 - mae: 2.3960 - mse: 13.0833 - val_loss: 2.4766 - val_mae: 2.4766 - val_mse: 14.2818\n",
      "Epoch 1109/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4631 - mae: 2.4631 - mse: 13.4373 - val_loss: 2.5284 - val_mae: 2.5284 - val_mse: 14.0899\n",
      "Epoch 1110/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3805 - mae: 2.3805 - mse: 13.0621 - val_loss: 2.5852 - val_mae: 2.5852 - val_mse: 16.2500\n",
      "Epoch 1111/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4984 - mae: 2.4984 - mse: 14.1889 - val_loss: 2.4302 - val_mae: 2.4302 - val_mse: 13.9793\n",
      "Epoch 1112/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3409 - mae: 2.3409 - mse: 12.7199 - val_loss: 2.4405 - val_mae: 2.4405 - val_mse: 13.9815\n",
      "Epoch 1113/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3253 - mae: 2.3253 - mse: 12.4822 - val_loss: 2.6407 - val_mae: 2.6407 - val_mse: 14.4224\n",
      "Epoch 1114/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3670 - mae: 2.3670 - mse: 12.7870 - val_loss: 2.4955 - val_mae: 2.4955 - val_mse: 14.6901\n",
      "Epoch 1115/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3681 - mae: 2.3681 - mse: 12.8588 - val_loss: 2.4115 - val_mae: 2.4115 - val_mse: 13.6059\n",
      "Epoch 1116/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3521 - mae: 2.3521 - mse: 12.5654 - val_loss: 2.4228 - val_mae: 2.4228 - val_mse: 13.6641\n",
      "Epoch 1117/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.3454 - mae: 2.3454 - mse: 12.5952 - val_loss: 2.6174 - val_mae: 2.6174 - val_mse: 14.7611\n",
      "Epoch 1118/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.3351 - mae: 2.3351 - mse: 12.4722 - val_loss: 2.4164 - val_mae: 2.4164 - val_mse: 13.8621\n",
      "Epoch 1119/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3314 - mae: 2.3314 - mse: 12.6873 - val_loss: 2.3818 - val_mae: 2.3818 - val_mse: 13.4427\n",
      "Epoch 1120/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3462 - mae: 2.3462 - mse: 12.5344 - val_loss: 2.4135 - val_mae: 2.4135 - val_mse: 13.9145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1121/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.3354 - mae: 2.3354 - mse: 12.5338 - val_loss: 2.4401 - val_mae: 2.4401 - val_mse: 14.0277\n",
      "Epoch 1122/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3334 - mae: 2.3334 - mse: 12.5655 - val_loss: 2.3705 - val_mae: 2.3705 - val_mse: 13.5296\n",
      "Epoch 1123/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3472 - mae: 2.3472 - mse: 12.5798 - val_loss: 2.5711 - val_mae: 2.5711 - val_mse: 14.0993\n",
      "Epoch 1124/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3368 - mae: 2.3368 - mse: 12.6191 - val_loss: 2.5491 - val_mae: 2.5491 - val_mse: 14.0115\n",
      "Epoch 1125/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.3749 - mae: 2.3749 - mse: 12.7257 - val_loss: 2.3865 - val_mae: 2.3865 - val_mse: 13.6553\n",
      "Epoch 1126/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3526 - mae: 2.3526 - mse: 12.5218 - val_loss: 2.4348 - val_mae: 2.4348 - val_mse: 13.6830\n",
      "Epoch 1127/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3274 - mae: 2.3274 - mse: 12.5252 - val_loss: 2.4503 - val_mae: 2.4503 - val_mse: 13.5558\n",
      "Epoch 1128/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3409 - mae: 2.3409 - mse: 12.5884 - val_loss: 2.4502 - val_mae: 2.4502 - val_mse: 13.6327\n",
      "Epoch 1129/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3558 - mae: 2.3558 - mse: 12.7277 - val_loss: 2.4135 - val_mae: 2.4135 - val_mse: 13.5862\n",
      "Epoch 1130/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3288 - mae: 2.3288 - mse: 12.4884 - val_loss: 2.4499 - val_mae: 2.4499 - val_mse: 13.9348\n",
      "Epoch 1131/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3472 - mae: 2.3472 - mse: 12.6671 - val_loss: 2.3871 - val_mae: 2.3871 - val_mse: 13.5092\n",
      "Epoch 1132/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3365 - mae: 2.3365 - mse: 12.5105 - val_loss: 2.3912 - val_mae: 2.3912 - val_mse: 13.7073\n",
      "Epoch 1133/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3076 - mae: 2.3076 - mse: 12.4425 - val_loss: 2.4380 - val_mae: 2.4380 - val_mse: 14.2786\n",
      "Epoch 1134/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3242 - mae: 2.3242 - mse: 12.5890 - val_loss: 2.3979 - val_mae: 2.3979 - val_mse: 13.5638\n",
      "Epoch 1135/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3318 - mae: 2.3318 - mse: 12.5295 - val_loss: 2.4304 - val_mae: 2.4304 - val_mse: 13.5034\n",
      "Epoch 1136/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3189 - mae: 2.3189 - mse: 12.4576 - val_loss: 2.4024 - val_mae: 2.4024 - val_mse: 13.7184\n",
      "Epoch 1137/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3132 - mae: 2.3132 - mse: 12.5049 - val_loss: 2.4942 - val_mae: 2.4942 - val_mse: 14.0446\n",
      "Epoch 1138/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.4416 - val_loss: 2.4179 - val_mae: 2.4179 - val_mse: 14.0741\n",
      "Epoch 1139/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3225 - mae: 2.3225 - mse: 12.5957 - val_loss: 2.4335 - val_mae: 2.4335 - val_mse: 14.3430\n",
      "Epoch 1140/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3754 - mae: 2.3754 - mse: 12.8091 - val_loss: 2.6017 - val_mae: 2.6017 - val_mse: 16.0337\n",
      "Epoch 1141/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3558 - mae: 2.3558 - mse: 12.8018 - val_loss: 2.4337 - val_mae: 2.4337 - val_mse: 13.8868\n",
      "Epoch 1142/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3277 - mae: 2.3277 - mse: 12.6120 - val_loss: 2.4914 - val_mae: 2.4914 - val_mse: 14.1508\n",
      "Epoch 1143/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3361 - mae: 2.3361 - mse: 12.7910 - val_loss: 2.5070 - val_mae: 2.5070 - val_mse: 14.8200\n",
      "Epoch 1144/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.4302 - mae: 2.4302 - mse: 13.1510 - val_loss: 2.4213 - val_mae: 2.4213 - val_mse: 13.6830\n",
      "Epoch 1145/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3664 - mae: 2.3664 - mse: 12.8586 - val_loss: 2.3964 - val_mae: 2.3964 - val_mse: 13.6253\n",
      "Epoch 1146/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3599 - mae: 2.3599 - mse: 12.6993 - val_loss: 2.4927 - val_mae: 2.4927 - val_mse: 15.1980\n",
      "Epoch 1147/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3223 - mae: 2.3223 - mse: 12.4937 - val_loss: 2.4177 - val_mae: 2.4177 - val_mse: 13.4816\n",
      "Epoch 1148/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.2951 - mae: 2.2951 - mse: 12.3058 - val_loss: 2.3982 - val_mae: 2.3982 - val_mse: 13.6170\n",
      "Epoch 1149/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3405 - mae: 2.3405 - mse: 12.5865 - val_loss: 2.4458 - val_mae: 2.4458 - val_mse: 14.0415\n",
      "Epoch 1150/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3140 - mae: 2.3140 - mse: 12.4908 - val_loss: 2.3913 - val_mae: 2.3913 - val_mse: 13.5063\n",
      "Epoch 1151/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.2873 - mae: 2.2873 - mse: 12.2592 - val_loss: 2.4551 - val_mae: 2.4551 - val_mse: 13.5695\n",
      "Epoch 1152/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.2965 - mae: 2.2965 - mse: 12.2692 - val_loss: 2.3801 - val_mae: 2.3801 - val_mse: 13.4515\n",
      "Epoch 1153/2500\n",
      "684/684 [==============================] - 1s 832us/sample - loss: 2.2943 - mae: 2.2943 - mse: 12.3848 - val_loss: 2.3957 - val_mae: 2.3956 - val_mse: 13.6445\n",
      "Epoch 1154/2500\n",
      "684/684 [==============================] - 1s 819us/sample - loss: 2.2940 - mae: 2.2940 - mse: 12.3468 - val_loss: 2.5006 - val_mae: 2.5006 - val_mse: 15.2404\n",
      "Epoch 1155/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.4208 - mae: 2.4208 - mse: 13.1185 - val_loss: 2.7249 - val_mae: 2.7249 - val_mse: 17.7536\n",
      "Epoch 1156/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4585 - mae: 2.4585 - mse: 13.6845 - val_loss: 2.4829 - val_mae: 2.4829 - val_mse: 14.6142\n",
      "Epoch 1157/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.4277 - mae: 2.4277 - mse: 13.3447 - val_loss: 2.5291 - val_mae: 2.5291 - val_mse: 15.0156\n",
      "Epoch 1158/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4112 - mae: 2.4112 - mse: 13.0154 - val_loss: 2.5802 - val_mae: 2.5802 - val_mse: 15.3576\n",
      "Epoch 1159/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3518 - mae: 2.3518 - mse: 12.7623 - val_loss: 2.4502 - val_mae: 2.4502 - val_mse: 13.8923\n",
      "Epoch 1160/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3632 - mae: 2.3632 - mse: 12.8441 - val_loss: 2.4185 - val_mae: 2.4185 - val_mse: 13.7774\n",
      "Epoch 1161/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3425 - mae: 2.3425 - mse: 12.6447 - val_loss: 2.4425 - val_mae: 2.4425 - val_mse: 13.8789\n",
      "Epoch 1162/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3242 - mae: 2.3242 - mse: 12.5638 - val_loss: 2.3857 - val_mae: 2.3857 - val_mse: 13.6117\n",
      "Epoch 1163/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3240 - mae: 2.3240 - mse: 12.4536 - val_loss: 2.4325 - val_mae: 2.4325 - val_mse: 13.6232\n",
      "Epoch 1164/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3124 - mae: 2.3124 - mse: 12.4669 - val_loss: 2.4059 - val_mae: 2.4059 - val_mse: 13.5580\n",
      "Epoch 1165/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3375 - mae: 2.3375 - mse: 12.4489 - val_loss: 2.4720 - val_mae: 2.4720 - val_mse: 14.3564\n",
      "Epoch 1166/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3256 - mae: 2.3256 - mse: 12.5856 - val_loss: 2.4249 - val_mae: 2.4249 - val_mse: 13.7072\n",
      "Epoch 1167/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3133 - mae: 2.3133 - mse: 12.5070 - val_loss: 2.4068 - val_mae: 2.4068 - val_mse: 13.8030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1168/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3658 - mae: 2.3658 - mse: 12.8088 - val_loss: 2.3954 - val_mae: 2.3954 - val_mse: 13.8810\n",
      "Epoch 1169/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3231 - mae: 2.3231 - mse: 12.5429 - val_loss: 2.3956 - val_mae: 2.3956 - val_mse: 13.5754\n",
      "Epoch 1170/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3582 - mae: 2.3582 - mse: 12.7313 - val_loss: 2.3877 - val_mae: 2.3877 - val_mse: 13.6071\n",
      "Epoch 1171/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3171 - mae: 2.3171 - mse: 12.4286 - val_loss: 2.4545 - val_mae: 2.4545 - val_mse: 14.4742\n",
      "Epoch 1172/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.4112 - mae: 2.4112 - mse: 13.2044 - val_loss: 2.4680 - val_mae: 2.4680 - val_mse: 14.7402\n",
      "Epoch 1173/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3808 - mae: 2.3808 - mse: 13.0939 - val_loss: 2.5785 - val_mae: 2.5785 - val_mse: 14.0102\n",
      "Epoch 1174/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3662 - mae: 2.3662 - mse: 12.7275 - val_loss: 2.5215 - val_mae: 2.5215 - val_mse: 14.9457\n",
      "Epoch 1175/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3843 - mae: 2.3843 - mse: 12.7767 - val_loss: 2.4636 - val_mae: 2.4636 - val_mse: 14.9207\n",
      "Epoch 1176/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3319 - mae: 2.3319 - mse: 12.4979 - val_loss: 2.4061 - val_mae: 2.4061 - val_mse: 13.6903\n",
      "Epoch 1177/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3590 - mae: 2.3590 - mse: 12.5614 - val_loss: 2.4957 - val_mae: 2.4957 - val_mse: 14.1822\n",
      "Epoch 1178/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3701 - mae: 2.3701 - mse: 12.7870 - val_loss: 2.4096 - val_mae: 2.4096 - val_mse: 13.4700\n",
      "Epoch 1179/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3538 - mae: 2.3538 - mse: 12.5342 - val_loss: 2.5024 - val_mae: 2.5024 - val_mse: 14.3940\n",
      "Epoch 1180/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3305 - mae: 2.3305 - mse: 12.5721 - val_loss: 2.3957 - val_mae: 2.3957 - val_mse: 13.5764\n",
      "Epoch 1181/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3999 - mae: 2.3999 - mse: 12.9903 - val_loss: 2.5230 - val_mae: 2.5230 - val_mse: 15.5544\n",
      "Epoch 1182/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3771 - mae: 2.3771 - mse: 13.2397 - val_loss: 2.4109 - val_mae: 2.4109 - val_mse: 14.0013\n",
      "Epoch 1183/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3014 - mae: 2.3014 - mse: 12.3076 - val_loss: 2.4086 - val_mae: 2.4086 - val_mse: 13.4517\n",
      "Epoch 1184/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.3321 - mae: 2.3321 - mse: 12.4949 - val_loss: 2.3903 - val_mae: 2.3903 - val_mse: 13.6799\n",
      "Epoch 1185/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3001 - mae: 2.3001 - mse: 12.3045 - val_loss: 2.4195 - val_mae: 2.4195 - val_mse: 13.9284\n",
      "Epoch 1186/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3092 - mae: 2.3092 - mse: 12.4714 - val_loss: 2.5185 - val_mae: 2.5185 - val_mse: 14.7191\n",
      "Epoch 1187/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3395 - mae: 2.3395 - mse: 12.6735 - val_loss: 2.5531 - val_mae: 2.5531 - val_mse: 15.5816\n",
      "Epoch 1188/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3942 - mae: 2.3942 - mse: 13.0522 - val_loss: 2.4367 - val_mae: 2.4367 - val_mse: 13.8219\n",
      "Epoch 1189/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3816 - mae: 2.3816 - mse: 13.0648 - val_loss: 2.4421 - val_mae: 2.4421 - val_mse: 14.3288\n",
      "Epoch 1190/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3377 - mae: 2.3377 - mse: 12.6678 - val_loss: 2.4255 - val_mae: 2.4255 - val_mse: 13.9171\n",
      "Epoch 1191/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3121 - mae: 2.3121 - mse: 12.4406 - val_loss: 2.3873 - val_mae: 2.3873 - val_mse: 13.4954\n",
      "Epoch 1192/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3085 - mae: 2.3085 - mse: 12.3554 - val_loss: 2.4031 - val_mae: 2.4031 - val_mse: 13.9327\n",
      "Epoch 1193/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3334 - mae: 2.3334 - mse: 12.6514 - val_loss: 2.4064 - val_mae: 2.4064 - val_mse: 14.0515\n",
      "Epoch 1194/2500\n",
      "684/684 [==============================] - 1s 825us/sample - loss: 2.3341 - mae: 2.3341 - mse: 12.6079 - val_loss: 2.5254 - val_mae: 2.5254 - val_mse: 13.8428\n",
      "Epoch 1195/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.2948 - mae: 2.2948 - mse: 12.3859 - val_loss: 2.4144 - val_mae: 2.4144 - val_mse: 13.5540\n",
      "Epoch 1196/2500\n",
      "684/684 [==============================] - 1s 824us/sample - loss: 2.3020 - mae: 2.3020 - mse: 12.3705 - val_loss: 2.4362 - val_mae: 2.4362 - val_mse: 14.0243\n",
      "Epoch 1197/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3271 - mae: 2.3271 - mse: 12.4530 - val_loss: 2.5686 - val_mae: 2.5686 - val_mse: 15.6505\n",
      "Epoch 1198/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3316 - mae: 2.3316 - mse: 12.4873 - val_loss: 2.4159 - val_mae: 2.4159 - val_mse: 13.6357\n",
      "Epoch 1199/2500\n",
      "684/684 [==============================] - 1s 820us/sample - loss: 2.3542 - mae: 2.3542 - mse: 12.8901 - val_loss: 2.6353 - val_mae: 2.6353 - val_mse: 17.1803\n",
      "Epoch 1200/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.4217 - mae: 2.4217 - mse: 13.4848 - val_loss: 2.4640 - val_mae: 2.4640 - val_mse: 14.1668\n",
      "Epoch 1201/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3456 - mae: 2.3456 - mse: 12.5992 - val_loss: 2.4327 - val_mae: 2.4327 - val_mse: 13.5369\n",
      "Epoch 1202/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3078 - mae: 2.3078 - mse: 12.3309 - val_loss: 2.3826 - val_mae: 2.3826 - val_mse: 13.6824\n",
      "Epoch 1203/2500\n",
      "684/684 [==============================] - 1s 816us/sample - loss: 2.3040 - mae: 2.3040 - mse: 12.3401 - val_loss: 2.4017 - val_mae: 2.4017 - val_mse: 13.7421\n",
      "Epoch 1204/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3112 - mae: 2.3112 - mse: 12.4567 - val_loss: 2.4197 - val_mae: 2.4197 - val_mse: 13.6981\n",
      "Epoch 1205/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3269 - mae: 2.3269 - mse: 12.5047 - val_loss: 2.4788 - val_mae: 2.4788 - val_mse: 15.0102\n",
      "Epoch 1206/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3269 - mae: 2.3269 - mse: 12.4421 - val_loss: 2.4608 - val_mae: 2.4608 - val_mse: 13.7337\n",
      "Epoch 1207/2500\n",
      "684/684 [==============================] - 1s 858us/sample - loss: 2.3397 - mae: 2.3397 - mse: 12.5920 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 14.2738\n",
      "Epoch 1208/2500\n",
      "684/684 [==============================] - 1s 834us/sample - loss: 2.3784 - mae: 2.3784 - mse: 12.8520 - val_loss: 2.6844 - val_mae: 2.6844 - val_mse: 14.6175\n",
      "Epoch 1209/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.4008 - mae: 2.4008 - mse: 13.3374 - val_loss: 2.4892 - val_mae: 2.4892 - val_mse: 15.1339\n",
      "Epoch 1210/2500\n",
      "684/684 [==============================] - 1s 835us/sample - loss: 2.3317 - mae: 2.3317 - mse: 12.7036 - val_loss: 2.4238 - val_mae: 2.4238 - val_mse: 13.5352\n",
      "Epoch 1211/2500\n",
      "684/684 [==============================] - 1s 837us/sample - loss: 2.3333 - mae: 2.3333 - mse: 12.6535 - val_loss: 2.4603 - val_mae: 2.4603 - val_mse: 14.2021\n",
      "Epoch 1212/2500\n",
      "684/684 [==============================] - 1s 828us/sample - loss: 2.3276 - mae: 2.3276 - mse: 12.7233 - val_loss: 2.4070 - val_mae: 2.4070 - val_mse: 13.6576\n",
      "Epoch 1213/2500\n",
      "684/684 [==============================] - 1s 830us/sample - loss: 2.3589 - mae: 2.3589 - mse: 12.6256 - val_loss: 2.5976 - val_mae: 2.5976 - val_mse: 15.2020\n",
      "Epoch 1214/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.4051 - mae: 2.4051 - mse: 13.2274 - val_loss: 2.4987 - val_mae: 2.4987 - val_mse: 13.9629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1215/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.4156 - mae: 2.4156 - mse: 13.5025 - val_loss: 2.4365 - val_mae: 2.4365 - val_mse: 14.2354\n",
      "Epoch 1216/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3291 - mae: 2.3291 - mse: 12.7031 - val_loss: 2.3834 - val_mae: 2.3834 - val_mse: 13.7385\n",
      "Epoch 1217/2500\n",
      "684/684 [==============================] - 1s 827us/sample - loss: 2.2992 - mae: 2.2992 - mse: 12.3511 - val_loss: 2.4015 - val_mae: 2.4015 - val_mse: 13.7632\n",
      "Epoch 1218/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 2.3166 - mae: 2.3166 - mse: 12.3759 - val_loss: 2.5604 - val_mae: 2.5604 - val_mse: 14.5862\n",
      "Epoch 1219/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.3828 - mae: 2.3828 - mse: 12.8756 - val_loss: 2.4204 - val_mae: 2.4204 - val_mse: 13.8081\n",
      "Epoch 1220/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3887 - mae: 2.3887 - mse: 12.9154 - val_loss: 2.6417 - val_mae: 2.6417 - val_mse: 15.3227\n",
      "Epoch 1221/2500\n",
      "684/684 [==============================] - 1s 832us/sample - loss: 2.3689 - mae: 2.3689 - mse: 12.8167 - val_loss: 2.3999 - val_mae: 2.3999 - val_mse: 14.0098\n",
      "Epoch 1222/2500\n",
      "684/684 [==============================] - 1s 829us/sample - loss: 2.3221 - mae: 2.3221 - mse: 12.5922 - val_loss: 2.4161 - val_mae: 2.4161 - val_mse: 13.8271\n",
      "Epoch 1223/2500\n",
      "684/684 [==============================] - 1s 815us/sample - loss: 2.3801 - mae: 2.3801 - mse: 12.7496 - val_loss: 2.5967 - val_mae: 2.5967 - val_mse: 15.9233\n",
      "Epoch 1224/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3945 - mae: 2.3945 - mse: 13.1296 - val_loss: 2.5314 - val_mae: 2.5314 - val_mse: 15.4005\n",
      "Epoch 1225/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3794 - mae: 2.3794 - mse: 13.0300 - val_loss: 2.6836 - val_mae: 2.6836 - val_mse: 15.2346\n",
      "Epoch 1226/2500\n",
      "684/684 [==============================] - 1s 818us/sample - loss: 2.3372 - mae: 2.3372 - mse: 12.5520 - val_loss: 2.3908 - val_mae: 2.3908 - val_mse: 13.7936\n",
      "Epoch 1227/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3734 - mae: 2.3734 - mse: 12.8857 - val_loss: 2.4155 - val_mae: 2.4155 - val_mse: 13.9819\n",
      "Epoch 1228/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3605 - mae: 2.3605 - mse: 12.9266 - val_loss: 2.4277 - val_mae: 2.4277 - val_mse: 13.8849\n",
      "Epoch 1229/2500\n",
      "684/684 [==============================] - 1s 840us/sample - loss: 2.3045 - mae: 2.3045 - mse: 12.4091 - val_loss: 2.4041 - val_mae: 2.4041 - val_mse: 13.5790\n",
      "Epoch 1230/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3126 - mae: 2.3126 - mse: 12.3675 - val_loss: 2.4625 - val_mae: 2.4625 - val_mse: 14.5048\n",
      "Epoch 1231/2500\n",
      "684/684 [==============================] - 1s 811us/sample - loss: 2.2933 - mae: 2.2933 - mse: 12.2650 - val_loss: 2.4797 - val_mae: 2.4797 - val_mse: 14.0981\n",
      "Epoch 1232/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.3220 - mae: 2.3220 - mse: 12.3901 - val_loss: 2.4862 - val_mae: 2.4862 - val_mse: 13.9254\n",
      "Epoch 1233/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.3878 - mae: 2.3878 - mse: 12.8573 - val_loss: 2.4667 - val_mae: 2.4667 - val_mse: 14.7739\n",
      "Epoch 1234/2500\n",
      "684/684 [==============================] - 1s 817us/sample - loss: 2.3868 - mae: 2.3868 - mse: 13.1669 - val_loss: 2.4272 - val_mae: 2.4272 - val_mse: 13.6663\n",
      "Epoch 1235/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3221 - mae: 2.3221 - mse: 12.4600 - val_loss: 2.4423 - val_mae: 2.4423 - val_mse: 13.7860\n",
      "Epoch 1236/2500\n",
      "684/684 [==============================] - 1s 845us/sample - loss: 2.3942 - mae: 2.3942 - mse: 13.0561 - val_loss: 2.5289 - val_mae: 2.5289 - val_mse: 15.2326\n",
      "Epoch 1237/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3877 - mae: 2.3877 - mse: 13.0839 - val_loss: 2.7473 - val_mae: 2.7473 - val_mse: 16.0177\n",
      "Epoch 1238/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3865 - mae: 2.3865 - mse: 13.1263 - val_loss: 2.4984 - val_mae: 2.4984 - val_mse: 14.6107\n",
      "Epoch 1239/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3275 - mae: 2.3275 - mse: 12.5130 - val_loss: 2.4198 - val_mae: 2.4198 - val_mse: 13.9515\n",
      "Epoch 1240/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3237 - mae: 2.3237 - mse: 12.6632 - val_loss: 2.4511 - val_mae: 2.4511 - val_mse: 13.5608\n",
      "Epoch 1241/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3344 - mae: 2.3344 - mse: 12.5567 - val_loss: 2.5428 - val_mae: 2.5428 - val_mse: 13.8187\n",
      "Epoch 1242/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3337 - mae: 2.3337 - mse: 12.4484 - val_loss: 2.3862 - val_mae: 2.3862 - val_mse: 13.4531\n",
      "Epoch 1243/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3211 - mae: 2.3211 - mse: 12.4252 - val_loss: 2.4338 - val_mae: 2.4338 - val_mse: 14.1036\n",
      "Epoch 1244/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3575 - mae: 2.3575 - mse: 12.6528 - val_loss: 2.5878 - val_mae: 2.5878 - val_mse: 16.0922\n",
      "Epoch 1245/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3574 - mae: 2.3574 - mse: 12.7241 - val_loss: 2.4107 - val_mae: 2.4107 - val_mse: 13.5923\n",
      "Epoch 1246/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3017 - mae: 2.3017 - mse: 12.4071 - val_loss: 2.4887 - val_mae: 2.4887 - val_mse: 13.9969\n",
      "Epoch 1247/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3233 - mae: 2.3233 - mse: 12.5406 - val_loss: 2.5697 - val_mae: 2.5697 - val_mse: 14.7671\n",
      "Epoch 1248/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3813 - mae: 2.3813 - mse: 13.0400 - val_loss: 2.5443 - val_mae: 2.5443 - val_mse: 14.9586\n",
      "Epoch 1249/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3284 - mae: 2.3284 - mse: 12.7590 - val_loss: 2.4525 - val_mae: 2.4525 - val_mse: 14.1661\n",
      "Epoch 1250/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.3807 - mae: 2.3807 - mse: 12.8306 - val_loss: 2.3726 - val_mae: 2.3726 - val_mse: 13.4658\n",
      "Epoch 1251/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3117 - mae: 2.3117 - mse: 12.4376 - val_loss: 2.4194 - val_mae: 2.4194 - val_mse: 13.7780\n",
      "Epoch 1252/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3227 - mae: 2.3227 - mse: 12.5497 - val_loss: 2.4117 - val_mae: 2.4117 - val_mse: 13.6095\n",
      "Epoch 1253/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3371 - mae: 2.3371 - mse: 12.5542 - val_loss: 2.5436 - val_mae: 2.5436 - val_mse: 15.0917\n",
      "Epoch 1254/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3635 - mae: 2.3635 - mse: 12.7232 - val_loss: 2.4326 - val_mae: 2.4326 - val_mse: 14.0490\n",
      "Epoch 1255/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3046 - mae: 2.3046 - mse: 12.3216 - val_loss: 2.4314 - val_mae: 2.4314 - val_mse: 14.2086\n",
      "Epoch 1256/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3370 - mae: 2.3370 - mse: 12.5764 - val_loss: 2.4757 - val_mae: 2.4757 - val_mse: 14.0855\n",
      "Epoch 1257/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3369 - mae: 2.3369 - mse: 12.5474 - val_loss: 2.4399 - val_mae: 2.4399 - val_mse: 13.5645\n",
      "Epoch 1258/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.2513 - val_loss: 2.4094 - val_mae: 2.4094 - val_mse: 13.7246\n",
      "Epoch 1259/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3040 - mae: 2.3040 - mse: 12.3336 - val_loss: 2.3759 - val_mae: 2.3759 - val_mse: 13.5331\n",
      "Epoch 1260/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.4105 - mae: 2.4105 - mse: 12.9331 - val_loss: 2.4953 - val_mae: 2.4953 - val_mse: 14.6729\n",
      "Epoch 1261/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3506 - mae: 2.3506 - mse: 12.8669 - val_loss: 2.5499 - val_mae: 2.5499 - val_mse: 15.2218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1262/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3382 - mae: 2.3382 - mse: 12.7040 - val_loss: 2.4189 - val_mae: 2.4189 - val_mse: 13.9824\n",
      "Epoch 1263/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.5520 - val_loss: 2.4005 - val_mae: 2.4005 - val_mse: 13.7524\n",
      "Epoch 1264/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3887 - mae: 2.3887 - mse: 13.0242 - val_loss: 2.4294 - val_mae: 2.4294 - val_mse: 14.3048\n",
      "Epoch 1265/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.4188 - mae: 2.4188 - mse: 13.3415 - val_loss: 2.4788 - val_mae: 2.4788 - val_mse: 14.9823\n",
      "Epoch 1266/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3627 - mae: 2.3627 - mse: 12.6733 - val_loss: 2.4525 - val_mae: 2.4525 - val_mse: 13.6448\n",
      "Epoch 1267/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3323 - mae: 2.3323 - mse: 12.6365 - val_loss: 2.4233 - val_mae: 2.4233 - val_mse: 13.9457\n",
      "Epoch 1268/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.3330 - mae: 2.3330 - mse: 12.5986 - val_loss: 2.3923 - val_mae: 2.3923 - val_mse: 13.3899\n",
      "Epoch 1269/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2884 - mae: 2.2884 - mse: 12.2594 - val_loss: 2.3889 - val_mae: 2.3889 - val_mse: 13.5473\n",
      "Epoch 1270/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3020 - mae: 2.3020 - mse: 12.4281 - val_loss: 2.3949 - val_mae: 2.3949 - val_mse: 13.8497\n",
      "Epoch 1271/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3240 - mae: 2.3240 - mse: 12.4773 - val_loss: 2.4962 - val_mae: 2.4962 - val_mse: 14.2897\n",
      "Epoch 1272/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3847 - mae: 2.3847 - mse: 12.7695 - val_loss: 2.3937 - val_mae: 2.3937 - val_mse: 13.6259\n",
      "Epoch 1273/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2878 - mae: 2.2878 - mse: 12.2604 - val_loss: 2.4708 - val_mae: 2.4708 - val_mse: 13.7504\n",
      "Epoch 1274/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3769 - mae: 2.3769 - mse: 12.7189 - val_loss: 2.5497 - val_mae: 2.5497 - val_mse: 14.9277\n",
      "Epoch 1275/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3220 - mae: 2.3220 - mse: 12.4163 - val_loss: 2.3868 - val_mae: 2.3868 - val_mse: 13.5855\n",
      "Epoch 1276/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2811 - mae: 2.2811 - mse: 12.2210 - val_loss: 2.3825 - val_mae: 2.3825 - val_mse: 13.6340\n",
      "Epoch 1277/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2852 - mae: 2.2852 - mse: 12.2481 - val_loss: 2.4580 - val_mae: 2.4580 - val_mse: 13.6498\n",
      "Epoch 1278/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3364 - mae: 2.3364 - mse: 12.4891 - val_loss: 2.4137 - val_mae: 2.4137 - val_mse: 13.6581\n",
      "Epoch 1279/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3708 - mae: 2.3708 - mse: 12.6955 - val_loss: 2.4768 - val_mae: 2.4768 - val_mse: 13.7412\n",
      "Epoch 1280/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2997 - mae: 2.2997 - mse: 12.3376 - val_loss: 2.4976 - val_mae: 2.4976 - val_mse: 14.0696\n",
      "Epoch 1281/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3306 - mae: 2.3306 - mse: 12.5104 - val_loss: 2.4543 - val_mae: 2.4543 - val_mse: 13.9614\n",
      "Epoch 1282/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3015 - mae: 2.3015 - mse: 12.3610 - val_loss: 2.3781 - val_mae: 2.3781 - val_mse: 13.4193\n",
      "Epoch 1283/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2968 - mae: 2.2968 - mse: 12.3645 - val_loss: 2.3988 - val_mae: 2.3988 - val_mse: 13.9445\n",
      "Epoch 1284/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.3169 - mae: 2.3169 - mse: 12.4719 - val_loss: 2.4765 - val_mae: 2.4765 - val_mse: 14.6952\n",
      "Epoch 1285/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3383 - mae: 2.3383 - mse: 12.6271 - val_loss: 2.4260 - val_mae: 2.4260 - val_mse: 13.9708\n",
      "Epoch 1286/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2857 - mae: 2.2857 - mse: 12.3341 - val_loss: 2.3658 - val_mae: 2.3658 - val_mse: 13.4211\n",
      "Epoch 1287/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2702 - mae: 2.2702 - mse: 12.2004 - val_loss: 2.5335 - val_mae: 2.5335 - val_mse: 13.9611\n",
      "Epoch 1288/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3312 - mae: 2.3312 - mse: 12.5997 - val_loss: 2.4240 - val_mae: 2.4240 - val_mse: 13.7363\n",
      "Epoch 1289/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3184 - mae: 2.3184 - mse: 12.5824 - val_loss: 2.4618 - val_mae: 2.4618 - val_mse: 13.5900\n",
      "Epoch 1290/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3490 - mae: 2.3490 - mse: 12.5662 - val_loss: 2.4306 - val_mae: 2.4306 - val_mse: 13.5272\n",
      "Epoch 1291/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3156 - mae: 2.3156 - mse: 12.4707 - val_loss: 2.4265 - val_mae: 2.4265 - val_mse: 14.3375\n",
      "Epoch 1292/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2847 - mae: 2.2847 - mse: 12.2435 - val_loss: 2.3817 - val_mae: 2.3817 - val_mse: 13.5808\n",
      "Epoch 1293/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2980 - mae: 2.2980 - mse: 12.2549 - val_loss: 2.3875 - val_mae: 2.3875 - val_mse: 13.6676\n",
      "Epoch 1294/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3119 - mae: 2.3119 - mse: 12.3360 - val_loss: 2.4023 - val_mae: 2.4023 - val_mse: 13.8855\n",
      "Epoch 1295/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3597 - mae: 2.3597 - mse: 12.8362 - val_loss: 2.4587 - val_mae: 2.4587 - val_mse: 13.8075\n",
      "Epoch 1296/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3313 - mae: 2.3313 - mse: 12.6274 - val_loss: 2.4345 - val_mae: 2.4345 - val_mse: 13.7961\n",
      "Epoch 1297/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3236 - mae: 2.3236 - mse: 12.5495 - val_loss: 2.3837 - val_mae: 2.3837 - val_mse: 13.5985\n",
      "Epoch 1298/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3485 - mae: 2.3485 - mse: 12.6100 - val_loss: 2.4790 - val_mae: 2.4790 - val_mse: 13.6719\n",
      "Epoch 1299/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4049 - mae: 2.4049 - mse: 13.1223 - val_loss: 2.6449 - val_mae: 2.6449 - val_mse: 16.1595\n",
      "Epoch 1300/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3777 - mae: 2.3777 - mse: 12.8753 - val_loss: 2.3967 - val_mae: 2.3967 - val_mse: 13.4049\n",
      "Epoch 1301/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2988 - mae: 2.2988 - mse: 12.3419 - val_loss: 2.3981 - val_mae: 2.3981 - val_mse: 13.7923\n",
      "Epoch 1302/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2938 - mae: 2.2938 - mse: 12.3081 - val_loss: 2.3827 - val_mae: 2.3827 - val_mse: 13.4043\n",
      "Epoch 1303/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3791 - mae: 2.3791 - mse: 12.8841 - val_loss: 2.5053 - val_mae: 2.5053 - val_mse: 14.4091\n",
      "Epoch 1304/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3402 - mae: 2.3402 - mse: 12.8006 - val_loss: 2.4601 - val_mae: 2.4601 - val_mse: 13.7108\n",
      "Epoch 1305/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3246 - mae: 2.3246 - mse: 12.4164 - val_loss: 2.4326 - val_mae: 2.4326 - val_mse: 13.9505\n",
      "Epoch 1306/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3966 - mae: 2.3966 - mse: 12.9832 - val_loss: 2.4213 - val_mae: 2.4213 - val_mse: 13.5619\n",
      "Epoch 1307/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3109 - mae: 2.3109 - mse: 12.2999 - val_loss: 2.4890 - val_mae: 2.4890 - val_mse: 14.6641\n",
      "Epoch 1308/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3044 - mae: 2.3044 - mse: 12.4671 - val_loss: 2.4891 - val_mae: 2.4891 - val_mse: 14.5612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1309/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3106 - mae: 2.3106 - mse: 12.3735 - val_loss: 2.3643 - val_mae: 2.3643 - val_mse: 13.4123\n",
      "Epoch 1310/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3023 - mae: 2.3023 - mse: 12.4070 - val_loss: 2.3768 - val_mae: 2.3768 - val_mse: 13.5162\n",
      "Epoch 1311/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3696 - mae: 2.3696 - mse: 12.7433 - val_loss: 2.4060 - val_mae: 2.4060 - val_mse: 13.7916\n",
      "Epoch 1312/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3213 - mae: 2.3213 - mse: 12.4279 - val_loss: 2.5165 - val_mae: 2.5165 - val_mse: 14.4794\n",
      "Epoch 1313/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3379 - mae: 2.3379 - mse: 12.7103 - val_loss: 2.4315 - val_mae: 2.4315 - val_mse: 13.8969\n",
      "Epoch 1314/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.4369 - mae: 2.4369 - mse: 13.1825 - val_loss: 2.6050 - val_mae: 2.6050 - val_mse: 15.2261\n",
      "Epoch 1315/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.5015 - mae: 2.5015 - mse: 13.8336 - val_loss: 2.5999 - val_mae: 2.5999 - val_mse: 15.7612\n",
      "Epoch 1316/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4629 - mae: 2.4629 - mse: 13.7464 - val_loss: 2.5543 - val_mae: 2.5543 - val_mse: 14.4616\n",
      "Epoch 1317/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3927 - mae: 2.3927 - mse: 13.0289 - val_loss: 2.5942 - val_mae: 2.5942 - val_mse: 15.0696\n",
      "Epoch 1318/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3623 - mae: 2.3623 - mse: 12.8942 - val_loss: 2.4058 - val_mae: 2.4058 - val_mse: 13.6147\n",
      "Epoch 1319/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3331 - mae: 2.3331 - mse: 12.5619 - val_loss: 2.3882 - val_mae: 2.3882 - val_mse: 13.6199\n",
      "Epoch 1320/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2767 - mae: 2.2767 - mse: 12.1862 - val_loss: 2.4308 - val_mae: 2.4308 - val_mse: 13.6702\n",
      "Epoch 1321/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3225 - mae: 2.3225 - mse: 12.4808 - val_loss: 2.4582 - val_mae: 2.4582 - val_mse: 13.6043\n",
      "Epoch 1322/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3405 - mae: 2.3405 - mse: 12.7942 - val_loss: 2.4140 - val_mae: 2.4140 - val_mse: 14.4512\n",
      "Epoch 1323/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2985 - mae: 2.2985 - mse: 12.4297 - val_loss: 2.4610 - val_mae: 2.4610 - val_mse: 13.6084\n",
      "Epoch 1324/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3155 - mae: 2.3155 - mse: 12.4477 - val_loss: 2.4472 - val_mae: 2.4472 - val_mse: 14.4440\n",
      "Epoch 1325/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3048 - mae: 2.3048 - mse: 12.5170 - val_loss: 2.4100 - val_mae: 2.4100 - val_mse: 13.8692\n",
      "Epoch 1326/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3067 - mae: 2.3067 - mse: 12.5963 - val_loss: 2.4556 - val_mae: 2.4556 - val_mse: 13.7308\n",
      "Epoch 1327/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3080 - mae: 2.3080 - mse: 12.3604 - val_loss: 2.3897 - val_mae: 2.3897 - val_mse: 13.4447\n",
      "Epoch 1328/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3411 - mae: 2.3411 - mse: 12.6582 - val_loss: 2.4479 - val_mae: 2.4479 - val_mse: 13.6801\n",
      "Epoch 1329/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3321 - mae: 2.3321 - mse: 12.5904 - val_loss: 2.3908 - val_mae: 2.3908 - val_mse: 13.5710\n",
      "Epoch 1330/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3105 - mae: 2.3105 - mse: 12.4204 - val_loss: 2.4467 - val_mae: 2.4467 - val_mse: 13.5531\n",
      "Epoch 1331/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3326 - mae: 2.3326 - mse: 12.5533 - val_loss: 2.4755 - val_mae: 2.4755 - val_mse: 14.2066\n",
      "Epoch 1332/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3279 - mae: 2.3279 - mse: 12.6308 - val_loss: 2.4398 - val_mae: 2.4398 - val_mse: 13.8843\n",
      "Epoch 1333/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3027 - mae: 2.3027 - mse: 12.4136 - val_loss: 2.4214 - val_mae: 2.4214 - val_mse: 13.7461\n",
      "Epoch 1334/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3767 - mae: 2.3767 - mse: 12.8004 - val_loss: 2.5260 - val_mae: 2.5260 - val_mse: 15.2521\n",
      "Epoch 1335/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3917 - mae: 2.3917 - mse: 12.9245 - val_loss: 2.4402 - val_mae: 2.4402 - val_mse: 14.1754\n",
      "Epoch 1336/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4487 - mae: 2.4487 - mse: 13.2604 - val_loss: 2.5392 - val_mae: 2.5392 - val_mse: 13.9123\n",
      "Epoch 1337/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4282 - mae: 2.4282 - mse: 13.1245 - val_loss: 2.4305 - val_mae: 2.4305 - val_mse: 13.6868\n",
      "Epoch 1338/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3313 - mae: 2.3313 - mse: 12.5295 - val_loss: 2.4713 - val_mae: 2.4713 - val_mse: 13.9850\n",
      "Epoch 1339/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3049 - mae: 2.3049 - mse: 12.3642 - val_loss: 2.5053 - val_mae: 2.5053 - val_mse: 14.8304\n",
      "Epoch 1340/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3646 - mae: 2.3646 - mse: 12.9659 - val_loss: 2.4209 - val_mae: 2.4209 - val_mse: 13.8590\n",
      "Epoch 1341/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3142 - mae: 2.3142 - mse: 12.5153 - val_loss: 2.4512 - val_mae: 2.4512 - val_mse: 14.2429\n",
      "Epoch 1342/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2895 - mae: 2.2895 - mse: 12.3030 - val_loss: 2.4853 - val_mae: 2.4853 - val_mse: 14.0300\n",
      "Epoch 1343/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3017 - mae: 2.3017 - mse: 12.3647 - val_loss: 2.3714 - val_mae: 2.3714 - val_mse: 13.4241\n",
      "Epoch 1344/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3318 - mae: 2.3318 - mse: 12.5632 - val_loss: 2.4249 - val_mae: 2.4249 - val_mse: 13.7007\n",
      "Epoch 1345/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3041 - mae: 2.3041 - mse: 12.4580 - val_loss: 2.4262 - val_mae: 2.4262 - val_mse: 13.8654\n",
      "Epoch 1346/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3199 - mae: 2.3199 - mse: 12.4435 - val_loss: 2.4082 - val_mae: 2.4082 - val_mse: 13.7971\n",
      "Epoch 1347/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2743 - mae: 2.2743 - mse: 12.2324 - val_loss: 2.3735 - val_mae: 2.3735 - val_mse: 13.4417\n",
      "Epoch 1348/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2895 - mae: 2.2895 - mse: 12.2611 - val_loss: 2.4023 - val_mae: 2.4023 - val_mse: 13.8178\n",
      "Epoch 1349/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2866 - mae: 2.2866 - mse: 12.2374 - val_loss: 2.6531 - val_mae: 2.6531 - val_mse: 14.7931\n",
      "Epoch 1350/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3554 - mae: 2.3554 - mse: 12.7873 - val_loss: 2.5864 - val_mae: 2.5864 - val_mse: 15.8374\n",
      "Epoch 1351/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3049 - mae: 2.3049 - mse: 12.5584 - val_loss: 2.3786 - val_mae: 2.3786 - val_mse: 13.7574\n",
      "Epoch 1352/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3353 - mae: 2.3353 - mse: 12.4728 - val_loss: 2.4712 - val_mae: 2.4712 - val_mse: 14.3602\n",
      "Epoch 1353/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3320 - mae: 2.3320 - mse: 12.7497 - val_loss: 2.4803 - val_mae: 2.4803 - val_mse: 15.0757\n",
      "Epoch 1354/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3915 - mae: 2.3915 - mse: 12.9842 - val_loss: 2.5391 - val_mae: 2.5391 - val_mse: 14.6930\n",
      "Epoch 1355/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3445 - mae: 2.3445 - mse: 12.7470 - val_loss: 2.4075 - val_mae: 2.4075 - val_mse: 14.0706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1356/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3393 - mae: 2.3393 - mse: 12.4920 - val_loss: 2.4368 - val_mae: 2.4368 - val_mse: 13.5239\n",
      "Epoch 1357/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3153 - mae: 2.3153 - mse: 12.4133 - val_loss: 2.4661 - val_mae: 2.4661 - val_mse: 13.6128\n",
      "Epoch 1358/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3672 - mae: 2.3672 - mse: 12.6379 - val_loss: 2.4691 - val_mae: 2.4691 - val_mse: 13.6108\n",
      "Epoch 1359/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3729 - mae: 2.3729 - mse: 12.7642 - val_loss: 2.4095 - val_mae: 2.4095 - val_mse: 14.0011\n",
      "Epoch 1360/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2957 - mae: 2.2957 - mse: 12.2918 - val_loss: 2.4891 - val_mae: 2.4891 - val_mse: 14.4754\n",
      "Epoch 1361/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3018 - mae: 2.3018 - mse: 12.3558 - val_loss: 2.3907 - val_mae: 2.3907 - val_mse: 13.8379\n",
      "Epoch 1362/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.4149 - mae: 2.4149 - mse: 13.1765 - val_loss: 2.5837 - val_mae: 2.5837 - val_mse: 15.1471\n",
      "Epoch 1363/2500\n",
      "684/684 [==============================] - 1s 783us/sample - loss: 2.4911 - mae: 2.4911 - mse: 14.0408 - val_loss: 2.8990 - val_mae: 2.8990 - val_mse: 16.1845\n",
      "Epoch 1364/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.4791 - mae: 2.4791 - mse: 14.0578 - val_loss: 2.4772 - val_mae: 2.4772 - val_mse: 15.0676\n",
      "Epoch 1365/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3198 - mae: 2.3198 - mse: 12.5905 - val_loss: 2.4123 - val_mae: 2.4123 - val_mse: 14.0094\n",
      "Epoch 1366/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3111 - mae: 2.3111 - mse: 12.4492 - val_loss: 2.3887 - val_mae: 2.3887 - val_mse: 13.6097\n",
      "Epoch 1367/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2810 - mae: 2.2810 - mse: 12.2541 - val_loss: 2.4196 - val_mae: 2.4196 - val_mse: 13.5103\n",
      "Epoch 1368/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2935 - mae: 2.2935 - mse: 12.1853 - val_loss: 2.4011 - val_mae: 2.4011 - val_mse: 13.9284\n",
      "Epoch 1369/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3194 - mae: 2.3194 - mse: 12.3201 - val_loss: 2.5014 - val_mae: 2.5014 - val_mse: 13.5590\n",
      "Epoch 1370/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3231 - mae: 2.3231 - mse: 12.4623 - val_loss: 2.4095 - val_mae: 2.4095 - val_mse: 13.9077\n",
      "Epoch 1371/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3235 - mae: 2.3235 - mse: 12.4653 - val_loss: 2.3745 - val_mae: 2.3745 - val_mse: 13.5289\n",
      "Epoch 1372/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.2828 - mae: 2.2828 - mse: 12.2592 - val_loss: 2.3834 - val_mae: 2.3834 - val_mse: 13.5815\n",
      "Epoch 1373/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2829 - mae: 2.2829 - mse: 12.1614 - val_loss: 2.4216 - val_mae: 2.4216 - val_mse: 13.8734\n",
      "Epoch 1374/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3022 - mae: 2.3022 - mse: 12.3264 - val_loss: 2.3933 - val_mae: 2.3933 - val_mse: 13.6713\n",
      "Epoch 1375/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2760 - mae: 2.2760 - mse: 12.1889 - val_loss: 2.3919 - val_mae: 2.3919 - val_mse: 13.7096\n",
      "Epoch 1376/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2939 - mae: 2.2939 - mse: 12.3980 - val_loss: 2.5368 - val_mae: 2.5368 - val_mse: 16.6673\n",
      "Epoch 1377/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3126 - mae: 2.3126 - mse: 12.4734 - val_loss: 2.4185 - val_mae: 2.4185 - val_mse: 13.4824\n",
      "Epoch 1378/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3119 - mae: 2.3119 - mse: 12.3831 - val_loss: 2.4770 - val_mae: 2.4770 - val_mse: 13.5554\n",
      "Epoch 1379/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3435 - mae: 2.3435 - mse: 12.5709 - val_loss: 2.4576 - val_mae: 2.4576 - val_mse: 13.9603\n",
      "Epoch 1380/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3061 - mae: 2.3061 - mse: 12.2623 - val_loss: 2.4441 - val_mae: 2.4441 - val_mse: 13.9747\n",
      "Epoch 1381/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3101 - mae: 2.3101 - mse: 12.5959 - val_loss: 2.4011 - val_mae: 2.4011 - val_mse: 13.8150\n",
      "Epoch 1382/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3374 - mae: 2.3374 - mse: 12.4757 - val_loss: 2.5567 - val_mae: 2.5567 - val_mse: 14.8224\n",
      "Epoch 1383/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3372 - mae: 2.3372 - mse: 12.6187 - val_loss: 2.4926 - val_mae: 2.4926 - val_mse: 14.4459\n",
      "Epoch 1384/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3172 - mae: 2.3172 - mse: 12.4974 - val_loss: 2.4362 - val_mae: 2.4362 - val_mse: 14.2526\n",
      "Epoch 1385/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2948 - mae: 2.2948 - mse: 12.3387 - val_loss: 2.4045 - val_mae: 2.4045 - val_mse: 13.7082\n",
      "Epoch 1386/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2984 - mae: 2.2984 - mse: 12.3214 - val_loss: 2.5166 - val_mae: 2.5166 - val_mse: 14.6239\n",
      "Epoch 1387/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3063 - mae: 2.3063 - mse: 12.3778 - val_loss: 2.3847 - val_mae: 2.3847 - val_mse: 13.5895\n",
      "Epoch 1388/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3305 - mae: 2.3305 - mse: 12.5809 - val_loss: 2.4684 - val_mae: 2.4684 - val_mse: 14.3970\n",
      "Epoch 1389/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2997 - mae: 2.2997 - mse: 12.4620 - val_loss: 2.3919 - val_mae: 2.3919 - val_mse: 13.5787\n",
      "Epoch 1390/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2866 - mae: 2.2866 - mse: 12.2193 - val_loss: 2.4221 - val_mae: 2.4221 - val_mse: 13.7071\n",
      "Epoch 1391/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3580 - mae: 2.3580 - mse: 12.5817 - val_loss: 2.4663 - val_mae: 2.4663 - val_mse: 14.1816\n",
      "Epoch 1392/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.6927 - mae: 2.6927 - mse: 15.6651 - val_loss: 3.3169 - val_mae: 3.3169 - val_mse: 18.5223\n",
      "Epoch 1393/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.5558 - mae: 2.5558 - mse: 14.8379 - val_loss: 2.5156 - val_mae: 2.5156 - val_mse: 15.9755\n",
      "Epoch 1394/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3981 - mae: 2.3981 - mse: 13.3290 - val_loss: 2.4465 - val_mae: 2.4465 - val_mse: 13.8544\n",
      "Epoch 1395/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3167 - mae: 2.3167 - mse: 12.4401 - val_loss: 2.3983 - val_mae: 2.3983 - val_mse: 13.7308\n",
      "Epoch 1396/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2999 - mae: 2.2999 - mse: 12.4723 - val_loss: 2.4278 - val_mae: 2.4278 - val_mse: 14.1500\n",
      "Epoch 1397/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3253 - mae: 2.3253 - mse: 12.5597 - val_loss: 2.4301 - val_mae: 2.4301 - val_mse: 14.2750\n",
      "Epoch 1398/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3613 - mae: 2.3613 - mse: 12.7683 - val_loss: 2.4674 - val_mae: 2.4674 - val_mse: 14.2107\n",
      "Epoch 1399/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3259 - mae: 2.3259 - mse: 12.4769 - val_loss: 2.4578 - val_mae: 2.4578 - val_mse: 14.0668\n",
      "Epoch 1400/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3274 - mae: 2.3274 - mse: 12.4514 - val_loss: 2.3825 - val_mae: 2.3825 - val_mse: 13.6302\n",
      "Epoch 1401/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3392 - mae: 2.3392 - mse: 12.6131 - val_loss: 2.4543 - val_mae: 2.4543 - val_mse: 14.0520\n",
      "Epoch 1402/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3062 - mae: 2.3062 - mse: 12.3420 - val_loss: 2.3776 - val_mae: 2.3776 - val_mse: 13.6308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1403/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2828 - mae: 2.2828 - mse: 12.3418 - val_loss: 2.3776 - val_mae: 2.3776 - val_mse: 13.5432\n",
      "Epoch 1404/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3022 - mae: 2.3022 - mse: 12.3722 - val_loss: 2.4056 - val_mae: 2.4056 - val_mse: 13.7686\n",
      "Epoch 1405/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3055 - mae: 2.3055 - mse: 12.3803 - val_loss: 2.3781 - val_mae: 2.3781 - val_mse: 13.6004\n",
      "Epoch 1406/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3885 - mae: 2.3885 - mse: 13.0989 - val_loss: 2.7236 - val_mae: 2.7236 - val_mse: 17.2896\n",
      "Epoch 1407/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3447 - mae: 2.3447 - mse: 12.6289 - val_loss: 2.4129 - val_mae: 2.4129 - val_mse: 13.4896\n",
      "Epoch 1408/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3275 - mae: 2.3275 - mse: 12.4573 - val_loss: 2.3905 - val_mae: 2.3905 - val_mse: 13.5117\n",
      "Epoch 1409/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2696 - mae: 2.2696 - mse: 12.0823 - val_loss: 2.3961 - val_mae: 2.3961 - val_mse: 13.8217\n",
      "Epoch 1410/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2724 - mae: 2.2724 - mse: 12.1620 - val_loss: 2.3565 - val_mae: 2.3565 - val_mse: 13.3519\n",
      "Epoch 1411/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2893 - mae: 2.2893 - mse: 12.2808 - val_loss: 2.3930 - val_mae: 2.3930 - val_mse: 13.5036\n",
      "Epoch 1412/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2995 - mae: 2.2995 - mse: 12.2946 - val_loss: 2.4941 - val_mae: 2.4941 - val_mse: 14.5272\n",
      "Epoch 1413/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3307 - mae: 2.3307 - mse: 12.5463 - val_loss: 2.3862 - val_mae: 2.3862 - val_mse: 13.7800\n",
      "Epoch 1414/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2988 - mae: 2.2988 - mse: 12.3420 - val_loss: 2.4165 - val_mae: 2.4165 - val_mse: 13.6495\n",
      "Epoch 1415/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3342 - mae: 2.3342 - mse: 12.6876 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 14.9743\n",
      "Epoch 1416/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2697 - mae: 2.2697 - mse: 12.1891 - val_loss: 2.4359 - val_mae: 2.4359 - val_mse: 13.5679\n",
      "Epoch 1417/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3669 - mae: 2.3669 - mse: 12.7145 - val_loss: 2.4184 - val_mae: 2.4184 - val_mse: 13.9256\n",
      "Epoch 1418/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3048 - mae: 2.3048 - mse: 12.4058 - val_loss: 2.4005 - val_mae: 2.4005 - val_mse: 13.5990\n",
      "Epoch 1419/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2781 - mae: 2.2781 - mse: 12.2293 - val_loss: 2.4249 - val_mae: 2.4249 - val_mse: 13.6947\n",
      "Epoch 1420/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2709 - mae: 2.2709 - mse: 12.1361 - val_loss: 2.3906 - val_mae: 2.3906 - val_mse: 13.6768\n",
      "Epoch 1421/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2717 - mae: 2.2717 - mse: 12.2045 - val_loss: 2.4280 - val_mae: 2.4280 - val_mse: 14.2764\n",
      "Epoch 1422/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3127 - mae: 2.3127 - mse: 12.4416 - val_loss: 2.4777 - val_mae: 2.4777 - val_mse: 14.0340\n",
      "Epoch 1423/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3578 - mae: 2.3578 - mse: 12.8743 - val_loss: 2.4742 - val_mae: 2.4742 - val_mse: 14.0708\n",
      "Epoch 1424/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3889 - mae: 2.3889 - mse: 13.0658 - val_loss: 2.8066 - val_mae: 2.8066 - val_mse: 16.9206\n",
      "Epoch 1425/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3371 - mae: 2.3371 - mse: 12.4222 - val_loss: 2.4199 - val_mae: 2.4199 - val_mse: 13.9810\n",
      "Epoch 1426/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3021 - mae: 2.3021 - mse: 12.3654 - val_loss: 2.4076 - val_mae: 2.4076 - val_mse: 13.6391\n",
      "Epoch 1427/2500\n",
      "684/684 [==============================] - 1s 814us/sample - loss: 2.3028 - mae: 2.3028 - mse: 12.3331 - val_loss: 2.4140 - val_mae: 2.4140 - val_mse: 13.9383\n",
      "Epoch 1428/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2723 - mae: 2.2723 - mse: 12.1033 - val_loss: 2.4289 - val_mae: 2.4289 - val_mse: 13.8875\n",
      "Epoch 1429/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3487 - mae: 2.3487 - mse: 12.5874 - val_loss: 2.5643 - val_mae: 2.5643 - val_mse: 15.2132\n",
      "Epoch 1430/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3158 - mae: 2.3158 - mse: 12.5706 - val_loss: 2.4434 - val_mae: 2.4434 - val_mse: 14.3807\n",
      "Epoch 1431/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3312 - mae: 2.3312 - mse: 12.5714 - val_loss: 2.4052 - val_mae: 2.4052 - val_mse: 14.1246\n",
      "Epoch 1432/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.4595 - val_loss: 2.3725 - val_mae: 2.3725 - val_mse: 13.4392\n",
      "Epoch 1433/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3394 - mae: 2.3394 - mse: 12.7188 - val_loss: 2.5363 - val_mae: 2.5363 - val_mse: 14.2427\n",
      "Epoch 1434/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3392 - mae: 2.3392 - mse: 12.7448 - val_loss: 2.4004 - val_mae: 2.4004 - val_mse: 13.9111\n",
      "Epoch 1435/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3415 - mae: 2.3415 - mse: 12.7289 - val_loss: 2.4453 - val_mae: 2.4453 - val_mse: 14.3459\n",
      "Epoch 1436/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3168 - mae: 2.3168 - mse: 12.3628 - val_loss: 2.3851 - val_mae: 2.3851 - val_mse: 13.5893\n",
      "Epoch 1437/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3557 - mae: 2.3557 - mse: 12.7515 - val_loss: 2.4761 - val_mae: 2.4761 - val_mse: 14.7621\n",
      "Epoch 1438/2500\n",
      "684/684 [==============================] - 1s 781us/sample - loss: 2.3295 - mae: 2.3295 - mse: 12.5072 - val_loss: 2.4215 - val_mae: 2.4215 - val_mse: 13.8179\n",
      "Epoch 1439/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3151 - mae: 2.3151 - mse: 12.5074 - val_loss: 2.4181 - val_mae: 2.4181 - val_mse: 14.2517\n",
      "Epoch 1440/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3215 - mae: 2.3215 - mse: 12.6928 - val_loss: 2.3971 - val_mae: 2.3971 - val_mse: 13.9027\n",
      "Epoch 1441/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2788 - mae: 2.2788 - mse: 12.1917 - val_loss: 2.4299 - val_mae: 2.4299 - val_mse: 14.0431\n",
      "Epoch 1442/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3188 - mae: 2.3188 - mse: 12.5123 - val_loss: 2.4742 - val_mae: 2.4742 - val_mse: 14.4829\n",
      "Epoch 1443/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3907 - mae: 2.3907 - mse: 13.1817 - val_loss: 2.4944 - val_mae: 2.4944 - val_mse: 13.8744\n",
      "Epoch 1444/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3559 - mae: 2.3559 - mse: 12.7975 - val_loss: 2.4434 - val_mae: 2.4434 - val_mse: 13.8269\n",
      "Epoch 1445/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3125 - mae: 2.3125 - mse: 12.5317 - val_loss: 2.4618 - val_mae: 2.4618 - val_mse: 13.9670\n",
      "Epoch 1446/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2894 - mae: 2.2894 - mse: 12.2177 - val_loss: 2.5140 - val_mae: 2.5140 - val_mse: 14.6886\n",
      "Epoch 1447/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3004 - mae: 2.3004 - mse: 12.3336 - val_loss: 2.4060 - val_mae: 2.4060 - val_mse: 14.3510\n",
      "Epoch 1448/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3032 - mae: 2.3032 - mse: 12.3706 - val_loss: 2.4526 - val_mae: 2.4526 - val_mse: 14.0778\n",
      "Epoch 1449/2500\n",
      "684/684 [==============================] - 1s 782us/sample - loss: 2.2860 - mae: 2.2860 - mse: 12.1855 - val_loss: 2.3675 - val_mae: 2.3675 - val_mse: 13.4515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1450/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2658 - mae: 2.2658 - mse: 12.1843 - val_loss: 2.3941 - val_mae: 2.3941 - val_mse: 13.4482\n",
      "Epoch 1451/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.2967 - mae: 2.2967 - mse: 12.2212 - val_loss: 2.4069 - val_mae: 2.4069 - val_mse: 13.7411\n",
      "Epoch 1452/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2816 - mae: 2.2816 - mse: 12.1898 - val_loss: 2.4009 - val_mae: 2.4009 - val_mse: 13.5826\n",
      "Epoch 1453/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.1756 - val_loss: 2.4678 - val_mae: 2.4678 - val_mse: 14.6686\n",
      "Epoch 1454/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2980 - mae: 2.2980 - mse: 12.2793 - val_loss: 2.3974 - val_mae: 2.3974 - val_mse: 13.6900\n",
      "Epoch 1455/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3000 - mae: 2.3000 - mse: 12.2884 - val_loss: 2.4034 - val_mae: 2.4034 - val_mse: 13.5668\n",
      "Epoch 1456/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3078 - mae: 2.3078 - mse: 12.3463 - val_loss: 2.4018 - val_mae: 2.4018 - val_mse: 13.5289\n",
      "Epoch 1457/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2775 - mae: 2.2775 - mse: 12.1680 - val_loss: 2.3875 - val_mae: 2.3875 - val_mse: 13.6311\n",
      "Epoch 1458/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3002 - mae: 2.3002 - mse: 12.3827 - val_loss: 2.4037 - val_mae: 2.4037 - val_mse: 13.8942\n",
      "Epoch 1459/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3173 - mae: 2.3173 - mse: 12.4542 - val_loss: 2.6439 - val_mae: 2.6439 - val_mse: 15.7148\n",
      "Epoch 1460/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3797 - mae: 2.3797 - mse: 12.8907 - val_loss: 2.6545 - val_mae: 2.6545 - val_mse: 15.1018\n",
      "Epoch 1461/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3070 - mae: 2.3070 - mse: 12.3696 - val_loss: 2.4320 - val_mae: 2.4320 - val_mse: 13.6804\n",
      "Epoch 1462/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3238 - mae: 2.3238 - mse: 12.5053 - val_loss: 2.5521 - val_mae: 2.5521 - val_mse: 15.7117\n",
      "Epoch 1463/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.4186 - mae: 2.4186 - mse: 13.1413 - val_loss: 2.4301 - val_mae: 2.4301 - val_mse: 14.0506\n",
      "Epoch 1464/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3572 - mae: 2.3572 - mse: 12.6967 - val_loss: 2.4151 - val_mae: 2.4151 - val_mse: 14.0540\n",
      "Epoch 1465/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3101 - mae: 2.3101 - mse: 12.4486 - val_loss: 2.3961 - val_mae: 2.3961 - val_mse: 13.6203\n",
      "Epoch 1466/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3134 - mae: 2.3134 - mse: 12.3968 - val_loss: 2.3763 - val_mae: 2.3763 - val_mse: 13.4099\n",
      "Epoch 1467/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3459 - mae: 2.3459 - mse: 12.5327 - val_loss: 2.5337 - val_mae: 2.5337 - val_mse: 13.8827\n",
      "Epoch 1468/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3432 - mae: 2.3432 - mse: 12.6691 - val_loss: 2.5633 - val_mae: 2.5633 - val_mse: 13.9926\n",
      "Epoch 1469/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.4263 - mae: 2.4263 - mse: 13.2467 - val_loss: 2.5635 - val_mae: 2.5635 - val_mse: 14.9919\n",
      "Epoch 1470/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.4186 - mae: 2.4186 - mse: 13.2992 - val_loss: 2.5009 - val_mae: 2.5009 - val_mse: 14.5091\n",
      "Epoch 1471/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4084 - mae: 2.4084 - mse: 13.3468 - val_loss: 2.4248 - val_mae: 2.4248 - val_mse: 13.9048\n",
      "Epoch 1472/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3248 - mae: 2.3248 - mse: 12.5802 - val_loss: 2.4438 - val_mae: 2.4438 - val_mse: 14.3437\n",
      "Epoch 1473/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3053 - mae: 2.3053 - mse: 12.4435 - val_loss: 2.3795 - val_mae: 2.3795 - val_mse: 13.6221\n",
      "Epoch 1474/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2966 - mae: 2.2966 - mse: 12.3272 - val_loss: 2.4433 - val_mae: 2.4433 - val_mse: 13.5003\n",
      "Epoch 1475/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3309 - mae: 2.3309 - mse: 12.4997 - val_loss: 2.4262 - val_mae: 2.4262 - val_mse: 13.7075\n",
      "Epoch 1476/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3398 - mae: 2.3398 - mse: 12.6342 - val_loss: 2.4780 - val_mae: 2.4780 - val_mse: 14.1226\n",
      "Epoch 1477/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4247 - mae: 2.4247 - mse: 13.4125 - val_loss: 2.4497 - val_mae: 2.4497 - val_mse: 14.1016\n",
      "Epoch 1478/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3143 - mae: 2.3143 - mse: 12.5752 - val_loss: 2.4321 - val_mae: 2.4321 - val_mse: 13.5217\n",
      "Epoch 1479/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2814 - mae: 2.2814 - mse: 12.3315 - val_loss: 2.3715 - val_mae: 2.3715 - val_mse: 13.6695\n",
      "Epoch 1480/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2868 - mae: 2.2868 - mse: 12.3713 - val_loss: 2.4245 - val_mae: 2.4245 - val_mse: 14.1313\n",
      "Epoch 1481/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3380 - mae: 2.3380 - mse: 12.5285 - val_loss: 2.3800 - val_mae: 2.3800 - val_mse: 13.6003\n",
      "Epoch 1482/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3590 - mae: 2.3590 - mse: 12.7486 - val_loss: 2.5252 - val_mae: 2.5252 - val_mse: 14.9414\n",
      "Epoch 1483/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.4072 - mae: 2.4072 - mse: 13.2641 - val_loss: 2.4681 - val_mae: 2.4681 - val_mse: 13.9812\n",
      "Epoch 1484/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3651 - mae: 2.3651 - mse: 12.8482 - val_loss: 2.5857 - val_mae: 2.5857 - val_mse: 14.0905\n",
      "Epoch 1485/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3445 - mae: 2.3445 - mse: 12.6925 - val_loss: 2.4594 - val_mae: 2.4594 - val_mse: 14.1901\n",
      "Epoch 1486/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3271 - mae: 2.3271 - mse: 12.6522 - val_loss: 2.4086 - val_mae: 2.4086 - val_mse: 13.5490\n",
      "Epoch 1487/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3296 - mae: 2.3296 - mse: 12.6961 - val_loss: 2.4169 - val_mae: 2.4169 - val_mse: 13.8396\n",
      "Epoch 1488/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3639 - mae: 2.3639 - mse: 12.7408 - val_loss: 2.4569 - val_mae: 2.4569 - val_mse: 13.9800\n",
      "Epoch 1489/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2769 - mae: 2.2769 - mse: 12.1659 - val_loss: 2.5824 - val_mae: 2.5824 - val_mse: 13.9798\n",
      "Epoch 1490/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2900 - mae: 2.2900 - mse: 12.3298 - val_loss: 2.4044 - val_mae: 2.4044 - val_mse: 13.6378\n",
      "Epoch 1491/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3050 - mae: 2.3050 - mse: 12.4224 - val_loss: 2.3980 - val_mae: 2.3980 - val_mse: 13.7145\n",
      "Epoch 1492/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2878 - mae: 2.2878 - mse: 12.2370 - val_loss: 2.3621 - val_mae: 2.3621 - val_mse: 13.6218\n",
      "Epoch 1493/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3217 - mae: 2.3217 - mse: 12.4938 - val_loss: 2.4014 - val_mae: 2.4014 - val_mse: 13.6081\n",
      "Epoch 1494/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3072 - mae: 2.3072 - mse: 12.3199 - val_loss: 2.3874 - val_mae: 2.3874 - val_mse: 13.4519\n",
      "Epoch 1495/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3435 - mae: 2.3435 - mse: 12.6503 - val_loss: 2.4419 - val_mae: 2.4419 - val_mse: 13.8893\n",
      "Epoch 1496/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3627 - mae: 2.3627 - mse: 12.7446 - val_loss: 2.4851 - val_mae: 2.4851 - val_mse: 14.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1497/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2933 - mae: 2.2933 - mse: 12.2689 - val_loss: 2.4177 - val_mae: 2.4177 - val_mse: 13.8859\n",
      "Epoch 1498/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3084 - mae: 2.3084 - mse: 12.3286 - val_loss: 2.4323 - val_mae: 2.4323 - val_mse: 13.7896\n",
      "Epoch 1499/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2844 - mae: 2.2844 - mse: 12.2930 - val_loss: 2.4019 - val_mae: 2.4019 - val_mse: 13.4694\n",
      "Epoch 1500/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2854 - mae: 2.2854 - mse: 12.1445 - val_loss: 2.3753 - val_mae: 2.3753 - val_mse: 13.5883\n",
      "Epoch 1501/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3492 - mae: 2.3492 - mse: 12.7207 - val_loss: 2.4314 - val_mae: 2.4314 - val_mse: 13.9356\n",
      "Epoch 1502/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3741 - mae: 2.3741 - mse: 12.9652 - val_loss: 2.4392 - val_mae: 2.4392 - val_mse: 14.0954\n",
      "Epoch 1503/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3372 - mae: 2.3372 - mse: 12.4836 - val_loss: 2.5511 - val_mae: 2.5511 - val_mse: 13.8607\n",
      "Epoch 1504/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3191 - mae: 2.3191 - mse: 12.6592 - val_loss: 2.4046 - val_mae: 2.4046 - val_mse: 13.8065\n",
      "Epoch 1505/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3160 - mae: 2.3160 - mse: 12.3866 - val_loss: 2.3800 - val_mae: 2.3800 - val_mse: 13.5402\n",
      "Epoch 1506/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.2818 - mae: 2.2818 - mse: 12.1464 - val_loss: 2.4235 - val_mae: 2.4235 - val_mse: 13.4895\n",
      "Epoch 1507/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3408 - mae: 2.3408 - mse: 12.6466 - val_loss: 2.4930 - val_mae: 2.4930 - val_mse: 15.5126\n",
      "Epoch 1508/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4185 - mae: 2.4185 - mse: 13.2923 - val_loss: 2.5492 - val_mae: 2.5492 - val_mse: 14.0039\n",
      "Epoch 1509/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3223 - mae: 2.3223 - mse: 12.4256 - val_loss: 2.4432 - val_mae: 2.4432 - val_mse: 13.9719\n",
      "Epoch 1510/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2999 - mae: 2.2999 - mse: 12.3965 - val_loss: 2.4214 - val_mae: 2.4214 - val_mse: 13.5907\n",
      "Epoch 1511/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2865 - mae: 2.2865 - mse: 12.2238 - val_loss: 2.3885 - val_mae: 2.3885 - val_mse: 13.6995\n",
      "Epoch 1512/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3073 - mae: 2.3073 - mse: 12.3634 - val_loss: 2.4351 - val_mae: 2.4351 - val_mse: 13.6026\n",
      "Epoch 1513/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3027 - mae: 2.3027 - mse: 12.3709 - val_loss: 2.4979 - val_mae: 2.4979 - val_mse: 14.4368\n",
      "Epoch 1514/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3044 - mae: 2.3044 - mse: 12.4016 - val_loss: 2.4185 - val_mae: 2.4185 - val_mse: 13.3987\n",
      "Epoch 1515/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2975 - mae: 2.2975 - mse: 12.2028 - val_loss: 2.6700 - val_mae: 2.6700 - val_mse: 15.8362\n",
      "Epoch 1516/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3514 - mae: 2.3514 - mse: 12.8717 - val_loss: 2.5963 - val_mae: 2.5963 - val_mse: 15.5905\n",
      "Epoch 1517/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3152 - mae: 2.3152 - mse: 12.5111 - val_loss: 2.5388 - val_mae: 2.5388 - val_mse: 14.4633\n",
      "Epoch 1518/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2906 - mae: 2.2906 - mse: 12.2206 - val_loss: 2.4090 - val_mae: 2.4090 - val_mse: 13.4628\n",
      "Epoch 1519/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3477 - mae: 2.3477 - mse: 12.6081 - val_loss: 2.4326 - val_mae: 2.4326 - val_mse: 13.4187\n",
      "Epoch 1520/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3144 - mae: 2.3144 - mse: 12.3768 - val_loss: 2.3993 - val_mae: 2.3993 - val_mse: 13.8554\n",
      "Epoch 1521/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2776 - mae: 2.2776 - mse: 12.2180 - val_loss: 2.5033 - val_mae: 2.5033 - val_mse: 13.8534\n",
      "Epoch 1522/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3201 - mae: 2.3201 - mse: 12.3452 - val_loss: 2.3980 - val_mae: 2.3980 - val_mse: 13.7831\n",
      "Epoch 1523/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2808 - mae: 2.2808 - mse: 12.2058 - val_loss: 2.3856 - val_mae: 2.3856 - val_mse: 13.6581\n",
      "Epoch 1524/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2766 - mae: 2.2766 - mse: 12.1761 - val_loss: 2.3898 - val_mae: 2.3898 - val_mse: 14.0405\n",
      "Epoch 1525/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3133 - mae: 2.3133 - mse: 12.3915 - val_loss: 2.4177 - val_mae: 2.4177 - val_mse: 13.9036\n",
      "Epoch 1526/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3012 - mae: 2.3012 - mse: 12.3219 - val_loss: 2.3801 - val_mae: 2.3801 - val_mse: 13.5950\n",
      "Epoch 1527/2500\n",
      "684/684 [==============================] - 1s 813us/sample - loss: 2.3131 - mae: 2.3131 - mse: 12.3547 - val_loss: 2.4198 - val_mae: 2.4198 - val_mse: 13.4463\n",
      "Epoch 1528/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3185 - mae: 2.3185 - mse: 12.4772 - val_loss: 2.4352 - val_mae: 2.4352 - val_mse: 14.0253\n",
      "Epoch 1529/2500\n",
      "684/684 [==============================] - 1s 810us/sample - loss: 2.3034 - mae: 2.3034 - mse: 12.3972 - val_loss: 2.4696 - val_mae: 2.4696 - val_mse: 14.3747\n",
      "Epoch 1530/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3003 - mae: 2.3003 - mse: 12.3248 - val_loss: 2.4206 - val_mae: 2.4206 - val_mse: 13.5142\n",
      "Epoch 1531/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2878 - mae: 2.2878 - mse: 12.2508 - val_loss: 2.3622 - val_mae: 2.3622 - val_mse: 13.4836\n",
      "Epoch 1532/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2937 - mae: 2.2937 - mse: 12.2931 - val_loss: 2.4093 - val_mae: 2.4093 - val_mse: 13.8017\n",
      "Epoch 1533/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2873 - mae: 2.2873 - mse: 12.2457 - val_loss: 2.4657 - val_mae: 2.4657 - val_mse: 13.9730\n",
      "Epoch 1534/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2899 - mae: 2.2899 - mse: 12.2628 - val_loss: 2.4819 - val_mae: 2.4819 - val_mse: 14.4398\n",
      "Epoch 1535/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2905 - mae: 2.2905 - mse: 12.2534 - val_loss: 2.4401 - val_mae: 2.4401 - val_mse: 13.8274\n",
      "Epoch 1536/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2885 - mae: 2.2885 - mse: 12.2230 - val_loss: 2.4409 - val_mae: 2.4409 - val_mse: 13.8917\n",
      "Epoch 1537/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3223 - mae: 2.3223 - mse: 12.5512 - val_loss: 2.4212 - val_mae: 2.4212 - val_mse: 13.8622\n",
      "Epoch 1538/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2859 - mae: 2.2859 - mse: 12.3077 - val_loss: 2.3850 - val_mae: 2.3850 - val_mse: 13.4761\n",
      "Epoch 1539/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3011 - mae: 2.3011 - mse: 12.2893 - val_loss: 2.4149 - val_mae: 2.4149 - val_mse: 14.1224\n",
      "Epoch 1540/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3031 - mae: 2.3031 - mse: 12.2541 - val_loss: 2.4299 - val_mae: 2.4299 - val_mse: 13.7054\n",
      "Epoch 1541/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3756 - mae: 2.3756 - mse: 13.0487 - val_loss: 2.4493 - val_mae: 2.4493 - val_mse: 15.0793\n",
      "Epoch 1542/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3246 - mae: 2.3246 - mse: 12.6299 - val_loss: 2.4154 - val_mae: 2.4154 - val_mse: 13.7654\n",
      "Epoch 1543/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3014 - mae: 2.3014 - mse: 12.4434 - val_loss: 2.4460 - val_mae: 2.4460 - val_mse: 14.0498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1544/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3141 - mae: 2.3141 - mse: 12.3691 - val_loss: 2.4057 - val_mae: 2.4057 - val_mse: 13.8107\n",
      "Epoch 1545/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3327 - mae: 2.3327 - mse: 12.4703 - val_loss: 2.6005 - val_mae: 2.6005 - val_mse: 14.3322\n",
      "Epoch 1546/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3355 - mae: 2.3355 - mse: 12.5445 - val_loss: 2.3748 - val_mae: 2.3748 - val_mse: 13.4705\n",
      "Epoch 1547/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2937 - mae: 2.2937 - mse: 12.2064 - val_loss: 2.4293 - val_mae: 2.4293 - val_mse: 13.8856\n",
      "Epoch 1548/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3202 - mae: 2.3202 - mse: 12.4900 - val_loss: 2.4284 - val_mae: 2.4284 - val_mse: 14.2381\n",
      "Epoch 1549/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2835 - mae: 2.2835 - mse: 12.3141 - val_loss: 2.4124 - val_mae: 2.4124 - val_mse: 13.9677\n",
      "Epoch 1550/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2953 - mae: 2.2953 - mse: 12.2900 - val_loss: 2.3931 - val_mae: 2.3931 - val_mse: 13.6280\n",
      "Epoch 1551/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3302 - mae: 2.3302 - mse: 12.5800 - val_loss: 2.4086 - val_mae: 2.4086 - val_mse: 13.9327\n",
      "Epoch 1552/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3005 - mae: 2.3005 - mse: 12.4009 - val_loss: 2.4109 - val_mae: 2.4109 - val_mse: 13.4827\n",
      "Epoch 1553/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2997 - mae: 2.2997 - mse: 12.2643 - val_loss: 2.4007 - val_mae: 2.4007 - val_mse: 13.7801\n",
      "Epoch 1554/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2853 - mae: 2.2853 - mse: 12.2307 - val_loss: 2.4242 - val_mae: 2.4242 - val_mse: 13.8528\n",
      "Epoch 1555/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3219 - mae: 2.3219 - mse: 12.4355 - val_loss: 2.4461 - val_mae: 2.4461 - val_mse: 14.5280\n",
      "Epoch 1556/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2844 - mae: 2.2844 - mse: 12.3165 - val_loss: 2.3743 - val_mae: 2.3743 - val_mse: 13.6986\n",
      "Epoch 1557/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3674 - mae: 2.3674 - mse: 12.8503 - val_loss: 2.5036 - val_mae: 2.5036 - val_mse: 13.7403\n",
      "Epoch 1558/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3633 - mae: 2.3633 - mse: 12.7409 - val_loss: 2.5482 - val_mae: 2.5482 - val_mse: 14.4824\n",
      "Epoch 1559/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3201 - mae: 2.3201 - mse: 12.4259 - val_loss: 2.3941 - val_mae: 2.3941 - val_mse: 13.5053\n",
      "Epoch 1560/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3154 - mae: 2.3154 - mse: 12.5308 - val_loss: 2.3861 - val_mae: 2.3861 - val_mse: 13.5579\n",
      "Epoch 1561/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3142 - mae: 2.3142 - mse: 12.3864 - val_loss: 2.4920 - val_mae: 2.4920 - val_mse: 13.9263\n",
      "Epoch 1562/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3634 - mae: 2.3634 - mse: 12.5791 - val_loss: 2.6048 - val_mae: 2.6048 - val_mse: 16.2517\n",
      "Epoch 1563/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3579 - mae: 2.3579 - mse: 12.9056 - val_loss: 2.4421 - val_mae: 2.4421 - val_mse: 14.1991\n",
      "Epoch 1564/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3891 - mae: 2.3891 - mse: 13.2560 - val_loss: 2.4226 - val_mae: 2.4226 - val_mse: 13.7801\n",
      "Epoch 1565/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3308 - mae: 2.3308 - mse: 12.7659 - val_loss: 2.5098 - val_mae: 2.5098 - val_mse: 14.3183\n",
      "Epoch 1566/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3002 - mae: 2.3002 - mse: 12.3454 - val_loss: 2.3884 - val_mae: 2.3884 - val_mse: 13.6132\n",
      "Epoch 1567/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.2323 - val_loss: 2.3681 - val_mae: 2.3681 - val_mse: 13.4844\n",
      "Epoch 1568/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3573 - mae: 2.3573 - mse: 12.7137 - val_loss: 2.4413 - val_mae: 2.4413 - val_mse: 13.8699\n",
      "Epoch 1569/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3317 - mae: 2.3317 - mse: 12.6421 - val_loss: 2.4994 - val_mae: 2.4994 - val_mse: 14.2869\n",
      "Epoch 1570/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3321 - mae: 2.3321 - mse: 12.4227 - val_loss: 2.4150 - val_mae: 2.4150 - val_mse: 13.7222\n",
      "Epoch 1571/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2758 - mae: 2.2758 - mse: 12.2191 - val_loss: 2.4605 - val_mae: 2.4605 - val_mse: 14.0599\n",
      "Epoch 1572/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3269 - mae: 2.3269 - mse: 12.4700 - val_loss: 2.5669 - val_mae: 2.5669 - val_mse: 14.9068\n",
      "Epoch 1573/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3614 - mae: 2.3614 - mse: 12.6776 - val_loss: 2.3979 - val_mae: 2.3979 - val_mse: 14.2339\n",
      "Epoch 1574/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3559 - mae: 2.3559 - mse: 12.7076 - val_loss: 2.5374 - val_mae: 2.5374 - val_mse: 14.6423\n",
      "Epoch 1575/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2968 - mae: 2.2968 - mse: 12.2930 - val_loss: 2.3908 - val_mae: 2.3908 - val_mse: 13.5785\n",
      "Epoch 1576/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2769 - mae: 2.2769 - mse: 12.1507 - val_loss: 2.4036 - val_mae: 2.4036 - val_mse: 13.5869\n",
      "Epoch 1577/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2794 - mae: 2.2794 - mse: 12.2253 - val_loss: 2.4936 - val_mae: 2.4936 - val_mse: 14.2686\n",
      "Epoch 1578/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3653 - mae: 2.3653 - mse: 12.8887 - val_loss: 2.4345 - val_mae: 2.4345 - val_mse: 13.8173\n",
      "Epoch 1579/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3090 - mae: 2.3090 - mse: 12.4880 - val_loss: 2.3978 - val_mae: 2.3978 - val_mse: 13.8141\n",
      "Epoch 1580/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3047 - mae: 2.3047 - mse: 12.2685 - val_loss: 2.4122 - val_mae: 2.4122 - val_mse: 13.6475\n",
      "Epoch 1581/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2659 - mae: 2.2659 - mse: 12.1345 - val_loss: 2.3680 - val_mae: 2.3680 - val_mse: 13.4304\n",
      "Epoch 1582/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2850 - mae: 2.2850 - mse: 12.2091 - val_loss: 2.4025 - val_mae: 2.4025 - val_mse: 13.8250\n",
      "Epoch 1583/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2875 - mae: 2.2875 - mse: 12.1584 - val_loss: 2.4035 - val_mae: 2.4035 - val_mse: 13.7520\n",
      "Epoch 1584/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.4177 - mae: 2.4177 - mse: 13.0727 - val_loss: 2.4905 - val_mae: 2.4905 - val_mse: 14.9254\n",
      "Epoch 1585/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3763 - mae: 2.3763 - mse: 13.1653 - val_loss: 2.4087 - val_mae: 2.4087 - val_mse: 13.8744\n",
      "Epoch 1586/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2752 - mae: 2.2752 - mse: 12.1705 - val_loss: 2.3864 - val_mae: 2.3864 - val_mse: 13.4444\n",
      "Epoch 1587/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3047 - mae: 2.3047 - mse: 12.3349 - val_loss: 2.3912 - val_mae: 2.3912 - val_mse: 13.7352\n",
      "Epoch 1588/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2952 - mae: 2.2952 - mse: 12.3668 - val_loss: 2.3811 - val_mae: 2.3811 - val_mse: 13.6633\n",
      "Epoch 1589/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2694 - mae: 2.2694 - mse: 12.1118 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 13.7155\n",
      "Epoch 1590/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2970 - mae: 2.2970 - mse: 12.4096 - val_loss: 2.4340 - val_mae: 2.4340 - val_mse: 13.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.2887 - mae: 2.2887 - mse: 12.2283 - val_loss: 2.3685 - val_mae: 2.3685 - val_mse: 13.6624\n",
      "Epoch 1592/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2817 - mae: 2.2817 - mse: 12.1986 - val_loss: 2.4502 - val_mae: 2.4502 - val_mse: 13.9756\n",
      "Epoch 1593/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3140 - mae: 2.3140 - mse: 12.5846 - val_loss: 2.3732 - val_mae: 2.3732 - val_mse: 13.4862\n",
      "Epoch 1594/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2816 - mae: 2.2816 - mse: 12.1500 - val_loss: 2.4261 - val_mae: 2.4261 - val_mse: 14.0685\n",
      "Epoch 1595/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3151 - mae: 2.3151 - mse: 12.5094 - val_loss: 2.4316 - val_mae: 2.4316 - val_mse: 13.5920\n",
      "Epoch 1596/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3449 - mae: 2.3449 - mse: 12.4940 - val_loss: 2.4214 - val_mae: 2.4214 - val_mse: 13.8249\n",
      "Epoch 1597/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3561 - mae: 2.3561 - mse: 12.7743 - val_loss: 2.4602 - val_mae: 2.4602 - val_mse: 14.3075\n",
      "Epoch 1598/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3452 - mae: 2.3452 - mse: 12.6239 - val_loss: 2.5278 - val_mae: 2.5278 - val_mse: 14.7829\n",
      "Epoch 1599/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3357 - mae: 2.3357 - mse: 12.5474 - val_loss: 2.4721 - val_mae: 2.4721 - val_mse: 13.7743\n",
      "Epoch 1600/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2898 - mae: 2.2898 - mse: 12.3389 - val_loss: 2.3981 - val_mae: 2.3981 - val_mse: 13.4908\n",
      "Epoch 1601/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3379 - mae: 2.3379 - mse: 12.5252 - val_loss: 2.4168 - val_mae: 2.4168 - val_mse: 13.5672\n",
      "Epoch 1602/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3190 - mae: 2.3190 - mse: 12.3941 - val_loss: 2.3767 - val_mae: 2.3767 - val_mse: 13.5971\n",
      "Epoch 1603/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3191 - mae: 2.3191 - mse: 12.5134 - val_loss: 2.4233 - val_mae: 2.4233 - val_mse: 13.8041\n",
      "Epoch 1604/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3062 - mae: 2.3062 - mse: 12.3538 - val_loss: 2.3862 - val_mae: 2.3862 - val_mse: 13.6322\n",
      "Epoch 1605/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3599 - mae: 2.3599 - mse: 12.6804 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 14.4978\n",
      "Epoch 1606/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.4115 - mae: 2.4115 - mse: 13.2042 - val_loss: 2.4747 - val_mae: 2.4747 - val_mse: 14.1265\n",
      "Epoch 1607/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.4372 - mae: 2.4372 - mse: 13.6019 - val_loss: 2.4773 - val_mae: 2.4773 - val_mse: 14.5165\n",
      "Epoch 1608/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3571 - mae: 2.3571 - mse: 12.8333 - val_loss: 2.5036 - val_mae: 2.5036 - val_mse: 15.0352\n",
      "Epoch 1609/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3219 - mae: 2.3219 - mse: 12.4881 - val_loss: 2.5357 - val_mae: 2.5357 - val_mse: 14.2441\n",
      "Epoch 1610/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3401 - mae: 2.3401 - mse: 12.7171 - val_loss: 2.3641 - val_mae: 2.3641 - val_mse: 13.4626\n",
      "Epoch 1611/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3180 - mae: 2.3180 - mse: 12.5156 - val_loss: 2.5388 - val_mae: 2.5388 - val_mse: 15.0752\n",
      "Epoch 1612/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3559 - mae: 2.3559 - mse: 12.6556 - val_loss: 2.4054 - val_mae: 2.4054 - val_mse: 14.0747\n",
      "Epoch 1613/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2921 - mae: 2.2921 - mse: 12.3228 - val_loss: 2.4258 - val_mae: 2.4258 - val_mse: 14.5192\n",
      "Epoch 1614/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2910 - mae: 2.2910 - mse: 12.2266 - val_loss: 2.3914 - val_mae: 2.3914 - val_mse: 13.4097\n",
      "Epoch 1615/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2972 - mae: 2.2972 - mse: 12.3534 - val_loss: 2.4009 - val_mae: 2.4009 - val_mse: 13.6205\n",
      "Epoch 1616/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3200 - mae: 2.3200 - mse: 12.4656 - val_loss: 2.4142 - val_mae: 2.4142 - val_mse: 13.5210\n",
      "Epoch 1617/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2814 - mae: 2.2814 - mse: 12.1777 - val_loss: 2.3911 - val_mae: 2.3911 - val_mse: 13.4067\n",
      "Epoch 1618/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3222 - mae: 2.3222 - mse: 12.4267 - val_loss: 2.4911 - val_mae: 2.4911 - val_mse: 15.7506\n",
      "Epoch 1619/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2996 - mae: 2.2996 - mse: 12.4216 - val_loss: 2.3785 - val_mae: 2.3785 - val_mse: 13.5448\n",
      "Epoch 1620/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3117 - mae: 2.3117 - mse: 12.3369 - val_loss: 2.4391 - val_mae: 2.4391 - val_mse: 14.1102\n",
      "Epoch 1621/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3149 - mae: 2.3149 - mse: 12.3843 - val_loss: 2.3969 - val_mae: 2.3969 - val_mse: 13.8199\n",
      "Epoch 1622/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2839 - mae: 2.2839 - mse: 12.1252 - val_loss: 2.4045 - val_mae: 2.4045 - val_mse: 13.6897\n",
      "Epoch 1623/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3017 - mae: 2.3017 - mse: 12.3661 - val_loss: 2.4553 - val_mae: 2.4553 - val_mse: 14.1069\n",
      "Epoch 1624/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3354 - mae: 2.3354 - mse: 12.4718 - val_loss: 2.3767 - val_mae: 2.3767 - val_mse: 13.3688\n",
      "Epoch 1625/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2850 - mae: 2.2850 - mse: 12.1752 - val_loss: 2.3916 - val_mae: 2.3916 - val_mse: 13.7430\n",
      "Epoch 1626/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3552 - mae: 2.3552 - mse: 12.6949 - val_loss: 2.4343 - val_mae: 2.4343 - val_mse: 14.2297\n",
      "Epoch 1627/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3699 - mae: 2.3699 - mse: 12.8215 - val_loss: 2.4654 - val_mae: 2.4654 - val_mse: 14.5155\n",
      "Epoch 1628/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3425 - mae: 2.3425 - mse: 12.5428 - val_loss: 2.8072 - val_mae: 2.8072 - val_mse: 17.4286\n",
      "Epoch 1629/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3376 - mae: 2.3376 - mse: 12.6826 - val_loss: 2.3888 - val_mae: 2.3888 - val_mse: 13.5544\n",
      "Epoch 1630/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3526 - mae: 2.3526 - mse: 12.6439 - val_loss: 2.4720 - val_mae: 2.4720 - val_mse: 14.6735\n",
      "Epoch 1631/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3274 - mae: 2.3274 - mse: 12.4587 - val_loss: 2.3936 - val_mae: 2.3936 - val_mse: 13.7554\n",
      "Epoch 1632/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2631 - mae: 2.2631 - mse: 12.0840 - val_loss: 2.3885 - val_mae: 2.3885 - val_mse: 13.5428\n",
      "Epoch 1633/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3179 - mae: 2.3179 - mse: 12.4109 - val_loss: 2.4249 - val_mae: 2.4249 - val_mse: 13.6005\n",
      "Epoch 1634/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2770 - mae: 2.2770 - mse: 12.1916 - val_loss: 2.4239 - val_mae: 2.4239 - val_mse: 13.6689\n",
      "Epoch 1635/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.2485 - val_loss: 2.3763 - val_mae: 2.3763 - val_mse: 13.5628\n",
      "Epoch 1636/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2970 - mae: 2.2970 - mse: 12.2992 - val_loss: 2.4083 - val_mae: 2.4083 - val_mse: 13.6567\n",
      "Epoch 1637/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3265 - mae: 2.3265 - mse: 12.5625 - val_loss: 2.4430 - val_mae: 2.4430 - val_mse: 13.4005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1638/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2993 - mae: 2.2993 - mse: 12.2336 - val_loss: 2.3746 - val_mae: 2.3746 - val_mse: 13.5515\n",
      "Epoch 1639/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3136 - mae: 2.3136 - mse: 12.2847 - val_loss: 2.4254 - val_mae: 2.4254 - val_mse: 14.1883\n",
      "Epoch 1640/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3053 - mae: 2.3053 - mse: 12.3272 - val_loss: 2.4138 - val_mae: 2.4138 - val_mse: 13.6597\n",
      "Epoch 1641/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2851 - mae: 2.2851 - mse: 12.1629 - val_loss: 2.4009 - val_mae: 2.4009 - val_mse: 13.3899\n",
      "Epoch 1642/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2971 - mae: 2.2971 - mse: 12.2910 - val_loss: 2.3861 - val_mae: 2.3861 - val_mse: 13.5927\n",
      "Epoch 1643/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4472 - mae: 2.4472 - mse: 13.5291 - val_loss: 2.5623 - val_mae: 2.5623 - val_mse: 14.7643\n",
      "Epoch 1644/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4243 - mae: 2.4243 - mse: 13.6755 - val_loss: 2.4042 - val_mae: 2.4042 - val_mse: 14.0815\n",
      "Epoch 1645/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2907 - mae: 2.2907 - mse: 12.3663 - val_loss: 2.3876 - val_mae: 2.3876 - val_mse: 13.6323\n",
      "Epoch 1646/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3000 - mae: 2.3000 - mse: 12.3656 - val_loss: 2.3933 - val_mae: 2.3933 - val_mse: 13.8081\n",
      "Epoch 1647/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3004 - mae: 2.3004 - mse: 12.3466 - val_loss: 2.4273 - val_mae: 2.4273 - val_mse: 14.0277\n",
      "Epoch 1648/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3878 - mae: 2.3878 - mse: 12.9366 - val_loss: 2.5254 - val_mae: 2.5254 - val_mse: 14.7817\n",
      "Epoch 1649/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3680 - mae: 2.3680 - mse: 12.7804 - val_loss: 2.4361 - val_mae: 2.4361 - val_mse: 14.6371\n",
      "Epoch 1650/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3300 - mae: 2.3300 - mse: 12.5684 - val_loss: 2.3973 - val_mae: 2.3973 - val_mse: 13.8330\n",
      "Epoch 1651/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3401 - mae: 2.3401 - mse: 12.7392 - val_loss: 2.4482 - val_mae: 2.4482 - val_mse: 14.3184\n",
      "Epoch 1652/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3095 - mae: 2.3095 - mse: 12.4310 - val_loss: 2.4601 - val_mae: 2.4601 - val_mse: 14.1349\n",
      "Epoch 1653/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3088 - mae: 2.3088 - mse: 12.4130 - val_loss: 2.4217 - val_mae: 2.4217 - val_mse: 13.9254\n",
      "Epoch 1654/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2905 - mae: 2.2905 - mse: 12.2812 - val_loss: 2.3733 - val_mae: 2.3733 - val_mse: 13.5358\n",
      "Epoch 1655/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2785 - mae: 2.2785 - mse: 12.2056 - val_loss: 2.3710 - val_mae: 2.3710 - val_mse: 13.4471\n",
      "Epoch 1656/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2743 - mae: 2.2743 - mse: 12.1490 - val_loss: 2.3843 - val_mae: 2.3843 - val_mse: 13.6111\n",
      "Epoch 1657/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2875 - mae: 2.2875 - mse: 12.2398 - val_loss: 2.5096 - val_mae: 2.5096 - val_mse: 13.6972\n",
      "Epoch 1658/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3313 - mae: 2.3313 - mse: 12.5826 - val_loss: 2.4041 - val_mae: 2.4041 - val_mse: 14.1979\n",
      "Epoch 1659/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2916 - mae: 2.2916 - mse: 12.3023 - val_loss: 2.3667 - val_mae: 2.3667 - val_mse: 13.4390\n",
      "Epoch 1660/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3601 - mae: 2.3601 - mse: 12.6676 - val_loss: 2.4675 - val_mae: 2.4675 - val_mse: 14.5943\n",
      "Epoch 1661/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3279 - mae: 2.3279 - mse: 12.5684 - val_loss: 2.4369 - val_mae: 2.4369 - val_mse: 13.7244\n",
      "Epoch 1662/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3263 - mae: 2.3263 - mse: 12.5050 - val_loss: 2.5019 - val_mae: 2.5019 - val_mse: 13.7043\n",
      "Epoch 1663/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4767 - mae: 2.4767 - mse: 13.9668 - val_loss: 2.4828 - val_mae: 2.4828 - val_mse: 15.1029\n",
      "Epoch 1664/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3261 - mae: 2.3261 - mse: 12.6784 - val_loss: 2.4000 - val_mae: 2.4000 - val_mse: 13.6993\n",
      "Epoch 1665/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3369 - mae: 2.3369 - mse: 12.4396 - val_loss: 2.4811 - val_mae: 2.4811 - val_mse: 13.6964\n",
      "Epoch 1666/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3197 - mae: 2.3197 - mse: 12.5061 - val_loss: 2.3765 - val_mae: 2.3765 - val_mse: 13.6167\n",
      "Epoch 1667/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2791 - mae: 2.2791 - mse: 12.1888 - val_loss: 2.3861 - val_mae: 2.3861 - val_mse: 13.5926\n",
      "Epoch 1668/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3154 - mae: 2.3154 - mse: 12.4404 - val_loss: 2.4291 - val_mae: 2.4291 - val_mse: 13.9628\n",
      "Epoch 1669/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2823 - mae: 2.2823 - mse: 12.1785 - val_loss: 2.3961 - val_mae: 2.3961 - val_mse: 13.5240\n",
      "Epoch 1670/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3307 - mae: 2.3307 - mse: 12.5713 - val_loss: 2.4824 - val_mae: 2.4824 - val_mse: 14.9739\n",
      "Epoch 1671/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3281 - mae: 2.3281 - mse: 12.4420 - val_loss: 2.3960 - val_mae: 2.3960 - val_mse: 13.7008\n",
      "Epoch 1672/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3453 - mae: 2.3453 - mse: 12.5908 - val_loss: 2.4350 - val_mae: 2.4350 - val_mse: 13.9300\n",
      "Epoch 1673/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3309 - mae: 2.3309 - mse: 12.7669 - val_loss: 2.4430 - val_mae: 2.4430 - val_mse: 14.1333\n",
      "Epoch 1674/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4163 - mae: 2.4163 - mse: 13.2737 - val_loss: 2.5344 - val_mae: 2.5344 - val_mse: 14.6495\n",
      "Epoch 1675/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.3247 - mae: 2.3247 - mse: 12.3471 - val_loss: 2.4612 - val_mae: 2.4612 - val_mse: 13.7391\n",
      "Epoch 1676/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3026 - mae: 2.3026 - mse: 12.2453 - val_loss: 2.4006 - val_mae: 2.4006 - val_mse: 13.5545\n",
      "Epoch 1677/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2910 - mae: 2.2910 - mse: 12.2245 - val_loss: 2.4608 - val_mae: 2.4608 - val_mse: 14.5905\n",
      "Epoch 1678/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2760 - mae: 2.2760 - mse: 12.1602 - val_loss: 2.3745 - val_mae: 2.3745 - val_mse: 13.4910\n",
      "Epoch 1679/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2682 - mae: 2.2682 - mse: 12.1519 - val_loss: 2.4124 - val_mae: 2.4124 - val_mse: 13.3888\n",
      "Epoch 1680/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2871 - mae: 2.2871 - mse: 12.2464 - val_loss: 2.3796 - val_mae: 2.3796 - val_mse: 13.7704\n",
      "Epoch 1681/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2769 - mae: 2.2769 - mse: 12.1330 - val_loss: 2.3788 - val_mae: 2.3788 - val_mse: 13.4111\n",
      "Epoch 1682/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2884 - mae: 2.2884 - mse: 12.3227 - val_loss: 2.4146 - val_mae: 2.4146 - val_mse: 13.8713\n",
      "Epoch 1683/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3238 - mae: 2.3238 - mse: 12.4507 - val_loss: 2.4808 - val_mae: 2.4808 - val_mse: 14.2016\n",
      "Epoch 1684/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3474 - mae: 2.3474 - mse: 12.6739 - val_loss: 2.5819 - val_mae: 2.5819 - val_mse: 15.7237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1685/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3278 - mae: 2.3278 - mse: 12.7983 - val_loss: 2.4287 - val_mae: 2.4287 - val_mse: 13.6194\n",
      "Epoch 1686/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2969 - mae: 2.2969 - mse: 12.3017 - val_loss: 2.3869 - val_mae: 2.3869 - val_mse: 13.5344\n",
      "Epoch 1687/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2832 - mae: 2.2832 - mse: 12.2068 - val_loss: 2.3756 - val_mae: 2.3756 - val_mse: 13.5293\n",
      "Epoch 1688/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3054 - mae: 2.3054 - mse: 12.2731 - val_loss: 2.4224 - val_mae: 2.4224 - val_mse: 13.7639\n",
      "Epoch 1689/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2984 - mae: 2.2984 - mse: 12.3936 - val_loss: 2.4256 - val_mae: 2.4255 - val_mse: 13.9134\n",
      "Epoch 1690/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3151 - mae: 2.3151 - mse: 12.3365 - val_loss: 2.6118 - val_mae: 2.6118 - val_mse: 14.2056\n",
      "Epoch 1691/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.4235 - mae: 2.4235 - mse: 13.2010 - val_loss: 2.6211 - val_mae: 2.6211 - val_mse: 15.7892\n",
      "Epoch 1692/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.4040 - mae: 2.4040 - mse: 12.9961 - val_loss: 2.4238 - val_mae: 2.4238 - val_mse: 13.9445\n",
      "Epoch 1693/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3996 - mae: 2.3996 - mse: 13.1414 - val_loss: 2.4254 - val_mae: 2.4254 - val_mse: 13.9054\n",
      "Epoch 1694/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3056 - mae: 2.3056 - mse: 12.3989 - val_loss: 2.3659 - val_mae: 2.3659 - val_mse: 13.3441\n",
      "Epoch 1695/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3184 - mae: 2.3184 - mse: 12.4002 - val_loss: 2.4218 - val_mae: 2.4218 - val_mse: 14.3133\n",
      "Epoch 1696/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2848 - mae: 2.2848 - mse: 12.3316 - val_loss: 2.3788 - val_mae: 2.3788 - val_mse: 13.4384\n",
      "Epoch 1697/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2683 - mae: 2.2683 - mse: 12.1546 - val_loss: 2.4121 - val_mae: 2.4121 - val_mse: 13.4250\n",
      "Epoch 1698/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3323 - mae: 2.3323 - mse: 12.4832 - val_loss: 2.6391 - val_mae: 2.6391 - val_mse: 14.4338\n",
      "Epoch 1699/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3042 - mae: 2.3042 - mse: 12.3541 - val_loss: 2.4381 - val_mae: 2.4381 - val_mse: 14.0817\n",
      "Epoch 1700/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3197 - mae: 2.3197 - mse: 12.5549 - val_loss: 2.4117 - val_mae: 2.4117 - val_mse: 13.8032\n",
      "Epoch 1701/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2933 - mae: 2.2933 - mse: 12.2434 - val_loss: 2.3751 - val_mae: 2.3751 - val_mse: 13.3308\n",
      "Epoch 1702/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2749 - mae: 2.2749 - mse: 12.1515 - val_loss: 2.3918 - val_mae: 2.3918 - val_mse: 13.5097\n",
      "Epoch 1703/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.2952 - mae: 2.2952 - mse: 12.2686 - val_loss: 2.4163 - val_mae: 2.4163 - val_mse: 13.9281\n",
      "Epoch 1704/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3114 - mae: 2.3114 - mse: 12.3745 - val_loss: 2.3738 - val_mae: 2.3738 - val_mse: 13.3690\n",
      "Epoch 1705/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2636 - mae: 2.2636 - mse: 12.0616 - val_loss: 2.3598 - val_mae: 2.3598 - val_mse: 13.5253\n",
      "Epoch 1706/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2693 - mae: 2.2693 - mse: 12.1450 - val_loss: 2.3768 - val_mae: 2.3768 - val_mse: 13.6045\n",
      "Epoch 1707/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2793 - mae: 2.2793 - mse: 12.2484 - val_loss: 2.4093 - val_mae: 2.4093 - val_mse: 13.6378\n",
      "Epoch 1708/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2755 - mae: 2.2755 - mse: 12.1929 - val_loss: 2.3658 - val_mae: 2.3658 - val_mse: 13.5664\n",
      "Epoch 1709/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2808 - mae: 2.2808 - mse: 12.1546 - val_loss: 2.4391 - val_mae: 2.4391 - val_mse: 13.5895\n",
      "Epoch 1710/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3061 - mae: 2.3061 - mse: 12.4794 - val_loss: 2.5230 - val_mae: 2.5230 - val_mse: 14.9556\n",
      "Epoch 1711/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3003 - mae: 2.3003 - mse: 12.3457 - val_loss: 2.4202 - val_mae: 2.4202 - val_mse: 13.6656\n",
      "Epoch 1712/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3452 - mae: 2.3452 - mse: 12.6109 - val_loss: 2.4239 - val_mae: 2.4239 - val_mse: 13.4421\n",
      "Epoch 1713/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3345 - mae: 2.3345 - mse: 12.3811 - val_loss: 2.6323 - val_mae: 2.6323 - val_mse: 16.7910\n",
      "Epoch 1714/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3873 - mae: 2.3873 - mse: 13.2057 - val_loss: 2.5555 - val_mae: 2.5555 - val_mse: 15.7021\n",
      "Epoch 1715/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3643 - mae: 2.3643 - mse: 12.8807 - val_loss: 2.4228 - val_mae: 2.4228 - val_mse: 14.0292\n",
      "Epoch 1716/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2999 - mae: 2.2999 - mse: 12.3413 - val_loss: 2.4032 - val_mae: 2.4032 - val_mse: 13.3846\n",
      "Epoch 1717/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2898 - mae: 2.2898 - mse: 12.1890 - val_loss: 2.4372 - val_mae: 2.4372 - val_mse: 13.8275\n",
      "Epoch 1718/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3734 - mae: 2.3734 - mse: 13.0909 - val_loss: 2.4132 - val_mae: 2.4132 - val_mse: 14.2729\n",
      "Epoch 1719/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3537 - mae: 2.3537 - mse: 12.5996 - val_loss: 2.3910 - val_mae: 2.3910 - val_mse: 13.7665\n",
      "Epoch 1720/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3078 - mae: 2.3078 - mse: 12.2985 - val_loss: 2.3936 - val_mae: 2.3936 - val_mse: 13.4258\n",
      "Epoch 1721/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3067 - mae: 2.3067 - mse: 12.2908 - val_loss: 2.4416 - val_mae: 2.4416 - val_mse: 14.2974\n",
      "Epoch 1722/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2847 - mae: 2.2847 - mse: 12.3438 - val_loss: 2.3827 - val_mae: 2.3827 - val_mse: 13.4481\n",
      "Epoch 1723/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2860 - mae: 2.2860 - mse: 12.2413 - val_loss: 2.3610 - val_mae: 2.3610 - val_mse: 13.3693\n",
      "Epoch 1724/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3085 - mae: 2.3085 - mse: 12.3048 - val_loss: 2.4258 - val_mae: 2.4258 - val_mse: 14.0619\n",
      "Epoch 1725/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2805 - mae: 2.2805 - mse: 12.1747 - val_loss: 2.4205 - val_mae: 2.4205 - val_mse: 13.6047\n",
      "Epoch 1726/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3218 - mae: 2.3218 - mse: 12.4722 - val_loss: 2.4660 - val_mae: 2.4660 - val_mse: 13.6966\n",
      "Epoch 1727/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3010 - mae: 2.3010 - mse: 12.3123 - val_loss: 2.4208 - val_mae: 2.4208 - val_mse: 14.0216\n",
      "Epoch 1728/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.2103 - val_loss: 2.4720 - val_mae: 2.4720 - val_mse: 13.7811\n",
      "Epoch 1729/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3087 - mae: 2.3087 - mse: 12.2969 - val_loss: 2.4262 - val_mae: 2.4262 - val_mse: 13.9336\n",
      "Epoch 1730/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2838 - mae: 2.2838 - mse: 12.2041 - val_loss: 2.4003 - val_mae: 2.4003 - val_mse: 13.8032\n",
      "Epoch 1731/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3047 - mae: 2.3047 - mse: 12.2529 - val_loss: 2.4569 - val_mae: 2.4569 - val_mse: 14.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1732/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3315 - mae: 2.3315 - mse: 12.5935 - val_loss: 2.5258 - val_mae: 2.5258 - val_mse: 13.8758\n",
      "Epoch 1733/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3441 - mae: 2.3441 - mse: 12.6092 - val_loss: 2.5447 - val_mae: 2.5447 - val_mse: 14.3397\n",
      "Epoch 1734/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3252 - mae: 2.3252 - mse: 12.4425 - val_loss: 2.4448 - val_mae: 2.4448 - val_mse: 13.6206\n",
      "Epoch 1735/2500\n",
      "684/684 [==============================] - 1s 783us/sample - loss: 2.3296 - mae: 2.3296 - mse: 12.4551 - val_loss: 2.4441 - val_mae: 2.4441 - val_mse: 13.4218\n",
      "Epoch 1736/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4512 - mae: 2.4512 - mse: 13.3962 - val_loss: 2.5274 - val_mae: 2.5274 - val_mse: 15.0266\n",
      "Epoch 1737/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.6704 - mae: 2.6704 - mse: 16.7414 - val_loss: 2.6421 - val_mae: 2.6421 - val_mse: 18.0915\n",
      "Epoch 1738/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.4031 - mae: 2.4031 - mse: 13.3029 - val_loss: 2.5287 - val_mae: 2.5287 - val_mse: 14.1701\n",
      "Epoch 1739/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3121 - mae: 2.3121 - mse: 12.4950 - val_loss: 2.3739 - val_mae: 2.3739 - val_mse: 13.6293\n",
      "Epoch 1740/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3263 - mae: 2.3263 - mse: 12.5016 - val_loss: 2.4376 - val_mae: 2.4376 - val_mse: 14.0348\n",
      "Epoch 1741/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2972 - mae: 2.2972 - mse: 12.2527 - val_loss: 2.4158 - val_mae: 2.4158 - val_mse: 13.5473\n",
      "Epoch 1742/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3171 - mae: 2.3171 - mse: 12.5996 - val_loss: 2.4380 - val_mae: 2.4380 - val_mse: 13.7273\n",
      "Epoch 1743/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3059 - mae: 2.3059 - mse: 12.3116 - val_loss: 2.3961 - val_mae: 2.3961 - val_mse: 13.5501\n",
      "Epoch 1744/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2603 - mae: 2.2603 - mse: 12.0470 - val_loss: 2.4096 - val_mae: 2.4096 - val_mse: 14.1387\n",
      "Epoch 1745/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2837 - mae: 2.2837 - mse: 12.1963 - val_loss: 2.4046 - val_mae: 2.4046 - val_mse: 13.5657\n",
      "Epoch 1746/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3143 - mae: 2.3143 - mse: 12.3301 - val_loss: 2.3998 - val_mae: 2.3998 - val_mse: 13.6493\n",
      "Epoch 1747/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2929 - mae: 2.2929 - mse: 12.3149 - val_loss: 2.3895 - val_mae: 2.3895 - val_mse: 13.5451\n",
      "Epoch 1748/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2624 - mae: 2.2624 - mse: 12.0415 - val_loss: 2.3904 - val_mae: 2.3904 - val_mse: 13.5648\n",
      "Epoch 1749/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3348 - mae: 2.3348 - mse: 12.5466 - val_loss: 2.4266 - val_mae: 2.4266 - val_mse: 13.9505\n",
      "Epoch 1750/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3565 - mae: 2.3565 - mse: 12.6890 - val_loss: 2.3942 - val_mae: 2.3942 - val_mse: 13.6664\n",
      "Epoch 1751/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2782 - mae: 2.2782 - mse: 12.1725 - val_loss: 2.3737 - val_mae: 2.3737 - val_mse: 13.4753\n",
      "Epoch 1752/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2659 - mae: 2.2659 - mse: 12.0480 - val_loss: 2.3985 - val_mae: 2.3985 - val_mse: 13.5588\n",
      "Epoch 1753/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3324 - mae: 2.3324 - mse: 12.4072 - val_loss: 2.3907 - val_mae: 2.3907 - val_mse: 13.6005\n",
      "Epoch 1754/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2967 - mae: 2.2967 - mse: 12.3221 - val_loss: 2.3761 - val_mae: 2.3761 - val_mse: 13.5292\n",
      "Epoch 1755/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2628 - mae: 2.2628 - mse: 12.0517 - val_loss: 2.3792 - val_mae: 2.3792 - val_mse: 13.7255\n",
      "Epoch 1756/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2900 - mae: 2.2900 - mse: 12.2794 - val_loss: 2.3989 - val_mae: 2.3989 - val_mse: 13.6611\n",
      "Epoch 1757/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2716 - mae: 2.2716 - mse: 12.0818 - val_loss: 2.3596 - val_mae: 2.3596 - val_mse: 13.4259\n",
      "Epoch 1758/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2650 - mae: 2.2650 - mse: 12.0974 - val_loss: 2.4140 - val_mae: 2.4140 - val_mse: 13.3366\n",
      "Epoch 1759/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.3462 - mae: 2.3462 - mse: 12.6173 - val_loss: 2.4984 - val_mae: 2.4984 - val_mse: 14.2344\n",
      "Epoch 1760/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2920 - mae: 2.2920 - mse: 12.4493 - val_loss: 2.3812 - val_mae: 2.3812 - val_mse: 13.4670\n",
      "Epoch 1761/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2611 - mae: 2.2611 - mse: 12.0962 - val_loss: 2.3842 - val_mae: 2.3842 - val_mse: 13.9566\n",
      "Epoch 1762/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2689 - mae: 2.2689 - mse: 12.1138 - val_loss: 2.4087 - val_mae: 2.4087 - val_mse: 13.8226\n",
      "Epoch 1763/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2872 - mae: 2.2872 - mse: 12.2458 - val_loss: 2.4164 - val_mae: 2.4164 - val_mse: 13.4266\n",
      "Epoch 1764/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3172 - mae: 2.3172 - mse: 12.3586 - val_loss: 2.4525 - val_mae: 2.4525 - val_mse: 13.8289\n",
      "Epoch 1765/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2953 - mae: 2.2953 - mse: 12.3040 - val_loss: 2.3857 - val_mae: 2.3857 - val_mse: 13.3600\n",
      "Epoch 1766/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.2753 - mae: 2.2753 - mse: 12.1609 - val_loss: 2.4066 - val_mae: 2.4066 - val_mse: 13.7016\n",
      "Epoch 1767/2500\n",
      "684/684 [==============================] - 1s 782us/sample - loss: 2.3140 - mae: 2.3140 - mse: 12.3470 - val_loss: 2.4303 - val_mae: 2.4303 - val_mse: 14.2708\n",
      "Epoch 1768/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3328 - mae: 2.3328 - mse: 12.5087 - val_loss: 2.4019 - val_mae: 2.4019 - val_mse: 14.0226\n",
      "Epoch 1769/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3810 - mae: 2.3810 - mse: 12.8950 - val_loss: 2.4130 - val_mae: 2.4130 - val_mse: 13.8677\n",
      "Epoch 1770/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3024 - mae: 2.3024 - mse: 12.5660 - val_loss: 2.4396 - val_mae: 2.4396 - val_mse: 13.8523\n",
      "Epoch 1771/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3255 - mae: 2.3255 - mse: 12.3810 - val_loss: 2.4300 - val_mae: 2.4300 - val_mse: 13.7506\n",
      "Epoch 1772/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2761 - mae: 2.2761 - mse: 12.1668 - val_loss: 2.3819 - val_mae: 2.3819 - val_mse: 13.7639\n",
      "Epoch 1773/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2830 - mae: 2.2830 - mse: 12.2012 - val_loss: 2.4108 - val_mae: 2.4108 - val_mse: 13.7584\n",
      "Epoch 1774/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2784 - mae: 2.2784 - mse: 12.1387 - val_loss: 2.3856 - val_mae: 2.3856 - val_mse: 13.5805\n",
      "Epoch 1775/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2890 - mae: 2.2890 - mse: 12.3481 - val_loss: 2.3731 - val_mae: 2.3731 - val_mse: 13.7483\n",
      "Epoch 1776/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2914 - mae: 2.2914 - mse: 12.2671 - val_loss: 2.5056 - val_mae: 2.5056 - val_mse: 14.5784\n",
      "Epoch 1777/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3149 - mae: 2.3149 - mse: 12.4877 - val_loss: 2.4772 - val_mae: 2.4772 - val_mse: 13.7970\n",
      "Epoch 1778/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2777 - mae: 2.2777 - mse: 12.1365 - val_loss: 2.4130 - val_mae: 2.4130 - val_mse: 13.8850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1779/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3229 - mae: 2.3229 - mse: 12.4584 - val_loss: 2.5634 - val_mae: 2.5634 - val_mse: 14.9396\n",
      "Epoch 1780/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3374 - mae: 2.3374 - mse: 12.6175 - val_loss: 2.7173 - val_mae: 2.7173 - val_mse: 17.2002\n",
      "Epoch 1781/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3819 - mae: 2.3819 - mse: 13.3339 - val_loss: 2.4341 - val_mae: 2.4341 - val_mse: 14.2311\n",
      "Epoch 1782/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3597 - mae: 2.3597 - mse: 12.9245 - val_loss: 2.5293 - val_mae: 2.5293 - val_mse: 14.8369\n",
      "Epoch 1783/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3300 - mae: 2.3300 - mse: 12.5446 - val_loss: 2.6332 - val_mae: 2.6332 - val_mse: 15.0113\n",
      "Epoch 1784/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3241 - mae: 2.3241 - mse: 12.6541 - val_loss: 2.3877 - val_mae: 2.3877 - val_mse: 13.3381\n",
      "Epoch 1785/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2791 - mae: 2.2791 - mse: 12.1047 - val_loss: 2.3869 - val_mae: 2.3869 - val_mse: 13.7615\n",
      "Epoch 1786/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3234 - mae: 2.3234 - mse: 12.5588 - val_loss: 2.4880 - val_mae: 2.4880 - val_mse: 13.7843\n",
      "Epoch 1787/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3390 - mae: 2.3390 - mse: 12.4688 - val_loss: 2.4017 - val_mae: 2.4017 - val_mse: 13.7905\n",
      "Epoch 1788/2500\n",
      "684/684 [==============================] - 1s 821us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.2125 - val_loss: 2.3854 - val_mae: 2.3854 - val_mse: 13.3183\n",
      "Epoch 1789/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2627 - mae: 2.2627 - mse: 12.0464 - val_loss: 2.3871 - val_mae: 2.3871 - val_mse: 13.3985\n",
      "Epoch 1790/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3170 - mae: 2.3170 - mse: 12.4474 - val_loss: 2.4287 - val_mae: 2.4287 - val_mse: 13.5382\n",
      "Epoch 1791/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3067 - mae: 2.3067 - mse: 12.3022 - val_loss: 2.3640 - val_mae: 2.3640 - val_mse: 13.3369\n",
      "Epoch 1792/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2639 - mae: 2.2639 - mse: 12.0702 - val_loss: 2.3803 - val_mae: 2.3803 - val_mse: 13.5897\n",
      "Epoch 1793/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2861 - mae: 2.2861 - mse: 12.2897 - val_loss: 2.3898 - val_mae: 2.3898 - val_mse: 13.4459\n",
      "Epoch 1794/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2772 - mae: 2.2772 - mse: 12.1543 - val_loss: 2.3628 - val_mae: 2.3628 - val_mse: 13.4341\n",
      "Epoch 1795/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2632 - mae: 2.2632 - mse: 12.0434 - val_loss: 2.3759 - val_mae: 2.3759 - val_mse: 13.6880\n",
      "Epoch 1796/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3048 - mae: 2.3048 - mse: 12.2951 - val_loss: 2.4517 - val_mae: 2.4517 - val_mse: 14.3017\n",
      "Epoch 1797/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3125 - mae: 2.3125 - mse: 12.4448 - val_loss: 2.4379 - val_mae: 2.4379 - val_mse: 13.5083\n",
      "Epoch 1798/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2976 - mae: 2.2976 - mse: 12.2159 - val_loss: 2.3821 - val_mae: 2.3821 - val_mse: 13.5345\n",
      "Epoch 1799/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3200 - mae: 2.3200 - mse: 12.5043 - val_loss: 2.4778 - val_mae: 2.4778 - val_mse: 13.7860\n",
      "Epoch 1800/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3212 - mae: 2.3212 - mse: 12.4984 - val_loss: 2.4168 - val_mae: 2.4168 - val_mse: 13.7959\n",
      "Epoch 1801/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2933 - mae: 2.2933 - mse: 12.2177 - val_loss: 2.4624 - val_mae: 2.4624 - val_mse: 14.0197\n",
      "Epoch 1802/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2857 - mae: 2.2857 - mse: 12.2569 - val_loss: 2.3608 - val_mae: 2.3608 - val_mse: 13.4664\n",
      "Epoch 1803/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2621 - mae: 2.2621 - mse: 12.0229 - val_loss: 2.4227 - val_mae: 2.4227 - val_mse: 14.3087\n",
      "Epoch 1804/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3537 - mae: 2.3537 - mse: 12.8307 - val_loss: 2.5480 - val_mae: 2.5480 - val_mse: 14.0730\n",
      "Epoch 1805/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3702 - mae: 2.3702 - mse: 13.0227 - val_loss: 2.4551 - val_mae: 2.4551 - val_mse: 13.7230\n",
      "Epoch 1806/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3491 - mae: 2.3491 - mse: 12.6824 - val_loss: 2.3988 - val_mae: 2.3988 - val_mse: 13.9624\n",
      "Epoch 1807/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3092 - mae: 2.3092 - mse: 12.4545 - val_loss: 2.3935 - val_mae: 2.3935 - val_mse: 13.7482\n",
      "Epoch 1808/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3176 - mae: 2.3176 - mse: 12.4900 - val_loss: 2.4147 - val_mae: 2.4147 - val_mse: 13.9186\n",
      "Epoch 1809/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2587 - mae: 2.2587 - mse: 12.1234 - val_loss: 2.3940 - val_mae: 2.3940 - val_mse: 13.5884\n",
      "Epoch 1810/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2642 - mae: 2.2642 - mse: 12.0189 - val_loss: 2.3645 - val_mae: 2.3645 - val_mse: 13.4438\n",
      "Epoch 1811/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2638 - mae: 2.2638 - mse: 12.0834 - val_loss: 2.3641 - val_mae: 2.3641 - val_mse: 13.4991\n",
      "Epoch 1812/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2882 - mae: 2.2882 - mse: 12.2434 - val_loss: 2.6311 - val_mae: 2.6311 - val_mse: 15.3877\n",
      "Epoch 1813/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3997 - mae: 2.3997 - mse: 13.0926 - val_loss: 2.4750 - val_mae: 2.4750 - val_mse: 13.9307\n",
      "Epoch 1814/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3745 - mae: 2.3745 - mse: 12.8261 - val_loss: 2.3763 - val_mae: 2.3763 - val_mse: 13.6168\n",
      "Epoch 1815/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3073 - mae: 2.3073 - mse: 12.3585 - val_loss: 2.4098 - val_mae: 2.4098 - val_mse: 13.7488\n",
      "Epoch 1816/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2915 - mae: 2.2915 - mse: 12.3457 - val_loss: 2.4367 - val_mae: 2.4367 - val_mse: 14.3768\n",
      "Epoch 1817/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3113 - mae: 2.3113 - mse: 12.5563 - val_loss: 2.4018 - val_mae: 2.4018 - val_mse: 13.9017\n",
      "Epoch 1818/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3856 - mae: 2.3856 - mse: 12.9470 - val_loss: 2.4902 - val_mae: 2.4902 - val_mse: 14.2572\n",
      "Epoch 1819/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3546 - mae: 2.3546 - mse: 12.6486 - val_loss: 2.4306 - val_mae: 2.4306 - val_mse: 13.4834\n",
      "Epoch 1820/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2862 - mae: 2.2862 - mse: 12.1529 - val_loss: 2.4873 - val_mae: 2.4873 - val_mse: 15.2338\n",
      "Epoch 1821/2500\n",
      "684/684 [==============================] - 1s 783us/sample - loss: 2.4374 - mae: 2.4374 - mse: 13.1160 - val_loss: 2.5286 - val_mae: 2.5286 - val_mse: 14.8568\n",
      "Epoch 1822/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.4169 - mae: 2.4169 - mse: 13.3880 - val_loss: 2.5125 - val_mae: 2.5125 - val_mse: 13.7541\n",
      "Epoch 1823/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3381 - mae: 2.3381 - mse: 12.4728 - val_loss: 2.4518 - val_mae: 2.4518 - val_mse: 14.5898\n",
      "Epoch 1824/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3289 - mae: 2.3289 - mse: 12.5405 - val_loss: 2.3975 - val_mae: 2.3975 - val_mse: 14.0053\n",
      "Epoch 1825/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2842 - mae: 2.2842 - mse: 12.2369 - val_loss: 2.3897 - val_mae: 2.3897 - val_mse: 13.5214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2706 - mae: 2.2706 - mse: 12.0725 - val_loss: 2.4513 - val_mae: 2.4513 - val_mse: 13.3444\n",
      "Epoch 1827/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4172 - mae: 2.4172 - mse: 13.1000 - val_loss: 2.3619 - val_mae: 2.3619 - val_mse: 13.5107\n",
      "Epoch 1828/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3088 - mae: 2.3088 - mse: 12.4547 - val_loss: 2.3977 - val_mae: 2.3977 - val_mse: 13.5809\n",
      "Epoch 1829/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2928 - mae: 2.2928 - mse: 12.3023 - val_loss: 2.4763 - val_mae: 2.4763 - val_mse: 13.4772\n",
      "Epoch 1830/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2883 - mae: 2.2883 - mse: 12.2206 - val_loss: 2.4097 - val_mae: 2.4097 - val_mse: 13.5355\n",
      "Epoch 1831/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3336 - mae: 2.3336 - mse: 12.5924 - val_loss: 2.4326 - val_mae: 2.4326 - val_mse: 13.7808\n",
      "Epoch 1832/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2583 - mae: 2.2583 - mse: 12.0207 - val_loss: 2.3806 - val_mae: 2.3806 - val_mse: 13.4973\n",
      "Epoch 1833/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2536 - mae: 2.2536 - mse: 12.0505 - val_loss: 2.3872 - val_mae: 2.3872 - val_mse: 13.3457\n",
      "Epoch 1834/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2794 - mae: 2.2794 - mse: 12.1593 - val_loss: 2.3871 - val_mae: 2.3871 - val_mse: 13.5190\n",
      "Epoch 1835/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2727 - mae: 2.2727 - mse: 12.1765 - val_loss: 2.3568 - val_mae: 2.3568 - val_mse: 13.4805\n",
      "Epoch 1836/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2728 - mae: 2.2728 - mse: 12.1913 - val_loss: 2.3957 - val_mae: 2.3957 - val_mse: 13.4656\n",
      "Epoch 1837/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2787 - mae: 2.2787 - mse: 12.1592 - val_loss: 2.4037 - val_mae: 2.4037 - val_mse: 13.7927\n",
      "Epoch 1838/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.2927 - val_loss: 2.4017 - val_mae: 2.4017 - val_mse: 13.9167\n",
      "Epoch 1839/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3094 - mae: 2.3094 - mse: 12.5640 - val_loss: 2.4800 - val_mae: 2.4800 - val_mse: 14.3286\n",
      "Epoch 1840/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2915 - mae: 2.2915 - mse: 12.3759 - val_loss: 2.4035 - val_mae: 2.4035 - val_mse: 13.5151\n",
      "Epoch 1841/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2891 - mae: 2.2891 - mse: 12.1731 - val_loss: 2.4880 - val_mae: 2.4880 - val_mse: 13.8049\n",
      "Epoch 1842/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3184 - mae: 2.3184 - mse: 12.3963 - val_loss: 2.3756 - val_mae: 2.3756 - val_mse: 13.3250\n",
      "Epoch 1843/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2963 - mae: 2.2963 - mse: 12.3174 - val_loss: 2.4829 - val_mae: 2.4829 - val_mse: 13.8523\n",
      "Epoch 1844/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3479 - mae: 2.3479 - mse: 12.6937 - val_loss: 2.3881 - val_mae: 2.3881 - val_mse: 13.5941\n",
      "Epoch 1845/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3594 - mae: 2.3594 - mse: 12.9784 - val_loss: 2.5136 - val_mae: 2.5136 - val_mse: 14.4202\n",
      "Epoch 1846/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3338 - mae: 2.3338 - mse: 12.4704 - val_loss: 2.4794 - val_mae: 2.4794 - val_mse: 14.5247\n",
      "Epoch 1847/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2930 - mae: 2.2930 - mse: 12.2417 - val_loss: 2.3818 - val_mae: 2.3818 - val_mse: 13.4001\n",
      "Epoch 1848/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2805 - mae: 2.2805 - mse: 12.3176 - val_loss: 2.3956 - val_mae: 2.3956 - val_mse: 13.5322\n",
      "Epoch 1849/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3417 - mae: 2.3417 - mse: 12.5462 - val_loss: 2.3915 - val_mae: 2.3915 - val_mse: 13.4941\n",
      "Epoch 1850/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3023 - mae: 2.3023 - mse: 12.3998 - val_loss: 2.4669 - val_mae: 2.4669 - val_mse: 14.9939\n",
      "Epoch 1851/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3026 - mae: 2.3026 - mse: 12.4413 - val_loss: 2.4160 - val_mae: 2.4160 - val_mse: 14.1368\n",
      "Epoch 1852/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2811 - mae: 2.2811 - mse: 12.2188 - val_loss: 2.3821 - val_mae: 2.3821 - val_mse: 13.5940\n",
      "Epoch 1853/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2698 - mae: 2.2698 - mse: 12.2034 - val_loss: 2.3760 - val_mae: 2.3760 - val_mse: 13.5212\n",
      "Epoch 1854/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3195 - mae: 2.3195 - mse: 12.4623 - val_loss: 2.4455 - val_mae: 2.4455 - val_mse: 13.7800\n",
      "Epoch 1855/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2949 - mae: 2.2949 - mse: 12.2600 - val_loss: 2.4469 - val_mae: 2.4469 - val_mse: 13.5550\n",
      "Epoch 1856/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3065 - mae: 2.3065 - mse: 12.3449 - val_loss: 2.4874 - val_mae: 2.4874 - val_mse: 15.3288\n",
      "Epoch 1857/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.3454 - mae: 2.3454 - mse: 12.7429 - val_loss: 2.4317 - val_mae: 2.4317 - val_mse: 14.2417\n",
      "Epoch 1858/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3240 - mae: 2.3240 - mse: 12.5124 - val_loss: 2.3713 - val_mae: 2.3713 - val_mse: 13.5412\n",
      "Epoch 1859/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2829 - mae: 2.2829 - mse: 12.1379 - val_loss: 2.3980 - val_mae: 2.3980 - val_mse: 13.7824\n",
      "Epoch 1860/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2733 - mae: 2.2733 - mse: 12.2109 - val_loss: 2.3943 - val_mae: 2.3943 - val_mse: 13.7826\n",
      "Epoch 1861/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3021 - mae: 2.3021 - mse: 12.3374 - val_loss: 2.5702 - val_mae: 2.5702 - val_mse: 13.8938\n",
      "Epoch 1862/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3436 - mae: 2.3436 - mse: 12.6794 - val_loss: 2.4525 - val_mae: 2.4525 - val_mse: 13.7406\n",
      "Epoch 1863/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3002 - mae: 2.3002 - mse: 12.3923 - val_loss: 2.3755 - val_mae: 2.3755 - val_mse: 13.6806\n",
      "Epoch 1864/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3069 - mae: 2.3069 - mse: 12.2952 - val_loss: 2.5285 - val_mae: 2.5285 - val_mse: 13.7189\n",
      "Epoch 1865/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2948 - mae: 2.2948 - mse: 12.3404 - val_loss: 2.4150 - val_mae: 2.4150 - val_mse: 14.4781\n",
      "Epoch 1866/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2651 - mae: 2.2651 - mse: 12.1690 - val_loss: 2.4183 - val_mae: 2.4183 - val_mse: 14.0502\n",
      "Epoch 1867/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2713 - mae: 2.2713 - mse: 12.2625 - val_loss: 2.3738 - val_mae: 2.3738 - val_mse: 13.5684\n",
      "Epoch 1868/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2668 - mae: 2.2668 - mse: 12.2204 - val_loss: 2.3887 - val_mae: 2.3887 - val_mse: 13.7842\n",
      "Epoch 1869/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3021 - mae: 2.3021 - mse: 12.3533 - val_loss: 2.4587 - val_mae: 2.4587 - val_mse: 14.3072\n",
      "Epoch 1870/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2918 - mae: 2.2918 - mse: 12.2792 - val_loss: 2.4130 - val_mae: 2.4130 - val_mse: 13.7577\n",
      "Epoch 1871/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2969 - mae: 2.2969 - mse: 12.1776 - val_loss: 2.4173 - val_mae: 2.4173 - val_mse: 13.7316\n",
      "Epoch 1872/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2982 - mae: 2.2982 - mse: 12.2788 - val_loss: 2.4207 - val_mae: 2.4207 - val_mse: 13.7539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1873/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2739 - mae: 2.2739 - mse: 12.1139 - val_loss: 2.4150 - val_mae: 2.4150 - val_mse: 14.5223\n",
      "Epoch 1874/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2963 - mae: 2.2963 - mse: 12.3430 - val_loss: 2.4233 - val_mae: 2.4233 - val_mse: 13.7773\n",
      "Epoch 1875/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3158 - mae: 2.3158 - mse: 12.4592 - val_loss: 2.3904 - val_mae: 2.3904 - val_mse: 13.5850\n",
      "Epoch 1876/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2855 - mae: 2.2855 - mse: 12.2383 - val_loss: 2.4722 - val_mae: 2.4722 - val_mse: 14.0913\n",
      "Epoch 1877/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3172 - mae: 2.3172 - mse: 12.3313 - val_loss: 2.4493 - val_mae: 2.4493 - val_mse: 13.6117\n",
      "Epoch 1878/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3108 - mae: 2.3108 - mse: 12.3974 - val_loss: 2.4401 - val_mae: 2.4401 - val_mse: 14.0583\n",
      "Epoch 1879/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3485 - mae: 2.3485 - mse: 12.6958 - val_loss: 2.4580 - val_mae: 2.4580 - val_mse: 14.1058\n",
      "Epoch 1880/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3199 - mae: 2.3199 - mse: 12.3522 - val_loss: 2.5215 - val_mae: 2.5215 - val_mse: 13.8182\n",
      "Epoch 1881/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2934 - mae: 2.2934 - mse: 12.3199 - val_loss: 2.4609 - val_mae: 2.4609 - val_mse: 13.5197\n",
      "Epoch 1882/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2720 - mae: 2.2720 - mse: 12.1562 - val_loss: 2.4325 - val_mae: 2.4325 - val_mse: 14.1204\n",
      "Epoch 1883/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2747 - mae: 2.2747 - mse: 12.0959 - val_loss: 2.4982 - val_mae: 2.4982 - val_mse: 14.0757\n",
      "Epoch 1884/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.3916 - val_loss: 2.3511 - val_mae: 2.3511 - val_mse: 13.3179\n",
      "Epoch 1885/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3025 - mae: 2.3025 - mse: 12.2893 - val_loss: 2.4078 - val_mae: 2.4078 - val_mse: 13.7364\n",
      "Epoch 1886/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2927 - mae: 2.2927 - mse: 12.2212 - val_loss: 2.4167 - val_mae: 2.4167 - val_mse: 13.5800\n",
      "Epoch 1887/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2965 - mae: 2.2965 - mse: 12.2435 - val_loss: 2.3903 - val_mae: 2.3903 - val_mse: 13.9622\n",
      "Epoch 1888/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2721 - mae: 2.2721 - mse: 12.1198 - val_loss: 2.4050 - val_mae: 2.4050 - val_mse: 13.5472\n",
      "Epoch 1889/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3155 - mae: 2.3155 - mse: 12.4702 - val_loss: 2.3605 - val_mae: 2.3605 - val_mse: 13.3943\n",
      "Epoch 1890/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2949 - mae: 2.2949 - mse: 12.2460 - val_loss: 2.3718 - val_mae: 2.3718 - val_mse: 13.7715\n",
      "Epoch 1891/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3134 - mae: 2.3134 - mse: 12.6111 - val_loss: 2.4878 - val_mae: 2.4878 - val_mse: 14.3794\n",
      "Epoch 1892/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2877 - mae: 2.2877 - mse: 12.2234 - val_loss: 2.4062 - val_mae: 2.4062 - val_mse: 13.6264\n",
      "Epoch 1893/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2995 - mae: 2.2995 - mse: 12.3325 - val_loss: 2.3708 - val_mae: 2.3708 - val_mse: 13.5623\n",
      "Epoch 1894/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3166 - mae: 2.3166 - mse: 12.3700 - val_loss: 2.3989 - val_mae: 2.3989 - val_mse: 13.7679\n",
      "Epoch 1895/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3060 - mae: 2.3060 - mse: 12.3948 - val_loss: 2.4771 - val_mae: 2.4771 - val_mse: 13.9791\n",
      "Epoch 1896/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3558 - mae: 2.3558 - mse: 12.6687 - val_loss: 2.4478 - val_mae: 2.4478 - val_mse: 14.1024\n",
      "Epoch 1897/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3873 - mae: 2.3873 - mse: 13.0453 - val_loss: 2.4217 - val_mae: 2.4217 - val_mse: 13.6997\n",
      "Epoch 1898/2500\n",
      "684/684 [==============================] - 1s 782us/sample - loss: 2.3475 - mae: 2.3475 - mse: 12.5535 - val_loss: 2.4062 - val_mae: 2.4062 - val_mse: 13.8756\n",
      "Epoch 1899/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3304 - mae: 2.3304 - mse: 12.5257 - val_loss: 2.4670 - val_mae: 2.4670 - val_mse: 14.1420\n",
      "Epoch 1900/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3138 - mae: 2.3138 - mse: 12.4415 - val_loss: 2.4428 - val_mae: 2.4428 - val_mse: 13.7724\n",
      "Epoch 1901/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2946 - mae: 2.2946 - mse: 12.2392 - val_loss: 2.4822 - val_mae: 2.4822 - val_mse: 14.0814\n",
      "Epoch 1902/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2945 - mae: 2.2945 - mse: 12.2231 - val_loss: 2.4135 - val_mae: 2.4135 - val_mse: 14.0046\n",
      "Epoch 1903/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2682 - mae: 2.2682 - mse: 12.1745 - val_loss: 2.4188 - val_mae: 2.4188 - val_mse: 13.7577\n",
      "Epoch 1904/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2747 - mae: 2.2747 - mse: 12.1605 - val_loss: 2.3826 - val_mae: 2.3826 - val_mse: 13.3624\n",
      "Epoch 1905/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3332 - mae: 2.3332 - mse: 12.5172 - val_loss: 2.3978 - val_mae: 2.3978 - val_mse: 13.6367\n",
      "Epoch 1906/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2800 - mae: 2.2800 - mse: 12.1246 - val_loss: 2.3883 - val_mae: 2.3883 - val_mse: 13.6741\n",
      "Epoch 1907/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2893 - mae: 2.2893 - mse: 12.1870 - val_loss: 2.4211 - val_mae: 2.4211 - val_mse: 14.0949\n",
      "Epoch 1908/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2988 - mae: 2.2988 - mse: 12.3366 - val_loss: 2.3793 - val_mae: 2.3793 - val_mse: 13.5030\n",
      "Epoch 1909/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2891 - mae: 2.2891 - mse: 12.1809 - val_loss: 2.4126 - val_mae: 2.4126 - val_mse: 13.6097\n",
      "Epoch 1910/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2984 - mae: 2.2984 - mse: 12.3636 - val_loss: 2.4638 - val_mae: 2.4638 - val_mse: 13.6033\n",
      "Epoch 1911/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3377 - mae: 2.3377 - mse: 12.6240 - val_loss: 2.4150 - val_mae: 2.4150 - val_mse: 13.6305\n",
      "Epoch 1912/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3132 - mae: 2.3132 - mse: 12.2975 - val_loss: 2.4406 - val_mae: 2.4406 - val_mse: 14.0035\n",
      "Epoch 1913/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3205 - mae: 2.3205 - mse: 12.4049 - val_loss: 2.4766 - val_mae: 2.4766 - val_mse: 15.1143\n",
      "Epoch 1914/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3566 - mae: 2.3566 - mse: 12.9956 - val_loss: 2.5508 - val_mae: 2.5508 - val_mse: 15.7188\n",
      "Epoch 1915/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3603 - mae: 2.3603 - mse: 13.0966 - val_loss: 2.5885 - val_mae: 2.5885 - val_mse: 14.1937\n",
      "Epoch 1916/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3094 - mae: 2.3094 - mse: 12.4535 - val_loss: 2.3928 - val_mae: 2.3928 - val_mse: 13.7705\n",
      "Epoch 1917/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2792 - mae: 2.2792 - mse: 12.1779 - val_loss: 2.3929 - val_mae: 2.3929 - val_mse: 13.4544\n",
      "Epoch 1918/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2933 - mae: 2.2933 - mse: 12.3113 - val_loss: 2.4058 - val_mae: 2.4058 - val_mse: 13.4798\n",
      "Epoch 1919/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3575 - mae: 2.3575 - mse: 12.7143 - val_loss: 2.4184 - val_mae: 2.4184 - val_mse: 13.8503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1920/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3227 - mae: 2.3227 - mse: 12.4791 - val_loss: 2.4384 - val_mae: 2.4384 - val_mse: 13.7320\n",
      "Epoch 1921/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3276 - mae: 2.3276 - mse: 12.6353 - val_loss: 2.3918 - val_mae: 2.3918 - val_mse: 13.5499\n",
      "Epoch 1922/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2775 - mae: 2.2775 - mse: 12.2502 - val_loss: 2.3761 - val_mae: 2.3761 - val_mse: 13.5381\n",
      "Epoch 1923/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2736 - mae: 2.2736 - mse: 12.0796 - val_loss: 2.3576 - val_mae: 2.3576 - val_mse: 13.3831\n",
      "Epoch 1924/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.2952 - mae: 2.2952 - mse: 12.2768 - val_loss: 2.5416 - val_mae: 2.5416 - val_mse: 15.4100\n",
      "Epoch 1925/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3279 - mae: 2.3279 - mse: 12.5175 - val_loss: 2.4371 - val_mae: 2.4371 - val_mse: 13.8229\n",
      "Epoch 1926/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2973 - mae: 2.2973 - mse: 12.3743 - val_loss: 2.3856 - val_mae: 2.3856 - val_mse: 13.5216\n",
      "Epoch 1927/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2725 - mae: 2.2725 - mse: 12.1124 - val_loss: 2.4024 - val_mae: 2.4024 - val_mse: 13.9339\n",
      "Epoch 1928/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3012 - mae: 2.3012 - mse: 12.3162 - val_loss: 2.4295 - val_mae: 2.4295 - val_mse: 14.4731\n",
      "Epoch 1929/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2839 - mae: 2.2839 - mse: 12.2038 - val_loss: 2.4320 - val_mae: 2.4320 - val_mse: 13.9880\n",
      "Epoch 1930/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3325 - mae: 2.3325 - mse: 12.5028 - val_loss: 2.6030 - val_mae: 2.6030 - val_mse: 14.9271\n",
      "Epoch 1931/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3275 - mae: 2.3275 - mse: 12.5017 - val_loss: 2.4454 - val_mae: 2.4454 - val_mse: 13.4606\n",
      "Epoch 1932/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3662 - mae: 2.3662 - mse: 12.8782 - val_loss: 2.4922 - val_mae: 2.4922 - val_mse: 14.6905\n",
      "Epoch 1933/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3134 - mae: 2.3134 - mse: 12.5054 - val_loss: 2.4099 - val_mae: 2.4099 - val_mse: 13.6880\n",
      "Epoch 1934/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2940 - mae: 2.2940 - mse: 12.3259 - val_loss: 2.3780 - val_mae: 2.3780 - val_mse: 13.5956\n",
      "Epoch 1935/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2795 - mae: 2.2795 - mse: 12.1184 - val_loss: 2.4616 - val_mae: 2.4616 - val_mse: 14.2716\n",
      "Epoch 1936/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2924 - mae: 2.2924 - mse: 12.2161 - val_loss: 2.3624 - val_mae: 2.3624 - val_mse: 13.3799\n",
      "Epoch 1937/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2929 - mae: 2.2929 - mse: 12.2564 - val_loss: 2.4969 - val_mae: 2.4969 - val_mse: 14.0083\n",
      "Epoch 1938/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2751 - mae: 2.2751 - mse: 12.1654 - val_loss: 2.4071 - val_mae: 2.4071 - val_mse: 14.0608\n",
      "Epoch 1939/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2749 - mae: 2.2749 - mse: 12.1361 - val_loss: 2.4335 - val_mae: 2.4335 - val_mse: 13.9551\n",
      "Epoch 1940/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2619 - mae: 2.2619 - mse: 12.0860 - val_loss: 2.4095 - val_mae: 2.4095 - val_mse: 13.5728\n",
      "Epoch 1941/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3151 - mae: 2.3151 - mse: 12.4908 - val_loss: 2.4025 - val_mae: 2.4025 - val_mse: 13.4332\n",
      "Epoch 1942/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3146 - mae: 2.3146 - mse: 12.3431 - val_loss: 2.3669 - val_mae: 2.3669 - val_mse: 13.4427\n",
      "Epoch 1943/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2669 - mae: 2.2669 - mse: 12.1394 - val_loss: 2.3634 - val_mae: 2.3634 - val_mse: 13.5077\n",
      "Epoch 1944/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3124 - mae: 2.3124 - mse: 12.3255 - val_loss: 2.4040 - val_mae: 2.4040 - val_mse: 13.8304\n",
      "Epoch 1945/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3169 - mae: 2.3169 - mse: 12.5206 - val_loss: 2.4226 - val_mae: 2.4226 - val_mse: 13.4730\n",
      "Epoch 1946/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2812 - mae: 2.2812 - mse: 12.2120 - val_loss: 2.3564 - val_mae: 2.3564 - val_mse: 13.4966\n",
      "Epoch 1947/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2804 - mae: 2.2804 - mse: 12.1365 - val_loss: 2.4447 - val_mae: 2.4447 - val_mse: 14.4600\n",
      "Epoch 1948/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3740 - mae: 2.3740 - mse: 13.0035 - val_loss: 2.5379 - val_mae: 2.5379 - val_mse: 14.2926\n",
      "Epoch 1949/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3554 - mae: 2.3554 - mse: 12.9413 - val_loss: 2.4189 - val_mae: 2.4189 - val_mse: 14.0329\n",
      "Epoch 1950/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.4158 - mae: 2.4158 - mse: 13.2485 - val_loss: 2.4999 - val_mae: 2.4999 - val_mse: 14.4500\n",
      "Epoch 1951/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3303 - mae: 2.3303 - mse: 12.7325 - val_loss: 2.4264 - val_mae: 2.4264 - val_mse: 13.7236\n",
      "Epoch 1952/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2768 - mae: 2.2768 - mse: 12.1932 - val_loss: 2.4064 - val_mae: 2.4064 - val_mse: 13.5143\n",
      "Epoch 1953/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2830 - mae: 2.2830 - mse: 12.1593 - val_loss: 2.3518 - val_mae: 2.3518 - val_mse: 13.4173\n",
      "Epoch 1954/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2877 - mae: 2.2877 - mse: 12.1628 - val_loss: 2.4557 - val_mae: 2.4557 - val_mse: 14.7594\n",
      "Epoch 1955/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3192 - mae: 2.3192 - mse: 12.4100 - val_loss: 2.4932 - val_mae: 2.4932 - val_mse: 14.4771\n",
      "Epoch 1956/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3563 - mae: 2.3563 - mse: 12.8748 - val_loss: 2.3902 - val_mae: 2.3902 - val_mse: 13.6872\n",
      "Epoch 1957/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2861 - mae: 2.2861 - mse: 12.2421 - val_loss: 2.4009 - val_mae: 2.4009 - val_mse: 14.1961\n",
      "Epoch 1958/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2806 - mae: 2.2806 - mse: 12.2024 - val_loss: 2.3891 - val_mae: 2.3891 - val_mse: 13.8494\n",
      "Epoch 1959/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2810 - mae: 2.2810 - mse: 12.1788 - val_loss: 2.3790 - val_mae: 2.3790 - val_mse: 13.5826\n",
      "Epoch 1960/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2693 - mae: 2.2693 - mse: 12.0954 - val_loss: 2.3796 - val_mae: 2.3796 - val_mse: 13.5533\n",
      "Epoch 1961/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2511 - mae: 2.2511 - mse: 11.9553 - val_loss: 2.3606 - val_mae: 2.3606 - val_mse: 13.3749\n",
      "Epoch 1962/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2724 - mae: 2.2724 - mse: 12.2010 - val_loss: 2.3654 - val_mae: 2.3654 - val_mse: 13.2395\n",
      "Epoch 1963/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2743 - mae: 2.2743 - mse: 12.1180 - val_loss: 2.3705 - val_mae: 2.3705 - val_mse: 13.3015\n",
      "Epoch 1964/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2724 - mae: 2.2724 - mse: 12.0624 - val_loss: 2.4164 - val_mae: 2.4164 - val_mse: 13.6193\n",
      "Epoch 1965/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.2877 - mae: 2.2877 - mse: 12.3414 - val_loss: 2.4371 - val_mae: 2.4371 - val_mse: 14.0923\n",
      "Epoch 1966/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3004 - mae: 2.3004 - mse: 12.2735 - val_loss: 2.4288 - val_mae: 2.4288 - val_mse: 13.8866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1967/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3041 - mae: 2.3041 - mse: 12.2419 - val_loss: 2.3876 - val_mae: 2.3876 - val_mse: 13.7302\n",
      "Epoch 1968/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2817 - mae: 2.2817 - mse: 12.3116 - val_loss: 2.3781 - val_mae: 2.3781 - val_mse: 13.4844\n",
      "Epoch 1969/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3471 - mae: 2.3471 - mse: 12.7253 - val_loss: 2.4414 - val_mae: 2.4414 - val_mse: 13.8292\n",
      "Epoch 1970/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2810 - mae: 2.2810 - mse: 12.2406 - val_loss: 2.3929 - val_mae: 2.3929 - val_mse: 13.5251\n",
      "Epoch 1971/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3384 - mae: 2.3384 - mse: 12.5184 - val_loss: 2.4040 - val_mae: 2.4040 - val_mse: 14.0726\n",
      "Epoch 1972/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2976 - mae: 2.2976 - mse: 12.2391 - val_loss: 2.4803 - val_mae: 2.4803 - val_mse: 14.7638\n",
      "Epoch 1973/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2957 - mae: 2.2957 - mse: 12.2773 - val_loss: 2.3886 - val_mae: 2.3886 - val_mse: 13.5423\n",
      "Epoch 1974/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3157 - mae: 2.3157 - mse: 12.5191 - val_loss: 2.5353 - val_mae: 2.5353 - val_mse: 13.8295\n",
      "Epoch 1975/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3117 - mae: 2.3117 - mse: 12.2488 - val_loss: 2.3786 - val_mae: 2.3786 - val_mse: 13.3928\n",
      "Epoch 1976/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2883 - mae: 2.2883 - mse: 12.1669 - val_loss: 2.3699 - val_mae: 2.3699 - val_mse: 13.4893\n",
      "Epoch 1977/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2699 - mae: 2.2699 - mse: 12.0750 - val_loss: 2.3837 - val_mae: 2.3837 - val_mse: 13.7232\n",
      "Epoch 1978/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2578 - mae: 2.2578 - mse: 12.0609 - val_loss: 2.3804 - val_mae: 2.3804 - val_mse: 13.2931\n",
      "Epoch 1979/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2786 - mae: 2.2786 - mse: 11.9977 - val_loss: 2.4057 - val_mae: 2.4057 - val_mse: 13.9862\n",
      "Epoch 1980/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2863 - mae: 2.2863 - mse: 12.3193 - val_loss: 2.3866 - val_mae: 2.3866 - val_mse: 13.6383\n",
      "Epoch 1981/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2637 - mae: 2.2637 - mse: 12.0855 - val_loss: 2.3555 - val_mae: 2.3555 - val_mse: 13.3027\n",
      "Epoch 1982/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2623 - mae: 2.2623 - mse: 12.0788 - val_loss: 2.4801 - val_mae: 2.4801 - val_mse: 14.0003\n",
      "Epoch 1983/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3010 - mae: 2.3010 - mse: 12.3150 - val_loss: 2.3452 - val_mae: 2.3452 - val_mse: 13.2573\n",
      "Epoch 1984/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2797 - mae: 2.2797 - mse: 12.0972 - val_loss: 2.3980 - val_mae: 2.3980 - val_mse: 13.9102\n",
      "Epoch 1985/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2899 - mae: 2.2899 - mse: 12.2861 - val_loss: 2.3789 - val_mae: 2.3789 - val_mse: 13.6399\n",
      "Epoch 1986/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2586 - mae: 2.2586 - mse: 12.1533 - val_loss: 2.3708 - val_mae: 2.3708 - val_mse: 13.6572\n",
      "Epoch 1987/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3105 - mae: 2.3105 - mse: 12.4108 - val_loss: 2.5290 - val_mae: 2.5290 - val_mse: 15.1648\n",
      "Epoch 1988/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3145 - mae: 2.3145 - mse: 12.5062 - val_loss: 2.4977 - val_mae: 2.4977 - val_mse: 13.6451\n",
      "Epoch 1989/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3573 - mae: 2.3573 - mse: 12.7412 - val_loss: 2.4519 - val_mae: 2.4519 - val_mse: 13.8683\n",
      "Epoch 1990/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3384 - mae: 2.3384 - mse: 12.6088 - val_loss: 2.4158 - val_mae: 2.4158 - val_mse: 14.3425\n",
      "Epoch 1991/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2607 - mae: 2.2607 - mse: 12.1533 - val_loss: 2.3565 - val_mae: 2.3565 - val_mse: 13.3654\n",
      "Epoch 1992/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2532 - mae: 2.2532 - mse: 12.0604 - val_loss: 2.3560 - val_mae: 2.3560 - val_mse: 13.5206\n",
      "Epoch 1993/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2782 - mae: 2.2782 - mse: 12.1633 - val_loss: 2.3804 - val_mae: 2.3804 - val_mse: 13.5276\n",
      "Epoch 1994/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2968 - mae: 2.2968 - mse: 12.2639 - val_loss: 2.3622 - val_mae: 2.3622 - val_mse: 13.3903\n",
      "Epoch 1995/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2977 - mae: 2.2977 - mse: 12.2817 - val_loss: 2.5947 - val_mae: 2.5947 - val_mse: 15.6884\n",
      "Epoch 1996/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3130 - mae: 2.3130 - mse: 12.6017 - val_loss: 2.3709 - val_mae: 2.3709 - val_mse: 13.5397\n",
      "Epoch 1997/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3021 - mae: 2.3021 - mse: 12.3804 - val_loss: 2.4110 - val_mae: 2.4110 - val_mse: 13.7296\n",
      "Epoch 1998/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3053 - mae: 2.3053 - mse: 12.3737 - val_loss: 2.4209 - val_mae: 2.4209 - val_mse: 13.3885\n",
      "Epoch 1999/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3089 - mae: 2.3089 - mse: 12.4711 - val_loss: 2.3968 - val_mae: 2.3968 - val_mse: 13.5658\n",
      "Epoch 2000/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3103 - mae: 2.3103 - mse: 12.3562 - val_loss: 2.3928 - val_mae: 2.3928 - val_mse: 13.4557\n",
      "Epoch 2001/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2803 - mae: 2.2803 - mse: 12.2291 - val_loss: 2.4335 - val_mae: 2.4335 - val_mse: 13.5735\n",
      "Epoch 2002/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2963 - mae: 2.2963 - mse: 12.3526 - val_loss: 2.4598 - val_mae: 2.4598 - val_mse: 15.5183\n",
      "Epoch 2003/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3304 - mae: 2.3304 - mse: 12.4970 - val_loss: 2.3832 - val_mae: 2.3832 - val_mse: 13.5806\n",
      "Epoch 2004/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2831 - mae: 2.2831 - mse: 12.1705 - val_loss: 2.3996 - val_mae: 2.3996 - val_mse: 13.8447\n",
      "Epoch 2005/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3481 - mae: 2.3481 - mse: 12.8666 - val_loss: 2.4888 - val_mae: 2.4888 - val_mse: 15.3073\n",
      "Epoch 2006/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3164 - mae: 2.3164 - mse: 12.4340 - val_loss: 2.4040 - val_mae: 2.4040 - val_mse: 13.9247\n",
      "Epoch 2007/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2859 - mae: 2.2859 - mse: 12.2380 - val_loss: 2.3631 - val_mae: 2.3631 - val_mse: 13.3509\n",
      "Epoch 2008/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2970 - mae: 2.2970 - mse: 12.2817 - val_loss: 2.3745 - val_mae: 2.3745 - val_mse: 13.4070\n",
      "Epoch 2009/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3082 - mae: 2.3082 - mse: 12.2859 - val_loss: 2.3851 - val_mae: 2.3851 - val_mse: 13.5060\n",
      "Epoch 2010/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3226 - mae: 2.3226 - mse: 12.4926 - val_loss: 2.4031 - val_mae: 2.4031 - val_mse: 13.4075\n",
      "Epoch 2011/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2876 - mae: 2.2876 - mse: 12.1931 - val_loss: 2.4392 - val_mae: 2.4392 - val_mse: 13.7842\n",
      "Epoch 2012/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3417 - mae: 2.3417 - mse: 12.6153 - val_loss: 2.4649 - val_mae: 2.4649 - val_mse: 14.2403\n",
      "Epoch 2013/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3237 - mae: 2.3237 - mse: 12.6763 - val_loss: 2.5280 - val_mae: 2.5280 - val_mse: 14.5452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2014/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3544 - mae: 2.3544 - mse: 12.6845 - val_loss: 2.4781 - val_mae: 2.4781 - val_mse: 13.5949\n",
      "Epoch 2015/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2946 - mae: 2.2946 - mse: 12.3270 - val_loss: 2.3847 - val_mae: 2.3847 - val_mse: 13.4296\n",
      "Epoch 2016/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2958 - mae: 2.2958 - mse: 12.2654 - val_loss: 2.3731 - val_mae: 2.3731 - val_mse: 13.7711\n",
      "Epoch 2017/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3034 - mae: 2.3034 - mse: 12.3966 - val_loss: 2.3965 - val_mae: 2.3965 - val_mse: 13.4372\n",
      "Epoch 2018/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2838 - mae: 2.2838 - mse: 12.2614 - val_loss: 2.3880 - val_mae: 2.3880 - val_mse: 13.6691\n",
      "Epoch 2019/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2895 - mae: 2.2895 - mse: 12.2654 - val_loss: 2.3675 - val_mae: 2.3675 - val_mse: 13.5032\n",
      "Epoch 2020/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2628 - mae: 2.2628 - mse: 12.1463 - val_loss: 2.3763 - val_mae: 2.3763 - val_mse: 13.4470\n",
      "Epoch 2021/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2763 - mae: 2.2763 - mse: 12.1776 - val_loss: 2.3843 - val_mae: 2.3843 - val_mse: 13.7936\n",
      "Epoch 2022/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3062 - mae: 2.3062 - mse: 12.3919 - val_loss: 2.4697 - val_mae: 2.4697 - val_mse: 13.6651\n",
      "Epoch 2023/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3363 - mae: 2.3363 - mse: 12.7437 - val_loss: 2.3768 - val_mae: 2.3768 - val_mse: 13.6255\n",
      "Epoch 2024/2500\n",
      "684/684 [==============================] - 1s 803us/sample - loss: 2.2744 - mae: 2.2744 - mse: 12.1462 - val_loss: 2.3702 - val_mae: 2.3702 - val_mse: 13.4904\n",
      "Epoch 2025/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2753 - mae: 2.2753 - mse: 12.2224 - val_loss: 2.3614 - val_mae: 2.3614 - val_mse: 13.3999\n",
      "Epoch 2026/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3027 - mae: 2.3027 - mse: 12.3247 - val_loss: 2.4194 - val_mae: 2.4194 - val_mse: 13.4968\n",
      "Epoch 2027/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2835 - mae: 2.2835 - mse: 12.2233 - val_loss: 2.4262 - val_mae: 2.4262 - val_mse: 13.4770\n",
      "Epoch 2028/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.2423 - val_loss: 2.3809 - val_mae: 2.3809 - val_mse: 13.6450\n",
      "Epoch 2029/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2844 - mae: 2.2844 - mse: 12.1755 - val_loss: 2.4253 - val_mae: 2.4253 - val_mse: 13.7304\n",
      "Epoch 2030/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2968 - mae: 2.2968 - mse: 12.3064 - val_loss: 2.5520 - val_mae: 2.5520 - val_mse: 14.0735\n",
      "Epoch 2031/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.4012 - mae: 2.4012 - mse: 13.3666 - val_loss: 2.5848 - val_mae: 2.5848 - val_mse: 15.6528\n",
      "Epoch 2032/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4189 - mae: 2.4189 - mse: 13.8294 - val_loss: 2.4665 - val_mae: 2.4665 - val_mse: 14.3559\n",
      "Epoch 2033/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3859 - mae: 2.3859 - mse: 13.3828 - val_loss: 2.4540 - val_mae: 2.4540 - val_mse: 14.2019\n",
      "Epoch 2034/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2852 - mae: 2.2852 - mse: 12.2243 - val_loss: 2.4133 - val_mae: 2.4133 - val_mse: 13.8954\n",
      "Epoch 2035/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.2925 - mae: 2.2925 - mse: 12.1721 - val_loss: 2.3651 - val_mae: 2.3651 - val_mse: 13.3831\n",
      "Epoch 2036/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2575 - mae: 2.2575 - mse: 12.0635 - val_loss: 2.3682 - val_mae: 2.3682 - val_mse: 13.2768\n",
      "Epoch 2037/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2713 - mae: 2.2713 - mse: 12.1255 - val_loss: 2.3887 - val_mae: 2.3887 - val_mse: 14.0028\n",
      "Epoch 2038/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2772 - mae: 2.2772 - mse: 12.2407 - val_loss: 2.4126 - val_mae: 2.4126 - val_mse: 13.9181\n",
      "Epoch 2039/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2893 - mae: 2.2893 - mse: 12.1680 - val_loss: 2.4063 - val_mae: 2.4063 - val_mse: 13.9563\n",
      "Epoch 2040/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2659 - mae: 2.2659 - mse: 12.0988 - val_loss: 2.4259 - val_mae: 2.4259 - val_mse: 13.9079\n",
      "Epoch 2041/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3363 - mae: 2.3363 - mse: 12.5964 - val_loss: 2.4101 - val_mae: 2.4101 - val_mse: 13.7606\n",
      "Epoch 2042/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3152 - mae: 2.3152 - mse: 12.4168 - val_loss: 2.4004 - val_mae: 2.4004 - val_mse: 13.4559\n",
      "Epoch 2043/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3805 - mae: 2.3805 - mse: 12.9568 - val_loss: 2.4387 - val_mae: 2.4387 - val_mse: 14.0076\n",
      "Epoch 2044/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3255 - mae: 2.3255 - mse: 12.5139 - val_loss: 2.3854 - val_mae: 2.3854 - val_mse: 13.6774\n",
      "Epoch 2045/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.4055 - mae: 2.4055 - mse: 13.5937 - val_loss: 2.4553 - val_mae: 2.4553 - val_mse: 14.3044\n",
      "Epoch 2046/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.4669 - mae: 2.4669 - mse: 13.6115 - val_loss: 2.5852 - val_mae: 2.5852 - val_mse: 14.4124\n",
      "Epoch 2047/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3447 - mae: 2.3447 - mse: 12.6706 - val_loss: 2.5620 - val_mae: 2.5620 - val_mse: 14.1909\n",
      "Epoch 2048/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3172 - mae: 2.3172 - mse: 12.4493 - val_loss: 2.4416 - val_mae: 2.4416 - val_mse: 13.4767\n",
      "Epoch 2049/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2777 - mae: 2.2777 - mse: 12.1201 - val_loss: 2.4253 - val_mae: 2.4253 - val_mse: 13.9781\n",
      "Epoch 2050/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2725 - mae: 2.2725 - mse: 12.1393 - val_loss: 2.4223 - val_mae: 2.4223 - val_mse: 13.6786\n",
      "Epoch 2051/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3600 - mae: 2.3600 - mse: 12.9137 - val_loss: 2.4318 - val_mae: 2.4318 - val_mse: 13.5397\n",
      "Epoch 2052/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.4410 - mae: 2.4410 - mse: 13.8114 - val_loss: 2.4162 - val_mae: 2.4162 - val_mse: 13.5658\n",
      "Epoch 2053/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3158 - mae: 2.3158 - mse: 12.4396 - val_loss: 2.5077 - val_mae: 2.5077 - val_mse: 14.7139\n",
      "Epoch 2054/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3330 - mae: 2.3330 - mse: 12.5030 - val_loss: 2.4239 - val_mae: 2.4239 - val_mse: 13.7119\n",
      "Epoch 2055/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3109 - mae: 2.3109 - mse: 12.4296 - val_loss: 2.4083 - val_mae: 2.4083 - val_mse: 13.3800\n",
      "Epoch 2056/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2631 - mae: 2.2631 - mse: 12.0648 - val_loss: 2.3834 - val_mae: 2.3834 - val_mse: 13.6946\n",
      "Epoch 2057/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3067 - mae: 2.3067 - mse: 12.2997 - val_loss: 2.3681 - val_mae: 2.3681 - val_mse: 13.4890\n",
      "Epoch 2058/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2563 - mae: 2.2563 - mse: 12.0339 - val_loss: 2.3601 - val_mae: 2.3601 - val_mse: 13.5060\n",
      "Epoch 2059/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2929 - mae: 2.2929 - mse: 12.3236 - val_loss: 2.4744 - val_mae: 2.4744 - val_mse: 14.3989\n",
      "Epoch 2060/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3236 - mae: 2.3236 - mse: 12.5018 - val_loss: 2.4527 - val_mae: 2.4527 - val_mse: 14.4562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2061/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2698 - mae: 2.2698 - mse: 12.1947 - val_loss: 2.3746 - val_mae: 2.3746 - val_mse: 13.3511\n",
      "Epoch 2062/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2532 - mae: 2.2532 - mse: 12.0083 - val_loss: 2.3847 - val_mae: 2.3847 - val_mse: 13.6988\n",
      "Epoch 2063/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2828 - mae: 2.2828 - mse: 12.2159 - val_loss: 2.3933 - val_mae: 2.3933 - val_mse: 13.7076\n",
      "Epoch 2064/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2708 - mae: 2.2708 - mse: 12.0381 - val_loss: 2.4323 - val_mae: 2.4323 - val_mse: 13.3676\n",
      "Epoch 2065/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2874 - mae: 2.2874 - mse: 12.2253 - val_loss: 2.4669 - val_mae: 2.4669 - val_mse: 13.4426\n",
      "Epoch 2066/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2870 - mae: 2.2870 - mse: 12.1136 - val_loss: 2.4047 - val_mae: 2.4047 - val_mse: 13.9486\n",
      "Epoch 2067/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2797 - mae: 2.2797 - mse: 12.1855 - val_loss: 2.3948 - val_mae: 2.3948 - val_mse: 13.3645\n",
      "Epoch 2068/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2746 - mae: 2.2746 - mse: 12.1413 - val_loss: 2.3738 - val_mae: 2.3738 - val_mse: 13.6316\n",
      "Epoch 2069/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2597 - mae: 2.2597 - mse: 12.0279 - val_loss: 2.4085 - val_mae: 2.4085 - val_mse: 13.4925\n",
      "Epoch 2070/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2779 - mae: 2.2779 - mse: 12.1156 - val_loss: 2.4050 - val_mae: 2.4050 - val_mse: 13.8622\n",
      "Epoch 2071/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2704 - mae: 2.2704 - mse: 12.1953 - val_loss: 2.3659 - val_mae: 2.3659 - val_mse: 13.5573\n",
      "Epoch 2072/2500\n",
      "684/684 [==============================] - 1s 804us/sample - loss: 2.2910 - mae: 2.2910 - mse: 12.2703 - val_loss: 2.3896 - val_mae: 2.3896 - val_mse: 13.6280\n",
      "Epoch 2073/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3060 - mae: 2.3060 - mse: 12.4387 - val_loss: 2.6498 - val_mae: 2.6498 - val_mse: 14.8053\n",
      "Epoch 2074/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3934 - mae: 2.3934 - mse: 13.1241 - val_loss: 2.4403 - val_mae: 2.4403 - val_mse: 14.1819\n",
      "Epoch 2075/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2880 - mae: 2.2880 - mse: 12.3566 - val_loss: 2.3848 - val_mae: 2.3848 - val_mse: 13.9391\n",
      "Epoch 2076/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3038 - mae: 2.3038 - mse: 12.2914 - val_loss: 2.4330 - val_mae: 2.4330 - val_mse: 14.0453\n",
      "Epoch 2077/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.2981 - mae: 2.2981 - mse: 12.2831 - val_loss: 2.4749 - val_mae: 2.4749 - val_mse: 13.5938\n",
      "Epoch 2078/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.3181 - mae: 2.3181 - mse: 12.6048 - val_loss: 2.4286 - val_mae: 2.4286 - val_mse: 14.0817\n",
      "Epoch 2079/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2823 - mae: 2.2823 - mse: 12.2619 - val_loss: 2.4836 - val_mae: 2.4836 - val_mse: 14.0990\n",
      "Epoch 2080/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2771 - mae: 2.2771 - mse: 12.1622 - val_loss: 2.3853 - val_mae: 2.3853 - val_mse: 13.5340\n",
      "Epoch 2081/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2792 - mae: 2.2792 - mse: 12.2540 - val_loss: 2.3842 - val_mae: 2.3842 - val_mse: 13.5454\n",
      "Epoch 2082/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2743 - mae: 2.2743 - mse: 12.2678 - val_loss: 2.4891 - val_mae: 2.4891 - val_mse: 14.0958\n",
      "Epoch 2083/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3161 - mae: 2.3161 - mse: 12.5504 - val_loss: 2.3796 - val_mae: 2.3796 - val_mse: 13.7124\n",
      "Epoch 2084/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2691 - mae: 2.2691 - mse: 12.1933 - val_loss: 2.4527 - val_mae: 2.4527 - val_mse: 13.9484\n",
      "Epoch 2085/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3206 - mae: 2.3206 - mse: 12.8394 - val_loss: 2.4430 - val_mae: 2.4430 - val_mse: 13.8441\n",
      "Epoch 2086/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2849 - mae: 2.2849 - mse: 12.1782 - val_loss: 2.3873 - val_mae: 2.3873 - val_mse: 13.5130\n",
      "Epoch 2087/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2906 - mae: 2.2906 - mse: 12.1654 - val_loss: 2.3907 - val_mae: 2.3907 - val_mse: 13.5226\n",
      "Epoch 2088/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3393 - mae: 2.3393 - mse: 12.4101 - val_loss: 2.4587 - val_mae: 2.4587 - val_mse: 13.9856\n",
      "Epoch 2089/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3091 - mae: 2.3091 - mse: 12.4277 - val_loss: 2.5746 - val_mae: 2.5746 - val_mse: 15.1696\n",
      "Epoch 2090/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3395 - mae: 2.3395 - mse: 12.5843 - val_loss: 2.3993 - val_mae: 2.3993 - val_mse: 13.3391\n",
      "Epoch 2091/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2993 - mae: 2.2993 - mse: 12.3007 - val_loss: 2.3824 - val_mae: 2.3824 - val_mse: 13.4461\n",
      "Epoch 2092/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2842 - mae: 2.2842 - mse: 12.1894 - val_loss: 2.3911 - val_mae: 2.3911 - val_mse: 13.5821\n",
      "Epoch 2093/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2785 - mae: 2.2785 - mse: 12.0621 - val_loss: 2.3893 - val_mae: 2.3893 - val_mse: 13.4712\n",
      "Epoch 2094/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2903 - mae: 2.2903 - mse: 12.2635 - val_loss: 2.3879 - val_mae: 2.3879 - val_mse: 13.6071\n",
      "Epoch 2095/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2759 - mae: 2.2759 - mse: 12.2082 - val_loss: 2.3489 - val_mae: 2.3489 - val_mse: 13.3045\n",
      "Epoch 2096/2500\n",
      "684/684 [==============================] - 1s 783us/sample - loss: 2.2874 - mae: 2.2874 - mse: 12.2606 - val_loss: 2.4056 - val_mae: 2.4056 - val_mse: 13.4976\n",
      "Epoch 2097/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2829 - mae: 2.2829 - mse: 12.2023 - val_loss: 2.3688 - val_mae: 2.3688 - val_mse: 13.4996\n",
      "Epoch 2098/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2701 - mae: 2.2701 - mse: 12.1696 - val_loss: 2.3848 - val_mae: 2.3848 - val_mse: 13.3919\n",
      "Epoch 2099/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3000 - mae: 2.3000 - mse: 12.2414 - val_loss: 2.5847 - val_mae: 2.5847 - val_mse: 15.0826\n",
      "Epoch 2100/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3269 - mae: 2.3269 - mse: 12.4575 - val_loss: 2.3652 - val_mae: 2.3652 - val_mse: 13.4588\n",
      "Epoch 2101/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2706 - mae: 2.2706 - mse: 12.1564 - val_loss: 2.4723 - val_mae: 2.4723 - val_mse: 13.5853\n",
      "Epoch 2102/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3215 - mae: 2.3215 - mse: 12.4563 - val_loss: 2.3664 - val_mae: 2.3664 - val_mse: 13.7872\n",
      "Epoch 2103/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2823 - mae: 2.2823 - mse: 12.1708 - val_loss: 2.3873 - val_mae: 2.3873 - val_mse: 13.3280\n",
      "Epoch 2104/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3655 - mae: 2.3655 - mse: 12.8213 - val_loss: 2.4720 - val_mae: 2.4720 - val_mse: 14.6770\n",
      "Epoch 2105/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2741 - mae: 2.2741 - mse: 12.1926 - val_loss: 2.3663 - val_mae: 2.3663 - val_mse: 13.3387\n",
      "Epoch 2106/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2760 - mae: 2.2760 - mse: 12.2149 - val_loss: 2.4001 - val_mae: 2.4001 - val_mse: 13.5556\n",
      "Epoch 2107/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2658 - mae: 2.2658 - mse: 12.0747 - val_loss: 2.4168 - val_mae: 2.4168 - val_mse: 13.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2108/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2800 - mae: 2.2800 - mse: 12.1627 - val_loss: 2.4197 - val_mae: 2.4197 - val_mse: 13.9657\n",
      "Epoch 2109/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2834 - mae: 2.2834 - mse: 12.2671 - val_loss: 2.3944 - val_mae: 2.3944 - val_mse: 13.3550\n",
      "Epoch 2110/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3353 - mae: 2.3353 - mse: 12.6369 - val_loss: 2.4084 - val_mae: 2.4084 - val_mse: 14.1011\n",
      "Epoch 2111/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3263 - mae: 2.3263 - mse: 12.5502 - val_loss: 2.4132 - val_mae: 2.4132 - val_mse: 14.0636\n",
      "Epoch 2112/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2960 - mae: 2.2960 - mse: 12.2948 - val_loss: 2.4455 - val_mae: 2.4455 - val_mse: 13.4337\n",
      "Epoch 2113/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3022 - mae: 2.3022 - mse: 12.3848 - val_loss: 2.4065 - val_mae: 2.4065 - val_mse: 14.0737\n",
      "Epoch 2114/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2990 - mae: 2.2990 - mse: 12.3633 - val_loss: 2.4449 - val_mae: 2.4449 - val_mse: 13.7036\n",
      "Epoch 2115/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2916 - mae: 2.2916 - mse: 12.3449 - val_loss: 2.3946 - val_mae: 2.3946 - val_mse: 13.4335\n",
      "Epoch 2116/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3179 - mae: 2.3179 - mse: 12.2955 - val_loss: 2.4022 - val_mae: 2.4022 - val_mse: 13.5749\n",
      "Epoch 2117/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2610 - mae: 2.2610 - mse: 12.1209 - val_loss: 2.3601 - val_mae: 2.3601 - val_mse: 13.3809\n",
      "Epoch 2118/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2760 - mae: 2.2760 - mse: 12.1070 - val_loss: 2.3923 - val_mae: 2.3923 - val_mse: 13.7690\n",
      "Epoch 2119/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2872 - mae: 2.2872 - mse: 12.2664 - val_loss: 2.3799 - val_mae: 2.3799 - val_mse: 13.5078\n",
      "Epoch 2120/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2781 - mae: 2.2781 - mse: 12.1429 - val_loss: 2.4119 - val_mae: 2.4119 - val_mse: 13.8942\n",
      "Epoch 2121/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3177 - mae: 2.3177 - mse: 12.4232 - val_loss: 2.4534 - val_mae: 2.4534 - val_mse: 14.1891\n",
      "Epoch 2122/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3553 - mae: 2.3553 - mse: 12.7320 - val_loss: 2.4141 - val_mae: 2.4141 - val_mse: 13.7247\n",
      "Epoch 2123/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2851 - mae: 2.2851 - mse: 12.2453 - val_loss: 2.4465 - val_mae: 2.4465 - val_mse: 13.6563\n",
      "Epoch 2124/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3607 - mae: 2.3607 - mse: 12.7334 - val_loss: 2.4370 - val_mae: 2.4370 - val_mse: 14.1108\n",
      "Epoch 2125/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.3109 - mae: 2.3109 - mse: 12.4796 - val_loss: 2.3745 - val_mae: 2.3745 - val_mse: 13.5198\n",
      "Epoch 2126/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2738 - mae: 2.2738 - mse: 12.2741 - val_loss: 2.3653 - val_mae: 2.3653 - val_mse: 13.5500\n",
      "Epoch 2127/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2769 - mae: 2.2769 - mse: 12.1854 - val_loss: 2.3985 - val_mae: 2.3985 - val_mse: 13.4125\n",
      "Epoch 2128/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2952 - mae: 2.2952 - mse: 12.2454 - val_loss: 2.4474 - val_mae: 2.4474 - val_mse: 13.7629\n",
      "Epoch 2129/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2922 - mae: 2.2922 - mse: 12.2574 - val_loss: 2.3816 - val_mae: 2.3816 - val_mse: 13.4879\n",
      "Epoch 2130/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2739 - mae: 2.2739 - mse: 12.1742 - val_loss: 2.3825 - val_mae: 2.3825 - val_mse: 13.9034\n",
      "Epoch 2131/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2869 - mae: 2.2869 - mse: 12.2319 - val_loss: 2.3574 - val_mae: 2.3574 - val_mse: 13.5081\n",
      "Epoch 2132/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2847 - mae: 2.2847 - mse: 12.2882 - val_loss: 2.4408 - val_mae: 2.4408 - val_mse: 13.7142\n",
      "Epoch 2133/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2876 - mae: 2.2876 - mse: 12.3300 - val_loss: 2.4342 - val_mae: 2.4342 - val_mse: 14.0343\n",
      "Epoch 2134/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2959 - mae: 2.2959 - mse: 12.3508 - val_loss: 2.4037 - val_mae: 2.4037 - val_mse: 13.7102\n",
      "Epoch 2135/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2931 - mae: 2.2931 - mse: 12.2954 - val_loss: 2.3679 - val_mae: 2.3679 - val_mse: 13.4078\n",
      "Epoch 2136/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2640 - mae: 2.2640 - mse: 12.1259 - val_loss: 2.3549 - val_mae: 2.3549 - val_mse: 13.4293\n",
      "Epoch 2137/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2656 - mae: 2.2656 - mse: 12.1686 - val_loss: 2.3655 - val_mae: 2.3655 - val_mse: 13.4126\n",
      "Epoch 2138/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2640 - mae: 2.2640 - mse: 12.0923 - val_loss: 2.3641 - val_mae: 2.3641 - val_mse: 13.4772\n",
      "Epoch 2139/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3142 - mae: 2.3142 - mse: 12.4202 - val_loss: 2.3807 - val_mae: 2.3807 - val_mse: 13.4512\n",
      "Epoch 2140/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2826 - mae: 2.2826 - mse: 12.2073 - val_loss: 2.3981 - val_mae: 2.3981 - val_mse: 13.7000\n",
      "Epoch 2141/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3041 - mae: 2.3041 - mse: 12.3337 - val_loss: 2.3897 - val_mae: 2.3897 - val_mse: 13.8220\n",
      "Epoch 2142/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2774 - mae: 2.2774 - mse: 12.1366 - val_loss: 2.4124 - val_mae: 2.4124 - val_mse: 14.0969\n",
      "Epoch 2143/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2822 - mae: 2.2822 - mse: 12.1776 - val_loss: 2.3745 - val_mae: 2.3745 - val_mse: 13.3622\n",
      "Epoch 2144/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2690 - mae: 2.2690 - mse: 12.2652 - val_loss: 2.3660 - val_mae: 2.3660 - val_mse: 13.4354\n",
      "Epoch 2145/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.2649 - mae: 2.2649 - mse: 12.1429 - val_loss: 2.3985 - val_mae: 2.3985 - val_mse: 13.9769\n",
      "Epoch 2146/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.3115 - mae: 2.3115 - mse: 12.3442 - val_loss: 2.4455 - val_mae: 2.4455 - val_mse: 14.7339\n",
      "Epoch 2147/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3314 - mae: 2.3314 - mse: 12.7399 - val_loss: 2.3630 - val_mae: 2.3630 - val_mse: 13.3925\n",
      "Epoch 2148/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2739 - mae: 2.2739 - mse: 12.1263 - val_loss: 2.3741 - val_mae: 2.3741 - val_mse: 13.4252\n",
      "Epoch 2149/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3113 - mae: 2.3113 - mse: 12.3646 - val_loss: 2.4097 - val_mae: 2.4097 - val_mse: 14.0253\n",
      "Epoch 2150/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2857 - mae: 2.2857 - mse: 12.2782 - val_loss: 2.3943 - val_mae: 2.3943 - val_mse: 13.5704\n",
      "Epoch 2151/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2824 - mae: 2.2824 - mse: 12.3110 - val_loss: 2.4149 - val_mae: 2.4149 - val_mse: 14.0642\n",
      "Epoch 2152/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3166 - mae: 2.3166 - mse: 12.5283 - val_loss: 2.5917 - val_mae: 2.5917 - val_mse: 14.3032\n",
      "Epoch 2153/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3137 - mae: 2.3137 - mse: 12.5166 - val_loss: 2.3892 - val_mae: 2.3892 - val_mse: 13.5618\n",
      "Epoch 2154/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2778 - mae: 2.2778 - mse: 12.1509 - val_loss: 2.4071 - val_mae: 2.4071 - val_mse: 13.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2155/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3209 - mae: 2.3209 - mse: 12.4639 - val_loss: 2.3867 - val_mae: 2.3867 - val_mse: 13.8436\n",
      "Epoch 2156/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2615 - mae: 2.2615 - mse: 12.1415 - val_loss: 2.4019 - val_mae: 2.4019 - val_mse: 13.6968\n",
      "Epoch 2157/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2917 - mae: 2.2917 - mse: 12.4276 - val_loss: 2.4414 - val_mae: 2.4414 - val_mse: 13.7265\n",
      "Epoch 2158/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2875 - mae: 2.2875 - mse: 12.2743 - val_loss: 2.3645 - val_mae: 2.3645 - val_mse: 13.4511\n",
      "Epoch 2159/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2869 - mae: 2.2869 - mse: 12.2026 - val_loss: 2.3656 - val_mae: 2.3656 - val_mse: 13.5742\n",
      "Epoch 2160/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2553 - mae: 2.2553 - mse: 12.0665 - val_loss: 2.3934 - val_mae: 2.3934 - val_mse: 13.6471\n",
      "Epoch 2161/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2677 - mae: 2.2677 - mse: 12.0917 - val_loss: 2.3607 - val_mae: 2.3607 - val_mse: 13.2401\n",
      "Epoch 2162/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2622 - mae: 2.2622 - mse: 12.0228 - val_loss: 2.3664 - val_mae: 2.3664 - val_mse: 13.5039\n",
      "Epoch 2163/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2569 - mae: 2.2569 - mse: 12.0184 - val_loss: 2.3919 - val_mae: 2.3919 - val_mse: 13.6372\n",
      "Epoch 2164/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2801 - mae: 2.2801 - mse: 12.1354 - val_loss: 2.3835 - val_mae: 2.3835 - val_mse: 13.4137\n",
      "Epoch 2165/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3702 - mae: 2.3702 - mse: 12.5945 - val_loss: 2.5238 - val_mae: 2.5238 - val_mse: 14.3201\n",
      "Epoch 2166/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.3097 - mae: 2.3097 - mse: 12.4005 - val_loss: 2.4220 - val_mae: 2.4220 - val_mse: 13.8489\n",
      "Epoch 2167/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3241 - mae: 2.3241 - mse: 12.7858 - val_loss: 2.4307 - val_mae: 2.4307 - val_mse: 14.6118\n",
      "Epoch 2168/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3102 - mae: 2.3102 - mse: 12.6010 - val_loss: 2.3869 - val_mae: 2.3869 - val_mse: 13.4513\n",
      "Epoch 2169/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3136 - mae: 2.3136 - mse: 12.5001 - val_loss: 2.4017 - val_mae: 2.4017 - val_mse: 13.4378\n",
      "Epoch 2170/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3116 - mae: 2.3116 - mse: 12.4961 - val_loss: 2.4288 - val_mae: 2.4288 - val_mse: 14.0129\n",
      "Epoch 2171/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.3423 - mae: 2.3423 - mse: 12.6991 - val_loss: 2.4174 - val_mae: 2.4174 - val_mse: 13.7666\n",
      "Epoch 2172/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3004 - mae: 2.3004 - mse: 12.3203 - val_loss: 2.5034 - val_mae: 2.5034 - val_mse: 13.6788\n",
      "Epoch 2173/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3197 - mae: 2.3197 - mse: 12.4457 - val_loss: 2.3980 - val_mae: 2.3980 - val_mse: 14.1014\n",
      "Epoch 2174/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2836 - mae: 2.2836 - mse: 12.2365 - val_loss: 2.3792 - val_mae: 2.3792 - val_mse: 13.6387\n",
      "Epoch 2175/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2690 - mae: 2.2690 - mse: 12.1335 - val_loss: 2.3992 - val_mae: 2.3992 - val_mse: 13.7831\n",
      "Epoch 2176/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2867 - mae: 2.2867 - mse: 12.1888 - val_loss: 2.3668 - val_mae: 2.3668 - val_mse: 13.3627\n",
      "Epoch 2177/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2555 - mae: 2.2555 - mse: 11.9673 - val_loss: 2.4200 - val_mae: 2.4200 - val_mse: 13.7086\n",
      "Epoch 2178/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2674 - mae: 2.2674 - mse: 12.0807 - val_loss: 2.3960 - val_mae: 2.3960 - val_mse: 13.7552\n",
      "Epoch 2179/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3212 - mae: 2.3212 - mse: 12.4583 - val_loss: 2.5058 - val_mae: 2.5058 - val_mse: 13.9934\n",
      "Epoch 2180/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3670 - mae: 2.3670 - mse: 12.9335 - val_loss: 2.8429 - val_mae: 2.8429 - val_mse: 19.2102\n",
      "Epoch 2181/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3906 - mae: 2.3906 - mse: 13.2515 - val_loss: 2.4454 - val_mae: 2.4454 - val_mse: 14.2895\n",
      "Epoch 2182/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2797 - mae: 2.2797 - mse: 12.3964 - val_loss: 2.4275 - val_mae: 2.4275 - val_mse: 13.6724\n",
      "Epoch 2183/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2759 - mae: 2.2759 - mse: 12.2988 - val_loss: 2.3744 - val_mae: 2.3744 - val_mse: 13.5014\n",
      "Epoch 2184/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2944 - mae: 2.2944 - mse: 12.3019 - val_loss: 2.3717 - val_mae: 2.3717 - val_mse: 13.3971\n",
      "Epoch 2185/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2633 - mae: 2.2633 - mse: 12.0896 - val_loss: 2.3560 - val_mae: 2.3560 - val_mse: 13.3930\n",
      "Epoch 2186/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2583 - mae: 2.2583 - mse: 12.0067 - val_loss: 2.4157 - val_mae: 2.4157 - val_mse: 13.4622\n",
      "Epoch 2187/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2836 - mae: 2.2836 - mse: 12.2527 - val_loss: 2.5249 - val_mae: 2.5249 - val_mse: 15.1987\n",
      "Epoch 2188/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3127 - mae: 2.3127 - mse: 12.6459 - val_loss: 2.5885 - val_mae: 2.5885 - val_mse: 14.7004\n",
      "Epoch 2189/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.4375 - mae: 2.4375 - mse: 13.1678 - val_loss: 2.4475 - val_mae: 2.4475 - val_mse: 14.0009\n",
      "Epoch 2190/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2867 - mae: 2.2867 - mse: 12.3449 - val_loss: 2.3937 - val_mae: 2.3937 - val_mse: 13.6388\n",
      "Epoch 2191/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2746 - mae: 2.2746 - mse: 12.2783 - val_loss: 2.3715 - val_mae: 2.3715 - val_mse: 13.7043\n",
      "Epoch 2192/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2717 - mae: 2.2717 - mse: 12.0766 - val_loss: 2.3842 - val_mae: 2.3842 - val_mse: 13.6378\n",
      "Epoch 2193/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2637 - mae: 2.2637 - mse: 12.0408 - val_loss: 2.3728 - val_mae: 2.3728 - val_mse: 13.6208\n",
      "Epoch 2194/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.2757 - mae: 2.2757 - mse: 12.1478 - val_loss: 2.3705 - val_mae: 2.3705 - val_mse: 13.6030\n",
      "Epoch 2195/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3861 - mae: 2.3861 - mse: 13.2400 - val_loss: 2.4783 - val_mae: 2.4783 - val_mse: 14.9595\n",
      "Epoch 2196/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3958 - mae: 2.3958 - mse: 13.1995 - val_loss: 2.4593 - val_mae: 2.4593 - val_mse: 14.3571\n",
      "Epoch 2197/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3297 - mae: 2.3297 - mse: 12.6444 - val_loss: 2.3823 - val_mae: 2.3823 - val_mse: 13.6917\n",
      "Epoch 2198/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3139 - mae: 2.3139 - mse: 12.4059 - val_loss: 2.4362 - val_mae: 2.4362 - val_mse: 13.5613\n",
      "Epoch 2199/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2672 - mae: 2.2672 - mse: 12.1200 - val_loss: 2.4280 - val_mae: 2.4280 - val_mse: 13.6346\n",
      "Epoch 2200/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2828 - mae: 2.2828 - mse: 12.1533 - val_loss: 2.3666 - val_mae: 2.3666 - val_mse: 13.3875\n",
      "Epoch 2201/2500\n",
      "684/684 [==============================] - 1s 808us/sample - loss: 2.2968 - mae: 2.2968 - mse: 12.3481 - val_loss: 2.5182 - val_mae: 2.5182 - val_mse: 15.8383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2202/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2878 - mae: 2.2878 - mse: 12.2519 - val_loss: 2.3992 - val_mae: 2.3992 - val_mse: 13.4277\n",
      "Epoch 2203/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2728 - mae: 2.2728 - mse: 12.1222 - val_loss: 2.3729 - val_mae: 2.3729 - val_mse: 13.5524\n",
      "Epoch 2204/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2718 - mae: 2.2718 - mse: 12.1983 - val_loss: 2.3766 - val_mae: 2.3766 - val_mse: 13.7262\n",
      "Epoch 2205/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2971 - mae: 2.2971 - mse: 12.2305 - val_loss: 2.3901 - val_mae: 2.3901 - val_mse: 13.4890\n",
      "Epoch 2206/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2766 - mae: 2.2766 - mse: 12.1526 - val_loss: 2.3704 - val_mae: 2.3704 - val_mse: 13.6083\n",
      "Epoch 2207/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2911 - mae: 2.2911 - mse: 12.2664 - val_loss: 2.3800 - val_mae: 2.3800 - val_mse: 13.5911\n",
      "Epoch 2208/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2613 - mae: 2.2613 - mse: 12.1202 - val_loss: 2.3577 - val_mae: 2.3577 - val_mse: 13.3145\n",
      "Epoch 2209/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2507 - mae: 2.2507 - mse: 12.0386 - val_loss: 2.3425 - val_mae: 2.3425 - val_mse: 13.2461\n",
      "Epoch 2210/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2602 - mae: 2.2602 - mse: 11.9949 - val_loss: 2.3957 - val_mae: 2.3957 - val_mse: 13.5438\n",
      "Epoch 2211/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2931 - mae: 2.2931 - mse: 12.1699 - val_loss: 2.4160 - val_mae: 2.4160 - val_mse: 13.6354\n",
      "Epoch 2212/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3071 - mae: 2.3071 - mse: 12.3561 - val_loss: 2.4594 - val_mae: 2.4594 - val_mse: 14.2385\n",
      "Epoch 2213/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2918 - mae: 2.2918 - mse: 12.3567 - val_loss: 2.4000 - val_mae: 2.4000 - val_mse: 13.9581\n",
      "Epoch 2214/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2637 - mae: 2.2637 - mse: 12.2123 - val_loss: 2.3953 - val_mae: 2.3953 - val_mse: 13.7752\n",
      "Epoch 2215/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2797 - mae: 2.2797 - mse: 12.1668 - val_loss: 2.3873 - val_mae: 2.3873 - val_mse: 13.8511\n",
      "Epoch 2216/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2790 - mae: 2.2790 - mse: 12.1050 - val_loss: 2.3785 - val_mae: 2.3785 - val_mse: 13.5737\n",
      "Epoch 2217/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2670 - mae: 2.2670 - mse: 12.1188 - val_loss: 2.3683 - val_mae: 2.3683 - val_mse: 13.4439\n",
      "Epoch 2218/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2720 - mae: 2.2720 - mse: 12.0917 - val_loss: 2.3617 - val_mae: 2.3617 - val_mse: 13.6495\n",
      "Epoch 2219/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3270 - mae: 2.3270 - mse: 12.4586 - val_loss: 2.5370 - val_mae: 2.5370 - val_mse: 14.1475\n",
      "Epoch 2220/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.5379 - mae: 2.5379 - mse: 14.5819 - val_loss: 2.5897 - val_mae: 2.5897 - val_mse: 15.4700\n",
      "Epoch 2221/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3814 - mae: 2.3814 - mse: 12.9195 - val_loss: 2.5050 - val_mae: 2.5050 - val_mse: 14.3910\n",
      "Epoch 2222/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3320 - mae: 2.3320 - mse: 12.7880 - val_loss: 2.4374 - val_mae: 2.4374 - val_mse: 14.4221\n",
      "Epoch 2223/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3406 - mae: 2.3407 - mse: 12.9859 - val_loss: 2.7389 - val_mae: 2.7389 - val_mse: 15.9212\n",
      "Epoch 2224/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.4784 - mae: 2.4784 - mse: 13.6789 - val_loss: 2.4422 - val_mae: 2.4422 - val_mse: 13.9360\n",
      "Epoch 2225/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3871 - mae: 2.3871 - mse: 13.0456 - val_loss: 2.4415 - val_mae: 2.4415 - val_mse: 14.0741\n",
      "Epoch 2226/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3518 - mae: 2.3518 - mse: 12.8141 - val_loss: 2.4137 - val_mae: 2.4137 - val_mse: 13.8514\n",
      "Epoch 2227/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3267 - mae: 2.3267 - mse: 12.5188 - val_loss: 2.5113 - val_mae: 2.5113 - val_mse: 14.0485\n",
      "Epoch 2228/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3456 - mae: 2.3456 - mse: 12.5908 - val_loss: 2.4488 - val_mae: 2.4488 - val_mse: 14.6503\n",
      "Epoch 2229/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.4364 - mae: 2.4364 - mse: 13.6892 - val_loss: 2.5575 - val_mae: 2.5575 - val_mse: 15.7999\n",
      "Epoch 2230/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3735 - mae: 2.3735 - mse: 12.9197 - val_loss: 2.3949 - val_mae: 2.3949 - val_mse: 13.6363\n",
      "Epoch 2231/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3367 - mae: 2.3367 - mse: 12.6559 - val_loss: 2.4369 - val_mae: 2.4369 - val_mse: 13.7938\n",
      "Epoch 2232/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.3968 - mae: 2.3968 - mse: 12.8725 - val_loss: 2.5348 - val_mae: 2.5348 - val_mse: 14.7947\n",
      "Epoch 2233/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3698 - mae: 2.3698 - mse: 12.9593 - val_loss: 2.4729 - val_mae: 2.4729 - val_mse: 14.9591\n",
      "Epoch 2234/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3295 - mae: 2.3295 - mse: 12.5301 - val_loss: 2.3937 - val_mae: 2.3937 - val_mse: 13.7327\n",
      "Epoch 2235/2500\n",
      "684/684 [==============================] - 1s 807us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.2974 - val_loss: 2.3890 - val_mae: 2.3890 - val_mse: 13.9542\n",
      "Epoch 2236/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2934 - mae: 2.2934 - mse: 12.3753 - val_loss: 2.4027 - val_mae: 2.4027 - val_mse: 14.0315\n",
      "Epoch 2237/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2882 - mae: 2.2882 - mse: 12.2906 - val_loss: 2.4954 - val_mae: 2.4954 - val_mse: 14.7621\n",
      "Epoch 2238/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3256 - mae: 2.3256 - mse: 12.4617 - val_loss: 2.4683 - val_mae: 2.4683 - val_mse: 13.7170\n",
      "Epoch 2239/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3442 - mae: 2.3442 - mse: 12.5589 - val_loss: 2.5382 - val_mae: 2.5382 - val_mse: 14.6307\n",
      "Epoch 2240/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2760 - mae: 2.2760 - mse: 12.1721 - val_loss: 2.3775 - val_mae: 2.3775 - val_mse: 13.5926\n",
      "Epoch 2241/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.3088 - mae: 2.3088 - mse: 12.3537 - val_loss: 2.3706 - val_mae: 2.3706 - val_mse: 13.5338\n",
      "Epoch 2242/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.3720 - val_loss: 2.3935 - val_mae: 2.3935 - val_mse: 13.4761\n",
      "Epoch 2243/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2993 - mae: 2.2993 - mse: 12.2074 - val_loss: 2.4476 - val_mae: 2.4476 - val_mse: 13.8682\n",
      "Epoch 2244/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3104 - mae: 2.3104 - mse: 12.3453 - val_loss: 2.3762 - val_mae: 2.3762 - val_mse: 13.5136\n",
      "Epoch 2245/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2927 - mae: 2.2927 - mse: 12.2813 - val_loss: 2.4830 - val_mae: 2.4830 - val_mse: 14.8117\n",
      "Epoch 2246/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3094 - mae: 2.3094 - mse: 12.3818 - val_loss: 2.4406 - val_mae: 2.4406 - val_mse: 14.0092\n",
      "Epoch 2247/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3190 - mae: 2.3190 - mse: 12.4273 - val_loss: 2.4751 - val_mae: 2.4751 - val_mse: 13.4666\n",
      "Epoch 2248/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2799 - mae: 2.2799 - mse: 12.1971 - val_loss: 2.3893 - val_mae: 2.3893 - val_mse: 13.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2249/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2807 - mae: 2.2807 - mse: 12.2190 - val_loss: 2.4157 - val_mae: 2.4157 - val_mse: 13.6587\n",
      "Epoch 2250/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2633 - mae: 2.2633 - mse: 12.0558 - val_loss: 2.3918 - val_mae: 2.3918 - val_mse: 13.4392\n",
      "Epoch 2251/2500\n",
      "684/684 [==============================] - 1s 783us/sample - loss: 2.2634 - mae: 2.2634 - mse: 12.1272 - val_loss: 2.3645 - val_mae: 2.3645 - val_mse: 13.3926\n",
      "Epoch 2252/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2703 - mae: 2.2703 - mse: 12.0992 - val_loss: 2.3796 - val_mae: 2.3796 - val_mse: 13.2435\n",
      "Epoch 2253/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2812 - mae: 2.2812 - mse: 12.1160 - val_loss: 2.3776 - val_mae: 2.3776 - val_mse: 13.3616\n",
      "Epoch 2254/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2636 - mae: 2.2636 - mse: 12.0999 - val_loss: 2.3872 - val_mae: 2.3872 - val_mse: 13.8123\n",
      "Epoch 2255/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2627 - mae: 2.2627 - mse: 12.0142 - val_loss: 2.3878 - val_mae: 2.3878 - val_mse: 13.3064\n",
      "Epoch 2256/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.3066 - mae: 2.3066 - mse: 12.3892 - val_loss: 2.3864 - val_mae: 2.3864 - val_mse: 13.7380\n",
      "Epoch 2257/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3101 - mae: 2.3101 - mse: 12.3474 - val_loss: 2.3762 - val_mae: 2.3762 - val_mse: 13.3910\n",
      "Epoch 2258/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3098 - mae: 2.3098 - mse: 12.3444 - val_loss: 2.3812 - val_mae: 2.3812 - val_mse: 13.9139\n",
      "Epoch 2259/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3106 - mae: 2.3106 - mse: 12.2849 - val_loss: 2.4336 - val_mae: 2.4336 - val_mse: 14.2599\n",
      "Epoch 2260/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.2730 - mae: 2.2730 - mse: 12.1507 - val_loss: 2.3528 - val_mae: 2.3528 - val_mse: 13.2835\n",
      "Epoch 2261/2500\n",
      "684/684 [==============================] - 1s 781us/sample - loss: 2.2661 - mae: 2.2661 - mse: 12.1348 - val_loss: 2.3441 - val_mae: 2.3441 - val_mse: 13.3455\n",
      "Epoch 2262/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2714 - mae: 2.2714 - mse: 12.1392 - val_loss: 2.3514 - val_mae: 2.3514 - val_mse: 13.3213\n",
      "Epoch 2263/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2811 - mae: 2.2811 - mse: 12.2348 - val_loss: 2.3762 - val_mae: 2.3762 - val_mse: 13.4645\n",
      "Epoch 2264/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3806 - mae: 2.3806 - mse: 12.9151 - val_loss: 2.4481 - val_mae: 2.4481 - val_mse: 14.6449\n",
      "Epoch 2265/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3328 - mae: 2.3328 - mse: 12.5502 - val_loss: 2.4319 - val_mae: 2.4319 - val_mse: 13.9075\n",
      "Epoch 2266/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3074 - mae: 2.3074 - mse: 12.3595 - val_loss: 2.4036 - val_mae: 2.4036 - val_mse: 13.7836\n",
      "Epoch 2267/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2969 - mae: 2.2969 - mse: 12.3579 - val_loss: 2.3776 - val_mae: 2.3776 - val_mse: 13.8019\n",
      "Epoch 2268/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2922 - mae: 2.2922 - mse: 12.3486 - val_loss: 2.3630 - val_mae: 2.3630 - val_mse: 13.4656\n",
      "Epoch 2269/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.1658 - val_loss: 2.4367 - val_mae: 2.4367 - val_mse: 13.4930\n",
      "Epoch 2270/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2894 - mae: 2.2894 - mse: 12.2336 - val_loss: 2.3906 - val_mae: 2.3906 - val_mse: 13.6310\n",
      "Epoch 2271/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2762 - mae: 2.2762 - mse: 12.1953 - val_loss: 2.5304 - val_mae: 2.5304 - val_mse: 14.8479\n",
      "Epoch 2272/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3364 - mae: 2.3364 - mse: 12.5110 - val_loss: 2.5126 - val_mae: 2.5126 - val_mse: 14.4231\n",
      "Epoch 2273/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3009 - mae: 2.3009 - mse: 12.5300 - val_loss: 2.4113 - val_mae: 2.4113 - val_mse: 14.5022\n",
      "Epoch 2274/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2870 - mae: 2.2870 - mse: 12.2258 - val_loss: 2.3817 - val_mae: 2.3817 - val_mse: 13.7668\n",
      "Epoch 2275/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2678 - mae: 2.2678 - mse: 12.0838 - val_loss: 2.4090 - val_mae: 2.4090 - val_mse: 13.7417\n",
      "Epoch 2276/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2913 - mae: 2.2913 - mse: 12.2989 - val_loss: 2.4453 - val_mae: 2.4453 - val_mse: 14.0795\n",
      "Epoch 2277/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2948 - mae: 2.2948 - mse: 12.2887 - val_loss: 2.3700 - val_mae: 2.3700 - val_mse: 13.4679\n",
      "Epoch 2278/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2873 - mae: 2.2873 - mse: 12.2383 - val_loss: 2.4110 - val_mae: 2.4110 - val_mse: 13.7358\n",
      "Epoch 2279/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.3004 - mae: 2.3004 - mse: 12.2432 - val_loss: 2.3786 - val_mae: 2.3786 - val_mse: 13.5932\n",
      "Epoch 2280/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2879 - mae: 2.2879 - mse: 12.1665 - val_loss: 2.5081 - val_mae: 2.5081 - val_mse: 14.7926\n",
      "Epoch 2281/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3100 - mae: 2.3100 - mse: 12.4854 - val_loss: 2.3806 - val_mae: 2.3806 - val_mse: 13.6533\n",
      "Epoch 2282/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2962 - mae: 2.2962 - mse: 12.4144 - val_loss: 2.4139 - val_mae: 2.4139 - val_mse: 14.0718\n",
      "Epoch 2283/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2646 - mae: 2.2646 - mse: 12.0845 - val_loss: 2.3660 - val_mae: 2.3660 - val_mse: 13.3606\n",
      "Epoch 2284/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2825 - mae: 2.2825 - mse: 12.1649 - val_loss: 2.3891 - val_mae: 2.3891 - val_mse: 13.8728\n",
      "Epoch 2285/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2484 - mae: 2.2484 - mse: 11.9780 - val_loss: 2.3775 - val_mae: 2.3775 - val_mse: 13.7780\n",
      "Epoch 2286/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2866 - mae: 2.2866 - mse: 12.2261 - val_loss: 2.4072 - val_mae: 2.4072 - val_mse: 14.1571\n",
      "Epoch 2287/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2677 - mae: 2.2677 - mse: 12.1198 - val_loss: 2.3897 - val_mae: 2.3897 - val_mse: 13.5573\n",
      "Epoch 2288/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2931 - mae: 2.2931 - mse: 12.3473 - val_loss: 2.4316 - val_mae: 2.4316 - val_mse: 14.4015\n",
      "Epoch 2289/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3237 - mae: 2.3238 - mse: 12.6938 - val_loss: 2.5622 - val_mae: 2.5622 - val_mse: 15.2914\n",
      "Epoch 2290/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3143 - mae: 2.3143 - mse: 12.4806 - val_loss: 2.4258 - val_mae: 2.4258 - val_mse: 13.5698\n",
      "Epoch 2291/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2877 - mae: 2.2877 - mse: 12.1116 - val_loss: 2.3923 - val_mae: 2.3923 - val_mse: 13.4096\n",
      "Epoch 2292/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2769 - mae: 2.2769 - mse: 12.0823 - val_loss: 2.3913 - val_mae: 2.3913 - val_mse: 13.6281\n",
      "Epoch 2293/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2832 - mae: 2.2832 - mse: 12.3038 - val_loss: 2.3737 - val_mae: 2.3737 - val_mse: 13.6422\n",
      "Epoch 2294/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2960 - mae: 2.2960 - mse: 12.2585 - val_loss: 2.3634 - val_mae: 2.3634 - val_mse: 13.4731\n",
      "Epoch 2295/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2807 - mae: 2.2807 - mse: 12.2196 - val_loss: 2.3839 - val_mae: 2.3839 - val_mse: 13.5433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2296/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2677 - mae: 2.2677 - mse: 12.1015 - val_loss: 2.3676 - val_mae: 2.3676 - val_mse: 13.5905\n",
      "Epoch 2297/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2676 - mae: 2.2676 - mse: 12.1385 - val_loss: 2.4142 - val_mae: 2.4142 - val_mse: 13.8549\n",
      "Epoch 2298/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2785 - mae: 2.2785 - mse: 12.2334 - val_loss: 2.4031 - val_mae: 2.4031 - val_mse: 13.3690\n",
      "Epoch 2299/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2633 - mae: 2.2633 - mse: 12.0603 - val_loss: 2.3861 - val_mae: 2.3861 - val_mse: 13.9476\n",
      "Epoch 2300/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2716 - mae: 2.2716 - mse: 12.1181 - val_loss: 2.4557 - val_mae: 2.4557 - val_mse: 14.1001\n",
      "Epoch 2301/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3259 - mae: 2.3259 - mse: 12.4704 - val_loss: 2.5287 - val_mae: 2.5287 - val_mse: 14.3706\n",
      "Epoch 2302/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2855 - mae: 2.2855 - mse: 12.1949 - val_loss: 2.3769 - val_mae: 2.3769 - val_mse: 13.5148\n",
      "Epoch 2303/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2671 - mae: 2.2671 - mse: 12.0473 - val_loss: 2.3889 - val_mae: 2.3889 - val_mse: 13.4872\n",
      "Epoch 2304/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2727 - mae: 2.2727 - mse: 12.1825 - val_loss: 2.3735 - val_mae: 2.3735 - val_mse: 13.4085\n",
      "Epoch 2305/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2815 - mae: 2.2815 - mse: 12.1211 - val_loss: 2.3667 - val_mae: 2.3667 - val_mse: 13.4837\n",
      "Epoch 2306/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2912 - mae: 2.2912 - mse: 12.2558 - val_loss: 2.3770 - val_mae: 2.3770 - val_mse: 13.7508\n",
      "Epoch 2307/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2872 - mae: 2.2872 - mse: 12.2628 - val_loss: 2.3600 - val_mae: 2.3600 - val_mse: 13.3767\n",
      "Epoch 2308/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3095 - mae: 2.3095 - mse: 12.5118 - val_loss: 2.3744 - val_mae: 2.3744 - val_mse: 13.4938\n",
      "Epoch 2309/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3044 - mae: 2.3044 - mse: 12.4347 - val_loss: 2.4923 - val_mae: 2.4923 - val_mse: 14.0620\n",
      "Epoch 2310/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2868 - mae: 2.2868 - mse: 12.1946 - val_loss: 2.3726 - val_mae: 2.3726 - val_mse: 13.5560\n",
      "Epoch 2311/2500\n",
      "684/684 [==============================] - 1s 822us/sample - loss: 2.2916 - mae: 2.2916 - mse: 12.2679 - val_loss: 2.3926 - val_mae: 2.3926 - val_mse: 13.5950\n",
      "Epoch 2312/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2683 - mae: 2.2683 - mse: 12.1128 - val_loss: 2.3810 - val_mae: 2.3810 - val_mse: 13.4996\n",
      "Epoch 2313/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2823 - mae: 2.2823 - mse: 12.2001 - val_loss: 2.4406 - val_mae: 2.4406 - val_mse: 13.6619\n",
      "Epoch 2314/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2832 - mae: 2.2832 - mse: 12.2799 - val_loss: 2.4061 - val_mae: 2.4061 - val_mse: 13.8929\n",
      "Epoch 2315/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2783 - mae: 2.2783 - mse: 12.1378 - val_loss: 2.4437 - val_mae: 2.4437 - val_mse: 14.4828\n",
      "Epoch 2316/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3001 - mae: 2.3001 - mse: 12.4384 - val_loss: 2.3919 - val_mae: 2.3919 - val_mse: 13.5007\n",
      "Epoch 2317/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3177 - mae: 2.3177 - mse: 12.4266 - val_loss: 2.4307 - val_mae: 2.4307 - val_mse: 14.3486\n",
      "Epoch 2318/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3898 - mae: 2.3898 - mse: 13.0214 - val_loss: 2.4257 - val_mae: 2.4257 - val_mse: 13.7902\n",
      "Epoch 2319/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2913 - mae: 2.2913 - mse: 12.2692 - val_loss: 2.4699 - val_mae: 2.4699 - val_mse: 14.0526\n",
      "Epoch 2320/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3026 - mae: 2.3026 - mse: 12.4281 - val_loss: 2.4332 - val_mae: 2.4332 - val_mse: 13.8499\n",
      "Epoch 2321/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3160 - mae: 2.3160 - mse: 12.4575 - val_loss: 2.5148 - val_mae: 2.5148 - val_mse: 15.1984\n",
      "Epoch 2322/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2921 - mae: 2.2921 - mse: 12.3795 - val_loss: 2.3683 - val_mae: 2.3683 - val_mse: 13.6910\n",
      "Epoch 2323/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2896 - mae: 2.2896 - mse: 12.2370 - val_loss: 2.5925 - val_mae: 2.5925 - val_mse: 14.7815\n",
      "Epoch 2324/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3202 - mae: 2.3202 - mse: 12.3524 - val_loss: 2.4737 - val_mae: 2.4737 - val_mse: 14.1203\n",
      "Epoch 2325/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2844 - mae: 2.2844 - mse: 12.2808 - val_loss: 2.3557 - val_mae: 2.3557 - val_mse: 13.3881\n",
      "Epoch 2326/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2686 - mae: 2.2686 - mse: 12.1008 - val_loss: 2.5166 - val_mae: 2.5166 - val_mse: 14.2885\n",
      "Epoch 2327/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2892 - mae: 2.2892 - mse: 12.3358 - val_loss: 2.3859 - val_mae: 2.3859 - val_mse: 13.3630\n",
      "Epoch 2328/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2755 - mae: 2.2755 - mse: 12.0584 - val_loss: 2.4993 - val_mae: 2.4993 - val_mse: 14.7752\n",
      "Epoch 2329/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3318 - mae: 2.3318 - mse: 12.5907 - val_loss: 2.3566 - val_mae: 2.3566 - val_mse: 13.3170\n",
      "Epoch 2330/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2920 - mae: 2.2920 - mse: 12.2097 - val_loss: 2.4141 - val_mae: 2.4141 - val_mse: 13.6869\n",
      "Epoch 2331/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2717 - mae: 2.2717 - mse: 12.1909 - val_loss: 2.4267 - val_mae: 2.4267 - val_mse: 14.2062\n",
      "Epoch 2332/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2683 - mae: 2.2683 - mse: 12.0524 - val_loss: 2.3603 - val_mae: 2.3603 - val_mse: 13.4483\n",
      "Epoch 2333/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2765 - mae: 2.2765 - mse: 12.1911 - val_loss: 2.4126 - val_mae: 2.4126 - val_mse: 13.4264\n",
      "Epoch 2334/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2593 - mae: 2.2593 - mse: 12.0488 - val_loss: 2.3817 - val_mae: 2.3817 - val_mse: 13.6220\n",
      "Epoch 2335/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2574 - mae: 2.2574 - mse: 12.0292 - val_loss: 2.3549 - val_mae: 2.3549 - val_mse: 13.4128\n",
      "Epoch 2336/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2425 - mae: 2.2425 - mse: 11.9874 - val_loss: 2.3615 - val_mae: 2.3615 - val_mse: 13.3745\n",
      "Epoch 2337/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2898 - mae: 2.2898 - mse: 12.2460 - val_loss: 2.3554 - val_mae: 2.3554 - val_mse: 13.3656\n",
      "Epoch 2338/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2547 - mae: 2.2547 - mse: 11.9768 - val_loss: 2.3727 - val_mae: 2.3727 - val_mse: 13.6300\n",
      "Epoch 2339/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2803 - mae: 2.2803 - mse: 12.1687 - val_loss: 2.4031 - val_mae: 2.4031 - val_mse: 13.9380\n",
      "Epoch 2340/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2847 - mae: 2.2847 - mse: 12.1411 - val_loss: 2.4269 - val_mae: 2.4269 - val_mse: 13.4472\n",
      "Epoch 2341/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3166 - mae: 2.3166 - mse: 12.3368 - val_loss: 2.4943 - val_mae: 2.4943 - val_mse: 14.2988\n",
      "Epoch 2342/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2957 - mae: 2.2957 - mse: 12.2725 - val_loss: 2.3799 - val_mae: 2.3799 - val_mse: 13.4205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2343/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2677 - mae: 2.2677 - mse: 12.1176 - val_loss: 2.4065 - val_mae: 2.4065 - val_mse: 13.8482\n",
      "Epoch 2344/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.2961 - mae: 2.2961 - mse: 12.5038 - val_loss: 2.4069 - val_mae: 2.4069 - val_mse: 14.4298\n",
      "Epoch 2345/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2805 - mae: 2.2805 - mse: 12.2604 - val_loss: 2.3930 - val_mae: 2.3930 - val_mse: 13.6705\n",
      "Epoch 2346/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2734 - mae: 2.2734 - mse: 12.1703 - val_loss: 2.3594 - val_mae: 2.3594 - val_mse: 13.3819\n",
      "Epoch 2347/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2772 - mae: 2.2772 - mse: 12.1928 - val_loss: 2.3827 - val_mae: 2.3827 - val_mse: 13.4751\n",
      "Epoch 2348/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2899 - mae: 2.2899 - mse: 12.3036 - val_loss: 2.3796 - val_mae: 2.3796 - val_mse: 13.5054\n",
      "Epoch 2349/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2713 - mae: 2.2713 - mse: 12.1305 - val_loss: 2.3741 - val_mae: 2.3741 - val_mse: 13.3223\n",
      "Epoch 2350/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2784 - mae: 2.2784 - mse: 12.1305 - val_loss: 2.3583 - val_mae: 2.3583 - val_mse: 13.4866\n",
      "Epoch 2351/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2900 - mae: 2.2900 - mse: 12.2151 - val_loss: 2.5104 - val_mae: 2.5104 - val_mse: 13.9423\n",
      "Epoch 2352/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3102 - mae: 2.3102 - mse: 12.3516 - val_loss: 2.4035 - val_mae: 2.4035 - val_mse: 13.4475\n",
      "Epoch 2353/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2757 - mae: 2.2757 - mse: 12.1419 - val_loss: 2.3897 - val_mae: 2.3897 - val_mse: 13.3991\n",
      "Epoch 2354/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2892 - mae: 2.2892 - mse: 12.2256 - val_loss: 2.4339 - val_mae: 2.4339 - val_mse: 14.4060\n",
      "Epoch 2355/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3193 - mae: 2.3193 - mse: 12.5417 - val_loss: 2.3833 - val_mae: 2.3833 - val_mse: 13.9259\n",
      "Epoch 2356/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2917 - mae: 2.2917 - mse: 12.3835 - val_loss: 2.4416 - val_mae: 2.4416 - val_mse: 14.8517\n",
      "Epoch 2357/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.3094 - mae: 2.3094 - mse: 12.4395 - val_loss: 2.3798 - val_mae: 2.3798 - val_mse: 13.5620\n",
      "Epoch 2358/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3083 - mae: 2.3083 - mse: 12.4216 - val_loss: 2.3671 - val_mae: 2.3671 - val_mse: 13.4561\n",
      "Epoch 2359/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.4026 - mae: 2.4026 - mse: 13.1610 - val_loss: 2.4516 - val_mae: 2.4516 - val_mse: 14.0392\n",
      "Epoch 2360/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.4758 - mae: 2.4758 - mse: 13.9417 - val_loss: 2.5298 - val_mae: 2.5298 - val_mse: 15.1499\n",
      "Epoch 2361/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3826 - mae: 2.3826 - mse: 13.1235 - val_loss: 2.3920 - val_mae: 2.3920 - val_mse: 13.9431\n",
      "Epoch 2362/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2997 - mae: 2.2997 - mse: 12.4095 - val_loss: 2.4328 - val_mae: 2.4328 - val_mse: 14.1275\n",
      "Epoch 2363/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2753 - mae: 2.2753 - mse: 12.2141 - val_loss: 2.4598 - val_mae: 2.4598 - val_mse: 14.0988\n",
      "Epoch 2364/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2871 - mae: 2.2871 - mse: 12.2630 - val_loss: 2.3963 - val_mae: 2.3963 - val_mse: 13.6852\n",
      "Epoch 2365/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2811 - mae: 2.2811 - mse: 12.2986 - val_loss: 2.3993 - val_mae: 2.3993 - val_mse: 14.1668\n",
      "Epoch 2366/2500\n",
      "684/684 [==============================] - 1s 805us/sample - loss: 2.2515 - mae: 2.2515 - mse: 12.0386 - val_loss: 2.3836 - val_mae: 2.3836 - val_mse: 13.3699\n",
      "Epoch 2367/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2665 - mae: 2.2665 - mse: 12.0623 - val_loss: 2.3582 - val_mae: 2.3582 - val_mse: 13.3916\n",
      "Epoch 2368/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2498 - mae: 2.2498 - mse: 11.9639 - val_loss: 2.3767 - val_mae: 2.3767 - val_mse: 13.4024\n",
      "Epoch 2369/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2508 - mae: 2.2508 - mse: 12.0136 - val_loss: 2.3507 - val_mae: 2.3507 - val_mse: 13.2598\n",
      "Epoch 2370/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2561 - mae: 2.2561 - mse: 12.0296 - val_loss: 2.4986 - val_mae: 2.4986 - val_mse: 13.6707\n",
      "Epoch 2371/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2612 - mae: 2.2612 - mse: 12.0922 - val_loss: 2.3524 - val_mae: 2.3524 - val_mse: 13.2617\n",
      "Epoch 2372/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2828 - mae: 2.2828 - mse: 12.1654 - val_loss: 2.3872 - val_mae: 2.3872 - val_mse: 13.5590\n",
      "Epoch 2373/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2775 - mae: 2.2775 - mse: 12.2722 - val_loss: 2.3744 - val_mae: 2.3744 - val_mse: 13.4134\n",
      "Epoch 2374/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3039 - mae: 2.3039 - mse: 12.3247 - val_loss: 2.4255 - val_mae: 2.4255 - val_mse: 13.6948\n",
      "Epoch 2375/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2604 - mae: 2.2604 - mse: 12.0441 - val_loss: 2.4010 - val_mae: 2.4010 - val_mse: 13.2619\n",
      "Epoch 2376/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2642 - mae: 2.2642 - mse: 12.0238 - val_loss: 2.3579 - val_mae: 2.3579 - val_mse: 13.3684\n",
      "Epoch 2377/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2570 - mae: 2.2570 - mse: 12.0713 - val_loss: 2.3749 - val_mae: 2.3749 - val_mse: 13.4332\n",
      "Epoch 2378/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2804 - mae: 2.2804 - mse: 12.0554 - val_loss: 2.3814 - val_mae: 2.3814 - val_mse: 13.4059\n",
      "Epoch 2379/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2599 - mae: 2.2599 - mse: 12.0511 - val_loss: 2.3554 - val_mae: 2.3554 - val_mse: 13.4608\n",
      "Epoch 2380/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2635 - mae: 2.2635 - mse: 12.1597 - val_loss: 2.3759 - val_mae: 2.3759 - val_mse: 13.3382\n",
      "Epoch 2381/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2603 - mae: 2.2603 - mse: 12.0246 - val_loss: 2.3748 - val_mae: 2.3748 - val_mse: 13.7526\n",
      "Epoch 2382/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2805 - mae: 2.2805 - mse: 12.1451 - val_loss: 2.5278 - val_mae: 2.5278 - val_mse: 14.8146\n",
      "Epoch 2383/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.5011 - mae: 2.5011 - mse: 14.4929 - val_loss: 2.6257 - val_mae: 2.6257 - val_mse: 15.8520\n",
      "Epoch 2384/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.3129 - mae: 2.3129 - mse: 12.4802 - val_loss: 2.3878 - val_mae: 2.3878 - val_mse: 13.6981\n",
      "Epoch 2385/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2926 - mae: 2.2926 - mse: 12.4250 - val_loss: 2.4268 - val_mae: 2.4268 - val_mse: 13.6817\n",
      "Epoch 2386/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2695 - mae: 2.2695 - mse: 12.0872 - val_loss: 2.3468 - val_mae: 2.3468 - val_mse: 13.2561\n",
      "Epoch 2387/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3092 - mae: 2.3092 - mse: 12.3093 - val_loss: 2.4130 - val_mae: 2.4130 - val_mse: 13.6538\n",
      "Epoch 2388/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2553 - mae: 2.2553 - mse: 11.9632 - val_loss: 2.3654 - val_mae: 2.3654 - val_mse: 13.3262\n",
      "Epoch 2389/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2690 - mae: 2.2690 - mse: 12.0858 - val_loss: 2.4526 - val_mae: 2.4526 - val_mse: 13.8518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2390/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2708 - mae: 2.2708 - mse: 12.1014 - val_loss: 2.4125 - val_mae: 2.4125 - val_mse: 13.2923\n",
      "Epoch 2391/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2586 - mae: 2.2586 - mse: 12.0534 - val_loss: 2.4032 - val_mae: 2.4032 - val_mse: 13.4287\n",
      "Epoch 2392/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2626 - mae: 2.2626 - mse: 12.0694 - val_loss: 2.3829 - val_mae: 2.3829 - val_mse: 13.4467\n",
      "Epoch 2393/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.3642 - mae: 2.3642 - mse: 12.6792 - val_loss: 2.5602 - val_mae: 2.5602 - val_mse: 15.1449\n",
      "Epoch 2394/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.3072 - mae: 2.3072 - mse: 12.4196 - val_loss: 2.3857 - val_mae: 2.3857 - val_mse: 13.6285\n",
      "Epoch 2395/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2618 - mae: 2.2618 - mse: 12.1462 - val_loss: 2.4341 - val_mae: 2.4341 - val_mse: 13.5526\n",
      "Epoch 2396/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2550 - mae: 2.2550 - mse: 12.0551 - val_loss: 2.3699 - val_mae: 2.3699 - val_mse: 13.2264\n",
      "Epoch 2397/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2744 - mae: 2.2744 - mse: 12.0671 - val_loss: 2.3966 - val_mae: 2.3966 - val_mse: 13.5388\n",
      "Epoch 2398/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2890 - mae: 2.2890 - mse: 12.2500 - val_loss: 2.4064 - val_mae: 2.4064 - val_mse: 13.2877\n",
      "Epoch 2399/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2953 - mae: 2.2953 - mse: 12.1569 - val_loss: 2.3725 - val_mae: 2.3725 - val_mse: 13.4315\n",
      "Epoch 2400/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2559 - mae: 2.2559 - mse: 12.0426 - val_loss: 2.3803 - val_mae: 2.3803 - val_mse: 13.5668\n",
      "Epoch 2401/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3076 - mae: 2.3076 - mse: 12.4760 - val_loss: 2.4599 - val_mae: 2.4599 - val_mse: 14.1889\n",
      "Epoch 2402/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2887 - mae: 2.2887 - mse: 12.2194 - val_loss: 2.4162 - val_mae: 2.4162 - val_mse: 13.9234\n",
      "Epoch 2403/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3037 - mae: 2.3037 - mse: 12.3020 - val_loss: 2.3825 - val_mae: 2.3825 - val_mse: 13.6809\n",
      "Epoch 2404/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3060 - mae: 2.3060 - mse: 12.3370 - val_loss: 2.4282 - val_mae: 2.4282 - val_mse: 13.9894\n",
      "Epoch 2405/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2807 - mae: 2.2807 - mse: 12.2051 - val_loss: 2.4102 - val_mae: 2.4102 - val_mse: 13.3262\n",
      "Epoch 2406/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2643 - mae: 2.2643 - mse: 12.1407 - val_loss: 2.3986 - val_mae: 2.3986 - val_mse: 13.6522\n",
      "Epoch 2407/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3018 - mae: 2.3018 - mse: 12.4902 - val_loss: 2.3641 - val_mae: 2.3641 - val_mse: 13.3918\n",
      "Epoch 2408/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2662 - mae: 2.2662 - mse: 12.0903 - val_loss: 2.3728 - val_mae: 2.3728 - val_mse: 13.5399\n",
      "Epoch 2409/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2639 - mae: 2.2639 - mse: 12.0794 - val_loss: 2.3996 - val_mae: 2.3996 - val_mse: 13.7303\n",
      "Epoch 2410/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.2787 - mae: 2.2787 - mse: 12.2054 - val_loss: 2.3849 - val_mae: 2.3849 - val_mse: 13.3934\n",
      "Epoch 2411/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2676 - mae: 2.2676 - mse: 12.0901 - val_loss: 2.4296 - val_mae: 2.4296 - val_mse: 13.4621\n",
      "Epoch 2412/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2820 - mae: 2.2820 - mse: 12.2084 - val_loss: 2.3689 - val_mae: 2.3689 - val_mse: 13.3861\n",
      "Epoch 2413/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.2945 - mae: 2.2945 - mse: 12.3788 - val_loss: 2.4275 - val_mae: 2.4275 - val_mse: 13.8544\n",
      "Epoch 2414/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2718 - mae: 2.2718 - mse: 12.0802 - val_loss: 2.4508 - val_mae: 2.4508 - val_mse: 14.1426\n",
      "Epoch 2415/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3535 - mae: 2.3535 - mse: 12.7667 - val_loss: 2.4419 - val_mae: 2.4419 - val_mse: 14.4001\n",
      "Epoch 2416/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3129 - mae: 2.3129 - mse: 12.4456 - val_loss: 2.3949 - val_mae: 2.3949 - val_mse: 13.4152\n",
      "Epoch 2417/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2696 - mae: 2.2696 - mse: 12.1349 - val_loss: 2.3827 - val_mae: 2.3827 - val_mse: 13.7627\n",
      "Epoch 2418/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2816 - mae: 2.2816 - mse: 12.1395 - val_loss: 2.3789 - val_mae: 2.3789 - val_mse: 13.7708\n",
      "Epoch 2419/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2680 - mae: 2.2680 - mse: 12.1430 - val_loss: 2.3565 - val_mae: 2.3565 - val_mse: 13.3584\n",
      "Epoch 2420/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2618 - mae: 2.2618 - mse: 12.0686 - val_loss: 2.3976 - val_mae: 2.3976 - val_mse: 13.8993\n",
      "Epoch 2421/2500\n",
      "684/684 [==============================] - 1s 806us/sample - loss: 2.2712 - mae: 2.2712 - mse: 12.1409 - val_loss: 2.3517 - val_mae: 2.3517 - val_mse: 13.3945\n",
      "Epoch 2422/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2602 - mae: 2.2602 - mse: 11.9933 - val_loss: 2.3666 - val_mae: 2.3666 - val_mse: 13.4126\n",
      "Epoch 2423/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2665 - mae: 2.2665 - mse: 12.1074 - val_loss: 2.3721 - val_mae: 2.3721 - val_mse: 13.3073\n",
      "Epoch 2424/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.3438 - mae: 2.3438 - mse: 12.9133 - val_loss: 2.4082 - val_mae: 2.4082 - val_mse: 14.1553\n",
      "Epoch 2425/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2993 - mae: 2.2993 - mse: 12.4058 - val_loss: 2.4052 - val_mae: 2.4052 - val_mse: 13.7057\n",
      "Epoch 2426/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3330 - mae: 2.3330 - mse: 12.6351 - val_loss: 2.4410 - val_mae: 2.4410 - val_mse: 14.3747\n",
      "Epoch 2427/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.2840 - mae: 2.2840 - mse: 12.3464 - val_loss: 2.3597 - val_mae: 2.3597 - val_mse: 13.6288\n",
      "Epoch 2428/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2888 - mae: 2.2888 - mse: 12.3072 - val_loss: 2.3887 - val_mae: 2.3887 - val_mse: 13.6150\n",
      "Epoch 2429/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3832 - mae: 2.3832 - mse: 13.0404 - val_loss: 2.5227 - val_mae: 2.5227 - val_mse: 15.2937\n",
      "Epoch 2430/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.3448 - mae: 2.3448 - mse: 13.0222 - val_loss: 2.6548 - val_mae: 2.6548 - val_mse: 15.9290\n",
      "Epoch 2431/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.4057 - mae: 2.4057 - mse: 13.5019 - val_loss: 2.4427 - val_mae: 2.4427 - val_mse: 14.1159\n",
      "Epoch 2432/2500\n",
      "684/684 [==============================] - 1s 784us/sample - loss: 2.4659 - mae: 2.4659 - mse: 13.6234 - val_loss: 2.5463 - val_mae: 2.5463 - val_mse: 14.0576\n",
      "Epoch 2433/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.3363 - mae: 2.3363 - mse: 12.6184 - val_loss: 2.3815 - val_mae: 2.3815 - val_mse: 13.6729\n",
      "Epoch 2434/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.3141 - mae: 2.3141 - mse: 12.5178 - val_loss: 2.5252 - val_mae: 2.5252 - val_mse: 15.3774\n",
      "Epoch 2435/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.4145 - mae: 2.4145 - mse: 13.1451 - val_loss: 2.5691 - val_mae: 2.5691 - val_mse: 15.4723\n",
      "Epoch 2436/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.3140 - mae: 2.3140 - mse: 12.5166 - val_loss: 2.3760 - val_mae: 2.3760 - val_mse: 13.3439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2437/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2649 - mae: 2.2649 - mse: 12.1073 - val_loss: 2.4146 - val_mae: 2.4146 - val_mse: 13.3276\n",
      "Epoch 2438/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2727 - mae: 2.2727 - mse: 12.1467 - val_loss: 2.3479 - val_mae: 2.3479 - val_mse: 13.3346\n",
      "Epoch 2439/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2914 - mae: 2.2914 - mse: 12.2016 - val_loss: 2.4275 - val_mae: 2.4275 - val_mse: 13.9043\n",
      "Epoch 2440/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2638 - mae: 2.2638 - mse: 12.0283 - val_loss: 2.3939 - val_mae: 2.3939 - val_mse: 13.7776\n",
      "Epoch 2441/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2646 - mae: 2.2646 - mse: 12.1526 - val_loss: 2.3691 - val_mae: 2.3691 - val_mse: 13.3939\n",
      "Epoch 2442/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2969 - mae: 2.2969 - mse: 12.3392 - val_loss: 2.3657 - val_mae: 2.3657 - val_mse: 13.3334\n",
      "Epoch 2443/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2930 - mae: 2.2930 - mse: 12.1992 - val_loss: 2.4387 - val_mae: 2.4387 - val_mse: 14.0652\n",
      "Epoch 2444/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2714 - mae: 2.2714 - mse: 12.1077 - val_loss: 2.3883 - val_mae: 2.3883 - val_mse: 13.4546\n",
      "Epoch 2445/2500\n",
      "684/684 [==============================] - 1s 781us/sample - loss: 2.2723 - mae: 2.2723 - mse: 12.1414 - val_loss: 2.4060 - val_mae: 2.4060 - val_mse: 14.0478\n",
      "Epoch 2446/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2910 - mae: 2.2910 - mse: 12.3637 - val_loss: 2.4168 - val_mae: 2.4168 - val_mse: 14.0363\n",
      "Epoch 2447/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.2671 - mae: 2.2671 - mse: 12.1119 - val_loss: 2.3567 - val_mae: 2.3567 - val_mse: 13.4448\n",
      "Epoch 2448/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2529 - mae: 2.2529 - mse: 12.0260 - val_loss: 2.3821 - val_mae: 2.3821 - val_mse: 13.5112\n",
      "Epoch 2449/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2548 - mae: 2.2548 - mse: 12.1010 - val_loss: 2.3617 - val_mae: 2.3617 - val_mse: 13.4311\n",
      "Epoch 2450/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2677 - mae: 2.2677 - mse: 12.1742 - val_loss: 2.3530 - val_mae: 2.3530 - val_mse: 13.2839\n",
      "Epoch 2451/2500\n",
      "684/684 [==============================] - 1s 787us/sample - loss: 2.2438 - mae: 2.2438 - mse: 11.9777 - val_loss: 2.3582 - val_mae: 2.3582 - val_mse: 13.4826\n",
      "Epoch 2452/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2404 - mae: 2.2404 - mse: 11.9198 - val_loss: 2.3448 - val_mae: 2.3448 - val_mse: 13.2571\n",
      "Epoch 2453/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2600 - mae: 2.2600 - mse: 12.0172 - val_loss: 2.3590 - val_mae: 2.3590 - val_mse: 13.4199\n",
      "Epoch 2454/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2562 - mae: 2.2562 - mse: 12.0281 - val_loss: 2.3963 - val_mae: 2.3963 - val_mse: 13.7478\n",
      "Epoch 2455/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2904 - mae: 2.2904 - mse: 12.1729 - val_loss: 2.4288 - val_mae: 2.4288 - val_mse: 14.0180\n",
      "Epoch 2456/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2745 - mae: 2.2745 - mse: 12.1082 - val_loss: 2.4111 - val_mae: 2.4111 - val_mse: 13.7982\n",
      "Epoch 2457/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2617 - mae: 2.2617 - mse: 12.0225 - val_loss: 2.3640 - val_mae: 2.3640 - val_mse: 13.3175\n",
      "Epoch 2458/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2746 - mae: 2.2746 - mse: 12.0927 - val_loss: 2.3664 - val_mae: 2.3664 - val_mse: 13.5820\n",
      "Epoch 2459/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2666 - mae: 2.2666 - mse: 12.2031 - val_loss: 2.3986 - val_mae: 2.3986 - val_mse: 13.5430\n",
      "Epoch 2460/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2712 - mae: 2.2712 - mse: 12.0822 - val_loss: 2.4035 - val_mae: 2.4035 - val_mse: 13.8681\n",
      "Epoch 2461/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2706 - mae: 2.2706 - mse: 12.1623 - val_loss: 2.4271 - val_mae: 2.4271 - val_mse: 13.6387\n",
      "Epoch 2462/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2777 - mae: 2.2777 - mse: 12.1591 - val_loss: 2.3839 - val_mae: 2.3839 - val_mse: 13.9270\n",
      "Epoch 2463/2500\n",
      "684/684 [==============================] - 1s 791us/sample - loss: 2.2693 - mae: 2.2693 - mse: 12.0366 - val_loss: 2.3505 - val_mae: 2.3505 - val_mse: 13.3180\n",
      "Epoch 2464/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2715 - mae: 2.2715 - mse: 12.1727 - val_loss: 2.3763 - val_mae: 2.3763 - val_mse: 13.5209\n",
      "Epoch 2465/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2759 - mae: 2.2759 - mse: 12.1523 - val_loss: 2.3704 - val_mae: 2.3704 - val_mse: 13.5202\n",
      "Epoch 2466/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2587 - mae: 2.2587 - mse: 12.1141 - val_loss: 2.4168 - val_mae: 2.4168 - val_mse: 14.2984\n",
      "Epoch 2467/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2456 - mae: 2.2456 - mse: 11.9616 - val_loss: 2.3931 - val_mae: 2.3931 - val_mse: 13.4165\n",
      "Epoch 2468/2500\n",
      "684/684 [==============================] - 1s 801us/sample - loss: 2.2474 - mae: 2.2474 - mse: 11.9213 - val_loss: 2.3619 - val_mae: 2.3619 - val_mse: 13.5736\n",
      "Epoch 2469/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2876 - mae: 2.2876 - mse: 12.1864 - val_loss: 2.3924 - val_mae: 2.3924 - val_mse: 13.6115\n",
      "Epoch 2470/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2671 - mae: 2.2671 - mse: 12.1505 - val_loss: 2.4458 - val_mae: 2.4458 - val_mse: 13.7452\n",
      "Epoch 2471/2500\n",
      "684/684 [==============================] - 1s 793us/sample - loss: 2.3323 - mae: 2.3323 - mse: 12.5217 - val_loss: 2.3666 - val_mae: 2.3666 - val_mse: 13.4559\n",
      "Epoch 2472/2500\n",
      "684/684 [==============================] - 1s 800us/sample - loss: 2.4256 - mae: 2.4256 - mse: 13.6117 - val_loss: 2.5688 - val_mae: 2.5688 - val_mse: 14.9258\n",
      "Epoch 2473/2500\n",
      "684/684 [==============================] - 1s 809us/sample - loss: 2.4834 - mae: 2.4834 - mse: 13.6431 - val_loss: 2.4830 - val_mae: 2.4830 - val_mse: 14.2236\n",
      "Epoch 2474/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.3812 - mae: 2.3812 - mse: 13.0627 - val_loss: 2.5199 - val_mae: 2.5199 - val_mse: 14.9265\n",
      "Epoch 2475/2500\n",
      "684/684 [==============================] - 1s 785us/sample - loss: 2.3521 - mae: 2.3521 - mse: 12.8312 - val_loss: 2.3803 - val_mae: 2.3803 - val_mse: 13.3335\n",
      "Epoch 2476/2500\n",
      "684/684 [==============================] - 1s 812us/sample - loss: 2.3392 - mae: 2.3392 - mse: 12.9094 - val_loss: 2.4356 - val_mae: 2.4356 - val_mse: 14.1839\n",
      "Epoch 2477/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2990 - mae: 2.2990 - mse: 12.2993 - val_loss: 2.3758 - val_mae: 2.3758 - val_mse: 13.5229\n",
      "Epoch 2478/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2686 - mae: 2.2686 - mse: 12.1156 - val_loss: 2.3667 - val_mae: 2.3667 - val_mse: 13.3596\n",
      "Epoch 2479/2500\n",
      "684/684 [==============================] - 1s 795us/sample - loss: 2.2777 - mae: 2.2777 - mse: 12.1931 - val_loss: 2.4386 - val_mae: 2.4386 - val_mse: 13.6900\n",
      "Epoch 2480/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2877 - mae: 2.2877 - mse: 12.2696 - val_loss: 2.4198 - val_mae: 2.4198 - val_mse: 14.1374\n",
      "Epoch 2481/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2859 - mae: 2.2859 - mse: 12.2206 - val_loss: 2.3715 - val_mae: 2.3715 - val_mse: 13.3544\n",
      "Epoch 2482/2500\n",
      "684/684 [==============================] - 1s 788us/sample - loss: 2.2609 - mae: 2.2609 - mse: 12.0364 - val_loss: 2.3649 - val_mae: 2.3649 - val_mse: 13.4012\n",
      "Epoch 2483/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2914 - mae: 2.2914 - mse: 12.1569 - val_loss: 2.4126 - val_mae: 2.4126 - val_mse: 13.6218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2484/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2691 - mae: 2.2691 - mse: 12.1778 - val_loss: 2.3588 - val_mae: 2.3588 - val_mse: 13.3041\n",
      "Epoch 2485/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2841 - mae: 2.2841 - mse: 12.3024 - val_loss: 2.3920 - val_mae: 2.3920 - val_mse: 13.4576\n",
      "Epoch 2486/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2657 - mae: 2.2657 - mse: 12.0494 - val_loss: 2.3576 - val_mae: 2.3576 - val_mse: 13.4486\n",
      "Epoch 2487/2500\n",
      "684/684 [==============================] - 1s 799us/sample - loss: 2.2855 - mae: 2.2855 - mse: 12.1584 - val_loss: 2.4023 - val_mae: 2.4023 - val_mse: 13.6131\n",
      "Epoch 2488/2500\n",
      "684/684 [==============================] - 1s 798us/sample - loss: 2.2976 - mae: 2.2976 - mse: 12.2662 - val_loss: 2.3850 - val_mae: 2.3850 - val_mse: 13.9784\n",
      "Epoch 2489/2500\n",
      "684/684 [==============================] - 1s 790us/sample - loss: 2.2895 - mae: 2.2895 - mse: 12.2147 - val_loss: 2.3733 - val_mae: 2.3733 - val_mse: 13.6932\n",
      "Epoch 2490/2500\n",
      "684/684 [==============================] - 1s 786us/sample - loss: 2.3314 - mae: 2.3314 - mse: 12.7970 - val_loss: 2.3774 - val_mae: 2.3774 - val_mse: 13.7314\n",
      "Epoch 2491/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2846 - mae: 2.2846 - mse: 12.3696 - val_loss: 2.3905 - val_mae: 2.3905 - val_mse: 13.9852\n",
      "Epoch 2492/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2796 - mae: 2.2796 - mse: 12.2094 - val_loss: 2.4172 - val_mae: 2.4172 - val_mse: 14.1230\n",
      "Epoch 2493/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2592 - mae: 2.2592 - mse: 12.1168 - val_loss: 2.3936 - val_mae: 2.3936 - val_mse: 13.5708\n",
      "Epoch 2494/2500\n",
      "684/684 [==============================] - 1s 802us/sample - loss: 2.2678 - mae: 2.2678 - mse: 12.2113 - val_loss: 2.3716 - val_mae: 2.3716 - val_mse: 13.5158\n",
      "Epoch 2495/2500\n",
      "684/684 [==============================] - 1s 796us/sample - loss: 2.2661 - mae: 2.2661 - mse: 12.0830 - val_loss: 2.4187 - val_mae: 2.4187 - val_mse: 13.9375\n",
      "Epoch 2496/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2772 - mae: 2.2772 - mse: 12.1111 - val_loss: 2.4066 - val_mae: 2.4066 - val_mse: 13.3866\n",
      "Epoch 2497/2500\n",
      "684/684 [==============================] - 1s 794us/sample - loss: 2.2805 - mae: 2.2805 - mse: 12.1728 - val_loss: 2.4419 - val_mae: 2.4419 - val_mse: 13.9536\n",
      "Epoch 2498/2500\n",
      "684/684 [==============================] - 1s 789us/sample - loss: 2.2530 - mae: 2.2530 - mse: 12.0137 - val_loss: 2.3736 - val_mae: 2.3736 - val_mse: 13.6192\n",
      "Epoch 2499/2500\n",
      "684/684 [==============================] - 1s 792us/sample - loss: 2.2541 - mae: 2.2541 - mse: 12.0026 - val_loss: 2.3537 - val_mae: 2.3537 - val_mse: 13.3635\n",
      "Epoch 2500/2500\n",
      "684/684 [==============================] - 1s 797us/sample - loss: 2.2428 - mae: 2.2428 - mse: 11.9575 - val_loss: 2.3564 - val_mae: 2.3564 - val_mse: 13.3831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149639f50>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  build_stack_GRU((10, 1), 20, 1)\n",
    "model.fit(train_x,train_y,batch_size=16,epochs=2500,validation_split=0.2,callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.03485365397076\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
